\chapter{Desarrollo matemático}

\section{Introducción a la inferencia}

	En esta primera sección se hace un breve repaso de los 
conceptos estadísticos necesarios para comprender el 
contenido de la memoria así como presentar la notación.
	
\begin{definicion}[Inferencia estadística]
	Rama de la estadística en la que se usan las propiedades
de una muestra para extraer conclusiones de la población. 
\end{definicion}

\begin{definicion}[Variable aleatoria]
	Función de conjuntos cuyo dominio es los elementos de un 
espacio muestral sobre el cual se ha definido una función de
probabilidad y cuyo rango es $\mathbb{R}$.\\
	$X$ es una variable aleatoria (v.a.) si para $x \in 
\mathbb{R}$ existe una probabilidad de que el valor tomado 
por la variable aleatoria sea menor o igual que $x$, es
decir, $P(X \leq x) = F_X (x)$, llamada función de
distribución de probabilidad (\textit{cumulative distribution
function}, cdf) de $X$.	
\end{definicion}

	Cualquier función de distribución, $F_X(x)$, de una v.a.
$X$ cumple las siguientes propiedades:
 
\begin{enumerate}
	\item $F_X$ es no decreciente: 
			$F_X(x_1) \leq F_X(x_2) \ \forall x_1 \leq x_2$.
	\item $\underset{x \rightarrow -\infty}{\lim} F_X(x) =
			 0$,
			$\underset{x \rightarrow \infty}{\lim} F_X(x) =
			 1$
	\item $F_X(x)$ es continua por la derecha: 
		$\underset{\varepsilon \rightarrow 0^+}{\lim} 
		F_X(x+\varepsilon) = F_X(x)$
\end{enumerate}

	Diremos que una v.a. es \textbf{continua} si su cdf es 
continua. Supondremos que una cdf continua es derivable cpd 
(\textit{casi por doquier}, es decir, en todo $\mathbb{R}$ 
salvo en un conjunto finito de puntos).
	
\begin{definicion}[Función de densidad]
	Se define la función de densidad como la derivada de 
$F_X(x)$, $f_X(x)$. Para $X$ continua:
	\[ 
		F_X(x) = \int_{-\infty}^x f_X(t) dt; \;
		f_X(x) = \frac{d}{dx}F_X(x) = F_X'(x) \geq 0; \;
		\int_{-\infty}^{\infty} f_X(x) dx = 1 
	\]
\end{definicion}
	
\begin{definicion}[Función de masa]
	Se define la función de masa de probabilidad  
(\textit{probability mass function}, pmf) de una v.a. 
\textbf{discreta}, es decir, que sólo toma un número contable 
de valores como
	\[ 
		f_X(x) = P(X=x) = 
		F_X(x) - 
			\lim_{\varepsilon \rightarrow 0^+} 
				F_X(X-\varepsilon).
	\]
\end{definicion}

\begin{definicion}[Muestra aleatoria]
	Llamamos muestra aleatoria de una v.a. $X$ a un conjunto 
de $n$ v.a., $(X_1, \dots, X_n)$, si son independientes e 
idénticamente distribuidas (i.i.d.), con lo que su 
distribución de probabilidad conjunta es
	\[ 
		f_{X}(x_1, \dots, x_n) =
		f_{X_1, \dots, X_n}(x_1, \dots, x_n) =
		\prod\limits_{i=1}^n f_X(x_i).
	\]
\end{definicion}
	
\begin{definicion}[Momento]
	Es un parámetro de la población. El momento $k$-ésimo de 
$X$ es $\mu_k' = E[X^k]$. La media es el momento de primer 
orden, $\mu_1' = E[X] = \mu$. El momento $k$-ésimo central es 
$\mu_k = E[(X - \mu)^k]$.
\end{definicion}

\begin{teorema}[Teorema central del límite]
	Sea $X_1, \dots, X_n$ una muestra aleatoria de una 
población con media $\mu$ y varianza $\sigma^2 > 0$ y sea 
$\bar{X}_n$ la media de esa muestra. Entonces para $n 
\rightarrow \infty$ la variable aleatoria $\sqrt{n}
\frac{(\bar{X}_n - \mu)}{\sigma}$ tiene como distribución 
límite la normal con media $0$ y varianza $1$.
\end{teorema}

\begin{definicion}[Estimador]
	Definimos como estimador, o estimador puntual una función 
de v.a. cuyo valor observado es usado para estimar el valor 
verdadero de un parámetro de la población. 
\end{definicion}

	Sea $\hat{\theta}_n = u(X_1, \dots, X_n)$ un estimador de 
un parámetro $\theta$. Incluimos unas propiedades deseables 
de $\hat{\theta}_n$:
	
	\begin{enumerate}
	\item \textit{Insesgadez}: 
			$E[\hat{\theta}_n] = \theta$ para todo $\theta$.
	\item \textit{Suficiencia}: Podemos escribir
			$f_{X_1, \dots, X_n}(x_1, \dots, x_n; \theta)$ 
			como producto de dos funciones $f_{X_1, \dots, 
			X_n}(x_1, \dots, x_n; \theta) = g(\hat{\theta}_n; 
			\theta) H((x_1, \dots, x_n)$ tal que $H(x_1, 
			\dots, x_n)$ no depende de $\theta$.
	\item \textit{Consistencia}
		\[ 
			\lim_{n \rightarrow \infty} 
				P(|\bar{\theta}_n - \theta| < \varepsilon) =
				 0 \quad 
				 \forall \varepsilon > 0 
		\]
	\begin{enumerate}
		\item Si $\hat{\theta}_n$ es un estimador insesgado 
			de $\theta$ y $\underset{n \rightarrow \infty}
			{\lim} var(\hat{\theta}_n) = 0$, entonces $
			\hat{\theta}_n$ es un estimador consistente por l
			a desigualdad de Chebyshev.
		\item $\hat{\theta}_n$ es un estimador consistente de 
			$\theta$ si la distribución límite es la 
			distribución degenerada con probabilidad $1$ en 
			$\theta$.
	\end{enumerate}
			
	\item \textit{Mínimo error cuadrático} 	
			$E[(\hat{\theta}_n - \theta)^2] \leq
			 E[(\hat{\theta}_n^* - \theta)^2]$ para cualquier 
			 estimador $\hat{\theta}_n^*$.
	\item \textit{Mínima varianza} 	$var(\hat{\theta}_n) \leq
			 var(\hat{\theta}^*_n)$ para cualquier estimador
			  $\hat{\theta}_n^*$, siendo ambos insesgados.
	\end{enumerate}
	
\begin{definicion}[Función de verosimilitud]
	La función de verosimilitud (\textit{likelihood 
function}) de una muestra aleatoria de tamaño $n$ de la 
población $f_X(x;\theta)$ es la probabilidad conjunta de las 
muestras tomadas como función de $\theta$. Esto es:
	\[ L(x_1, \dots, x_n; \theta) = 
		\prod\limits_{i=1}^n f_X(x_i;\theta)	\]
\end{definicion}

	Un \textbf{estimador máximo verosímil} (MLE) de $\theta$ 
es un valor $\bar{\theta}$ tal que 
	\[ 
		L(x_1, \dots, x_n; \bar{\theta}) \geq 
			L(x_1, \dots, x_n; \theta) \ \forall \theta 	
	\]
	
	La relevancia de este estimador consiste en que, para 
unas ciertas condiciones de regularidad, un estimador máximo 
verosímil es suficiente, consistente y asintóticamente 
insesgado, con varianza mínima y con distribución normal.
	
	
\begin{definicion}[Intervalo de confianza]
	Un intervalo de confianza al $100(1-\alpha)\%$ para el 
parámetro $\theta$ es un intervalo aleatorio de extremos $U$ 
y $V$ (funciones de v.a.) tal que $P(U < \theta < V) = 
1 -\alpha$.
\end{definicion}
	
\begin{definicion}[Hipótesis estadística]
	Es una afirmación sobre la la función de probabilidad de 
una o más v.a. o una afirmación sobre las poblaciones de las 
cuales se han obtenido una o más muestras aleatorias. La 
\textbf{hipótesis nula}, $H_0$ es la hipótesis sobre la que 
se realizará un test. La \textbf{hipótesis alternativa}, 
$H_1$ es la que conclusión alcanzada si se rechaza la 
hipótesis nula.
\end{definicion}

\begin{definicion}[Región crítica]
	Llamamos región crítica o región de rechazo $R$ para un 
test al conjunto de valores tomados por el test que conducen 
a rechazar la hipótesis nula. Llamamos \textbf{valores 
críticos} a los extremos de $R$.
\end{definicion}

\begin{definicion}[Tipos de error]\textit{}
	\begin{description}
	\item[Error de tipo I] La hipótesis nula es rechazada 
		siendo cierta.
	\item[Error de tipo II] La hipótesis nula no es rechazada 
		siendo falsa.
	\end{description}
\end{definicion}

	Siendo $T$ un test estadístico con hipótesis $H_0: \theta 
\in \omega, \ H_1: \theta \in \Omega \setminus \omega$, los 
errores de tipo I y II tienen probabilidad
	\[ 
	\alpha(\theta) = P(T \in R | \theta \in \omega); \quad
	\beta(\theta) = 
		P(T \not\in R | 
				\theta \in \Omega \setminus \omega)
	\]
	respectivamente.

\begin{definicion}[Tamaño del test]
	Se define el tamaño del test como $\underset{\theta \in 
	\omega}\sup \alpha(\theta)$.
\end{definicion}

\begin{definicion}[Potencia del test]
	Se define la potencia del test como la probabilidad de 
que el test conduzca a un rechazo de $H_0$: $Pw(\theta) = P(T 
\in R)$. Esta medida nos interesa cuando debemos rechazar la 
hipótesis nula, con lo que calculamos $Pw(\theta) = P(T \in R 
| \theta \in \Omega \setminus \omega) = 1 - \beta(\theta)$. 
\end{definicion}
	
	Diremos que un test es \textbf{más potente} para una 
hipótesis alternativa concreta si ningún test del mismo 
tamaño tiene mayor potencia contra la misma hipótesis 
alternativa.\\
	A continuación definimos un enfoque distinto,
especialmente relevante en los test no paramétricos. 
	
\begin{definicion}[$p$-valor]
	Probabilidad de obtener, siendo cierta la hipótesis nula 
$H_0$, una muestra aleatoria tan alejada o más de la 
hipotesis nula que la muestra aleatoria observada.
\end{definicion}

\begin{definicion}[Consistencia]
	Diremos que un test es consistente para una hipótesis 
alternativa $H_1$ si la potencia del test se aproxima a 1 
conforme $n \rightarrow \infty$, siendo $n$ el tamaño de la 
muestra.
\end{definicion}

	Notaremos como $\mathbb{I}[\textit{condición}]$ a la 
función indicadora, que toma valor $1$ si \textit{condición} es
cierta y 0 si no.
	
	
\section{Test paramétricos}

	Los test paramétricos se basan en la suposición de que la
muestra pertenece a una distribución que sigue un modelo 
conocido (frecuentemente, un modelo gaussiano). La ventaja de 
este enfoque es que la definición del modelo atiende a un 
pequeño número de parámetros (son los estadísticos 
suficientes). Estimando estos parámetros a partir de la 
muestra, se conoce la distribución. 
	
\subsection{Test binomial para una muestra}

	Con este test se pretende comprobar si en una población
compuesta por dos categorías de la que se extrae la muestra, 
la proporción de observaciones de una de las categorías es 
igual a un valor concreto. En nuestro contexto, consideramos 
$\theta$ la probabilidad del clasificador de cometer un error 
y queremos realizar una hipótesis sobre el valor de $\theta$. 
Supongamos que tenemos una muestra de tamaño $N$, 
$\{(x_i, y_i): i = 1, \dots,N \}$ con $y_i$ la categoría y
consideraremos la variable aleatoria $X$ que denota el número
de errores cometidos por el clasificador $f$,
	\[ 
		X = \sum\limits_{i=1}^N 
				\mathbb{I}[f(x_i) \neq y_i].
	\]
	
	El test a realizar consiste en si la probabilidad de 
cometer un error $\theta$ es igual a un valor $\theta_0$
dado: $H_0: \theta = \theta_0;\ H_1: \theta \neq \theta_0$.
La probabilidad de cometer $j$ errores de $N$ supuesta $H_0$
será $P[X = j] = {N \choose j} \theta^j (1-p)^{N-j}$. Se 
rechazará la hipótesis nula si la probabilidad de obtener un 
valor tan alejado o más de la hipótesis nula que el observado 
es menor que el valor $\alpha/2$ (al considerar la hipótesis 
alternativa no direccional).\\
	Cuando el tamaño de la muestra es grande el test 
estadístico para la binomial puede ser aproximado con la 
distribución $\chi^2$ con un grado de libertad. Hay varias 
opiniones con respecto al tamaño mínimo para realizar
esta aproximación. Se pueden tomar referencia que 
$N \theta_0$ y $N (1 - \theta_0)$ sean mayores que 5. El test 
estadístico para realizar estadístico para usar esta 
aproximación será:
	\[
		z = \frac{X/N - \theta_0}
				{\sqrt{\frac{\theta_0(1 - \theta_0)}
							{N}}}
	\]
	
\subsection{$t$-Test para muestras emparejadas}

	Nos ocupamos aquí de esta versión del $t$-test para 
muestras independientes emparejadas con varianzas 
desconocidas por tener una mayor relevancia en la evaluación 
de algoritmos de aprendizaje automático. Con este test se 
pretende conocer si dos muestras independientes representan
a dos poblaciones con diferentes medias. Para estimar el
valor de las medias de las poblaciones, notaremos por 
$\bar{X}_1, \bar{X}_2$ a las medias de las dos muestras. Las 
condiciones para realizar este test son:
	
	\begin{itemize}
	\item Cada muestra ha sido seleccionada aleatoriamente 
		de la población a la que representa.
	\item La distribución de los datos de las poblaciones de 
		las que se extraen las muestras son normales.
	\item Homogeneidad de las varianzas: La varianza de las 
		dos poblaciones son iguales ($\sigma_1 = \sigma_2$).
	\end{itemize}
	
	Nótese que si la varianza es conocida, es más apropiado 
usar el $z$-test.\\
	La hipótesis nula será por tanto $H_0: \mu_1 = \mu_2$.
El test se realiza utilizando el estadístico $t$:
\begin{align*}
	t 	= \frac{\bar{d}}
			{\frac{\bar{\sigma}_d}{\sqrt{N}}}
		= \frac{\bar{X}_1 - \bar{X}_2}
			{\frac{\bar{\sigma}_d}{\sqrt{N}}},
\end{align*}
	
	donde $N$ es el número de datos de la muestra, 
$\bar{X}_i,\ i=1,2$  es la media $\frac{1}{N}
\sum\limits_{j=1}^{N} X_{ij}$ de los  valores obtenidos en 
cada muestra, $\bar{d}$ es la diferencia de las medias y 
$\bar{\sigma}_d$ es el estimador para la desviación típica:
	\[
		\bar{\sigma}_d =
			\sqrt{
			\frac{\sum\limits_{i=1}^{N} (d_i - \bar{d})^2}
				{N - 1}
			}.
	\]
	
	El valor $t$ obtenido se comparará con el valor crítico
para la distribución $t$ de Student con $N - 1$ 
grados de libertad.\\
	Una versión más general de este test es el $t$-test de
Welch para muestras no emparejadas de tamaños $N_1, N_2$
cuyo estadístico es
	\[
		t = \frac{\bar{X}_1 - \bar{X}_2}
				{\sqrt{ \frac{\sigma_1^2}{N_1} +
						\frac{\sigma_2^2}{N_2}}},
	\]
	con $\sigma_i^2,\ i=1,2$ la varianza de la muestra.
	
\paragraph{Tamaño del efecto} El $t$-test determina si las 
diferencias observadas son significativas, pero no si 
estas diferencias tienen importancia práctica, es decir, 
se observa un efecto, una diferencia entre los 
clasificadores, pero no se cuantifica esta diferencia
(crítica que se le hace desde la estadística bayesiana,
como veremos). El tamaño del efecto para este test se
suele realizar con el estadístico $d$ de Cohen:
	\[
		d_{Cohen} = \frac{\bar{X_1}-\bar{X_2}}
					{\sigma_p},
	\]
	con $\sigma_p = \sqrt{\frac{\sigma_1^2 + \sigma_2^2}{2}}$
la media de las varianzas de las respectivas muestras.
La interpretación del estadístico propuesta por Cohen es:
	\begin{itemize}
	\item $d_{Cohen}$ en torno a $0.2, 0.3$ denota un 
		efecto pequeño, posiblemente significativo.
	\item $d_{Cohen}$ sobre $0.5$ significa un efecto medio,
		observable.
	\item $d_{Cohen}$ de $0.8$ significa un gran tamaño del 
		efecto.
	\end{itemize}
	
\subsubsection{5x2 CV $t$-test}
	
	En el capítulo siguiente (\ref{sssec:CV}), se describe el 
proceso de validación cruzada, especialmente útil cuando se
disponen de pocos datos y queremos mantener un equilibrio
entre el tamaño del conjunto de entrenamiento y el de test.
Para esta situación, se propone la siguiente variación 
del $t$-test. Se considera $d_i^{(j)}$, para $j=1,2$, $i=
1,\dots,5$, la diferencia entre el rendimiento de los dos
clasificadores para la repetición $i$ y el \textit{fold} $j$.
Se considera la media para cada repetición $\bar{d}_i = 
(d_i^{(1)} + d_i^{(2)})/2$ y la varianza estimada
$s_i^2 = (d_i^{(1)}-\bar{d_i})^2 + (d_i^{(2)}-\bar{d_i})^2$. 
Bajo la hipótesis nula de que los dos clasificadores tienen 
el mismo rendimiento, $d_i^{(j)}$ puede considerarse 
aproximadamente normal . Si suponemos $d_i^{(1)}$ y 
$d_i^{(2)}$ independientes y normales (lo cual no es
cierto porque los conjuntos de test y de entrenamiento
no se han obtenido de manera independiente), entonces
$s_i^2/\sigma^2$ sigue una distribución $\chi^2$ con un
grado de libertad. Si suponemos las $s_i^2$ independientes,
su suma $M = \frac{\sum\limits_{i=1}^5 s_i^2}{\sigma^2}
\sim \chi^2_5$ y 
\begin{equation}
	\label{eq:5x2CVt}
	t = \frac{d_1^{(1)}/\sigma}{\sqrt{M/5}} = 
		\frac{d_1^{(1)}}
			{\sqrt{\sum\limits_{i=1}^5 s_i^2/5}}
		\sim t_5.
\end{equation}

\paragraph{Modificación} Nótese que en la 
ecuación~\ref{eq:5x2CVt} el valor $d_1^{(1)}$ podría ser
ocupado por cualquier estadístico $d_i^{(j)}$. Alpaydin
propuso combinar estos valores de la forma:
	\[
		N = \frac{\sum\limits_{i=1}^5
				\sum\limits_{j=1}^2
					\left( d_i^{(j)} \right)^2}
				{\sigma^2}
			\sim \chi_{10}^2.
	\]
	Sustituyendo esto en \ref{eq:5x2CVt}, tenemos
un estadístico que es el radio de dos v.a. que siguen 
una $\chi^2$, con lo que definimos la v.a. $f$, que seguirá
una distribución $F$ de Snedecor con 10 y 5 grados de
libertad:
	\[ 
		f = \frac{N/10}{M/5} \sim F_{10,5}.
	\]
	
		
\subsection{Análisis de la varianza}

	Estos test resultan insuficientes a la hora de comparar 
múltiples clasificadores. Aunque se ha usado el $t$-test para 
realizar repetidas comparaciones entre distintos 
clasificadores, esto plantea el problema de que son 
necesarios numerosos test para realizar todas las 
combinaciones y por tanto la información que se obtiene es
más difícil de analizar. Otro problema asociado es el 
incremento de la probabilidad de cometer un error de tipo I. 
Presentamos en esta sección la versión paramétrica, ANOVA.\\
	En este test, al igual que en el $t$-test, la hipótesis 
hace referencia a las medias de las poblaciones de las que 
se extraen las muestras, sin embargo, la hipótesis nula es
	\[
		H_0 : \mu_1 = \mu_2 = \dots = \mu_k,
	\]
	frente a la hipótesis alternativa
	\[
		H_1 : \mu_r \neq \mu_s \text{ para algún par }
			(r, s), r \neq s 
	\]
	
	El test ANOVA puede tratar con tres tipos de varianzas
si los datos están clasificados en grupos (como es nuestro
caso, donde los datos se podrán agrupar bien por los errores
de todos los clasificadores en una base de datos, o bien por
los errores de un clasificador en todas las conjuntos de datos):
	\begin{enumerate}
	\item variación en un grupo,
	\item variación entre grupos, y
	\item variación total, como combinación de las 
		dos anteriores.
	\end{enumerate}

	Consideraremos para realizar este test que disponemos de 
$n$ conjuntos de datos y $k$ clasificadores. Notaremos por 
$X_{ij}$ el rendimiento del algoritmo $j$ para la base de 
datos $i$. Así, $\bar{\bar{X}}$ se refiere a la media entre 
todos los valores de los clasificadores para las bases de
datos; $\bar{X}_{i \cdot}$ la media para la base de datos $i$ 
y $\bar{X}_{\cdot j}$ la media del clasificador $f_j$.\\
	El modelo para el rendimiento de un clasificador en una 
base de datos es
	\[
		X_{ij} = \bar{\bar{X}} + \alpha_i + e_{ij},
	\]
	donde $\alpha_i$ es la variabilidad del rendimiento entre 
los distintos conjuntos de datos, que se supone con media 0 y
varianza $\sigma_A^2$ y $e_{ij}$ representa la variabilidad
dentro del propio conjunto de datos, que se supone con media 
0 y varianza $\sigma^2$. Además, se supone $e_{ij}$ 
independiente de $\alpha_i$ y de los demás $e_{ij}$.\\
	Definiremos en primer lugar algunas medidas de la 
variación, como la existente debida a los clasificadores
	\[ 
		SS_C = \sum\limits_{j=1}^k
				 \sum\limits_{i=1}^m
					\left( \bar{X}_{\cdot j} - 
						   \bar{\bar{X}} \right)^2 =
				n \sum\limits_{j=1}^k
					\left( \bar{X}_{\cdot j} - 
					  	   \bar{\bar{X}} \right)^2,
	\]
	de igual manera, la variación relativa a los conjuntos de
datos:
	\[ 
		SS_B = k \sum\limits_{i=1}^n
					\left( \bar{X}_{i \cdot} - 
					  	   \bar{\bar{X}} \right)^2.
	\]
	
	La variación total entre clasificadores se obtiene con
	\[
		SS_{Total} =  
			\sum\limits_{j=1}^k
				\sum\limits_{i=1}^m
					\left( \bar{X}_{ij} - 
						   \bar{\bar{X}} \right)^2.
	\]
			
	La variación en el error se deriva de la diferencia entre 
la variación total y la combinación de $SS_B$ y $SS_C$:
	\[
		SS_{Error} = SS_{Total} - (SS_B + SS_C).
	\]
	
	Definimos ahora los estadísticos a partir de los cuales 
realizaremos el test. En primer lugar, la variabilidad entre
clasificadores:
	\[
		MS_C = \frac{SS_C}{k-1},
	\]
	con $k-1$ el grado de libertad de $SS_C$. El segundo 
estadístico hace referencia a la variabilidad dentro de los 
clasificadores:
	\[
		MS_{Error} = \frac{SS_{Error}}{(n-1)(k-1)},
	\]
	con $(n-1)(k-1)$ los grados de libertad de $SS_{Error}$.
Finalmente, el estadístico con el que se lleva a cabo el
test, el cociente $F$ se obtiene como
	\[
		F = \frac{MS_C}{MS_{Error}},
	\]
	
	que sigue una distribución $F$ de Snedecor con $k-1$ y
$(n-1)(k-1)$ grados de libertad.

\paragraph{\textit{One-way} ANOVA} Se trata de un modelo más 
simple que no distingue entre la variabilidad dentro de los
conjuntos de datos y entre conjuntos de datos, sino que ambas
variabilidades se analizan de forma conjunta. En términos del
caso anterior, $X_{ij} = \bar{\bar{X}} + \alpha_i + e_{ij}$, 
con $\alpha_i = \bar{X}_{\cdot j} - \bar{\bar{X}}$ y $e_{ij}$
hace referencia al error aleatorio, que sigue una 
distribución normal, con media $0$ y varianza $\sigma^2$. \\
	Al calcular los estadísticos necesarios, tenemos que los 
grados de libertad de $SS_{Error} = SS_{Total} - SS_{C}$ son 
$nk-k$ y por consiguiente $MS_{Error} = \frac{SS_{Error}}
{nk-k}$. Este test asume la independencia entre las muestras
a diferencia del test ANOVA previo, donde la correlación de 
las muestras, esto es, el rendimiento de cada algoritmo para
el mismo conjunto de datos se tenía en cuenta. Además, este
test tiene una menor potencia.
	

\section{Test no paramétricos}

	Para poder comprender este concepto, definimos la familia 
no paramétrica de distribuciones según \cite{PESSAL10}, sobre 
la que se realizan los test no paramétricos. 
 
\begin{definicion}[Familia de distribuciones no paramétrica]
	Una familia de distribuciones $\mathcal{P}$ se dice que 
se comporta de manera no paramétrica cuando no es posible
encontrar un espacio de dimensión finita $\Theta$ tal que hay 
una relación uno a uno entre $\Theta$ y $\mathcal{P}$, en el 
sentido en que cada elemento $P \in \mathcal{P}$ no puede ser 
identificado por un único elemento $\theta \in \Theta$ y 
viceversa.
\end{definicion}

	Si existiese esta relación, $\mathcal{P}$ sería una 
familia paramétrica y $\theta$ sería el parámetro.\\
	En base a esta definición, consideraremos la inferencia 
estadística no paramétrica aquella que se realiza sobre una 
muestra suponiendo la pertenencia de ésta a una familia no 
paramétrica de distribuciones. Un concepto relacionado es la 
propiedad de ser libre de distribución:
	
\begin{definicion}[Libre de distribución]
	Decimos que un estadístico es libre de distribución si 
para $H_0$ cierta, la distribución del estadístico no depende 
de la distribución $F$ de la población. Este concepto se 
puede extender a intevalos de confianza. 
\end{definicion}
	
	\subsection{Comparación con test paramétricos}
	
	En la inferencia clásica se efectúan suposiciones sobre 
la población de la que se extraen muestras para realizar la 
inferencia. Aunque estas suposiciones están normalmente 
justificadas, en ocasiones no se dan las circunstancias 
necesarias para aplicar estas técnicas o su uso no está bien 
documentado. Por ello surgen las técnicas no paramétricas. 
Nótese que es distinta la suposición al aplicar estas 
técnicas no paramétricas, pues consideramos en este caso que 
no conocemos su distribución.\\
	
 	La principal ventaja de los test no paramétricos es que  
las hipótesis son más generales con lo que se pueden aplicar 
en un mayor número de problemas. Una de las condiciones 
habituales es la continuidad, aunque hay otras condiciones 
más estrictas como que la población sea simétrica para según 
qué test. Esto repercute en que se le pueden aplicar 
funciones a las muestras obtenidas para la realización de los 
test, a diferencia de en los test paramétricos dado que las 
muestras deben generalmente provenir de una población de 
forma conocida.\\
 	
	Hay test de hipótesis que no están relacionados con 
valores de parámetros (a diferencia de los paramétricos). Son 
más simples de aplicar, las matemáticas, menos sofisticadas y 
basadas en la combinatoria, están relacionadas con las 
propiedades usadas en el proceso inductivo. Los libros de 
recetas no son necesarios, pues con la mera definición del 
test queda suficientemente claro cómo aplicar el test no 
paramétrico. Además, las distribuciones asintóticas son 
distribuciones conocidas como la normal o la chi cuadrado. Al 
relajar las condiciones sobre los datos de entrada, es menos 
sensible al \textit{dirty-data}, datos con errores usados en 
el entrenamiento del clasificador. Esto implica una mayor 
robustez en los test no paramétricos.\\
 	
	Correctamente aplicados, los test paramétricos, al 
disponer de mayor información tienen una mayor potencia, sin 
embargo, cuando se disponen de menos datos, y por tanto es 
más difícil que se den las condiciones de los test 
paramétricos, la potencia es similar. Además, en esta 
situación, la falta de eficiencia de los test no paramétricos 
se suple con la falta de precisión de los test paramétricos 
al aproximar la distribución de los datos por la distribución 
asintótica conocida.


 	Se incluye en esta sección el desarrollo de los test no
paramétricos más utilizados en aprendizaje automático.
 	
 	
\subsection{Test de aleatoriedad}

	Una de las condiciones para la realización de los test 
estadísticos, tanto de los paramétricos como de los no 
paramétricos, es la aleatoriedad de la muestra de partida. La 
hipótesis nula para los test que serán presentados en esta 
sección será la aleatoriedad de la muestra, mientras que la 
hipótesis alternativa será la presencia de un patrón. Estos 
test también son útiles en los estudios de series temporales 
y control de calidad.
	
\subsubsection{Test basado en el número de rachas}

	Supongamos una secuencia de $n$ elementos de dos tipos, 
$n_1$ del primer tipo y $n_2$ del segundo, $n = n_1 + n_2$. 
Sea $R_1$ el número de rachas del primer tipo, $R_2$ el 
número de rachas del segundo tipo, $R = R_1 + R_2$. Siendo 
cierta la hipótesis nula (la aleatoriedad de la muestra), 
procedemos a obtener la distribución de $R$.
	
\begin{lema} 
	El número de formas distintas de distribuir $n$ objetos 
en $r$ posiciones consecutivas es ${n-1 \choose r-1}, n \geq 
r, r \geq 1$.
\end{lema}

\begin{teorema}
	Sean $R_1$ y $R_2$ los números de rachas de los $n_1$ de 
tipo 1 y los $n_2$ elementos de tipo 2 respectivamente en una 
muestra de tamaño $n = n_1 + n_2$. La función de distribución 
de probabilidad conjunta de $R_1$ y $R_2$ es
	\[ f_{R_1,R_2} (r_1, r_2) = 
		\frac{c {n_1 - 1 \choose r_1 - 1} 
				{n_2 - 1 \choose r_2 - 1}}
			{{n_1 + n_2 \choose n_1}}\;
		\begin{array}{l}
			r_1 = 1,2, \dots, n_1 \\
			r_2 = 1,2, \dots, n_2 \\
			r_1 = r_2 \text{ ó } r_1 = r_2 \pm 1
		\end{array}
	\]
	donde $c=2$ si $r_1 = r_2$ (hay igual número de rachas de 
elementos del tipo 1 y del tipo 2) y $c=1$ si $r_1 = 
r_2 \pm 1$ (hay una racha más del tipo 1 ó 2).
\end{teorema}

	Para muestras de un mayor tamaño (aquellas en el que 
$n_1, n_2 \geq 10$) se suele utilizar una aproximación 
utilizando la distribución asintótica supuesto cierta 
$H_0$.\\
	Suponemos que el tamaño de la muestra $n \rightarrow 
\infty$, de forma en que $\frac{n_1}{n} \rightarrow \lambda$, 
$0<\lambda<1$. De aquí obtenemos
	\[ \underset{n \rightarrow \infty}{\lim} E[R/n] = 
			2\lambda (1-\lambda) 
				\underset{n \rightarrow \infty}{\lim} 
					var(R\sqrt{n}) =
			4\lambda^2(1-\lambda)^2
	\]
	
\begin{teorema}
	La distribución de probabilidad de $R$, es decir, el 
número total de rachas en una muestra aleatoria es:
	
	\begin{equation}
		f_R(r) = \left\lbrace\begin{array}{ll}
	2 {n_1-1 \choose r/2-1} {n_2-1 \choose r/2-1} 
		\big/ {n_1 + n_2 \choose n_1} &
			\textit{ si } r \text{ es par} \\
	\left[
		{n_1-1 \choose (r-1)/2} {n_2-1 \choose (r-3)/2} +  
		{n_1-1 \choose (r-3)/2} {n_2-1 \choose (r-1)/2} 
	\right]
		\big/ {n_1 + n_2 \choose n_1} &
			\textit{ si } r \text{ es impar} \\		
		\end{array}\right.
	\label{th-dist-R}
	\end{equation}
	para $r=2, 3, \dots, n_1 + n_2.$
\end{teorema}
	
	Si llamamos $Z = \frac{R - 2n\lambda (1-\lambda)}
{2 \sqrt{n}\lambda (1-\lambda)}$ y sustituimos en 
\ref{th-dist-R}, obtenemos la distribución estandarizada de 
$R$, $f_Z(z)$. Entonces aplicamos la fórmula de Stirling y el 
límite queda de la forma
	\[ \underset{n \rightarrow \infty}{\lim} \log f_Z(z)=
			-\log \sqrt{2\pi} - \frac{1}{2} z^2,	\]
	con lo que la distribución límite de $Z$ es la normal. 
	
	
\subsubsection{Test basado en rachas crecientes y decrecientes}	

	Para este test consideramos una serie de datos de tipo 
numérico ordenados temporalmente y queremos comprobar la 
hipótesis de la aleatoriedad de la muestra.\\
	Para una muestra de $n$ elementos, supongamos que podemos 
ordenarlos de la forma $a_1 < \dots < a_n$ (estamos 
suponiendo que no hay dos iguales). Si la hipótesis nula fuese 
cierta, nuestra muestra se corresponderá con una de las $n!$ 
permutaciones con igual probabilidad. Usaremos para este test 
las rachas crecientes y decrecientes. Construimos la 
secuencia $D_{n-1}$, cuyo elemento $i$-ésimo es el signo de 
$x_{i+1} - x_i,\ i=1, \dots, n-1$. Sean $R_1, \dots, R_{n-1}$ 
el número de rachas de longitud $1, \dots, n-1$ 
respectivamente. $f_n(r_{n-1}, \dots, r_1)$ indica la 
probabilidad de obtener $r_j$ rachas de longitud $j$ supuesta 
cierta la hipótesis nula. Escribiremos como $u_n$ la 
frecuencia absoluta $f_n = \frac{u_n}{n!}$. Para obtener la 
función de distribución, partiremos del caso $n=3$.\\
	Sean $a_1 < a_2 < a_3$. La distribución de probabilidad 
será 
	\[ 
	f_3(r_2, r_1) = 
		\left\lbrace\begin{array}{cc}
			\frac{2}{6} & \text{si } r_2 = 1, r_1 = 0 \\
			\frac{4}{6} & \text{si } r_2 = 0, r_1 = 2 
		\end{array}\right.
	\]
	dado que las únicas rachas de longitud 2 son 
$(a_1, a_2, a_3) \rightarrow (+,+)$ y $(a_3, a_2, a_1)$ 
$\rightarrow (-,-)$, siendo las demás posibles combinaciones 
dos rachas de longitud 1.\\
	Las posibilidades a la hora de insertar un elemento $a_n$ 
en las permutaciones de $S_n$ son:
\begin{enumerate}
	\item Se añade una racha de longitud 1.
	\item Una racha de longitud $i-1$ se convierte en una 
		de longitud $i$, $i=2,\dots n-1$.
	\item Una racha de longitud $h=2i$ se convierte en una de 
		longitud $i$, seguida por otra de longitud $1$, 
		seguida por otra de longitud $i$.
	\item Una racha de longitud $h=i+j$ se convierte en
	\begin{enumerate}
		\item Una racha de longitud $i$ seguida por otra de 	
			longitud $1$ seguida por otra de longitud $j$,
		\item Una racha de longitud $j$ seguida por otra de 	
			longitud $1$ seguida por otra de longitud $i$,
	\end{enumerate}
		con $h>i>j$, $3 \leq h \leq n-2$.
\end{enumerate}

	De forma general, la frecuencia $u_n$ conocido $u_{n-1}$ 
sigue la siguiente relación:
\begin{align*}
	& u_n (r_{n-1}, \dots, r_h, \dots, r_i, \dots, r_j, 
			\dots, r_1)= 
		2 u_{n-1}(r_{n-2}, \dots, r_1-1) \\
	&+ \sum\limits_{i=2}^{n-1} 
		(r_{i-1} + 1)
		u_{n-1}(r_{n-2},\dots, r_i-1, r_{i-1}+1,\dots, r_1)\\
	&+ \sum\limits_{i=1, h=2i}^{\lfloor (n-2)/2 \rfloor} 
		(r_{h} + 1)
		u_{n-1}(r_{n-2},\dots, r_h+1,\dots r_i-2,
				\dots, r_1-1)\\
	&+ 2 \underbrace{\sum\limits_{i=2}^{n-3} 
		\sum\limits_{j=1}^{i-1}}_{h=i+j, h \leq n-2}
		(r_{h} + 1)
		u_{n-1}(r_{n-2},\dots, r_h+1,\dots, r_i-1,
				\dots, r_1-1)			
\end{align*}
	
	Otro test que se podría realizar es el del número total 
de rachas, independientemente de su longitud. El número de 
rachas total sería $R = \sum\limits_{i=1}^{n-1} R_i$. Usando 
el procedimiento anterior, se llega a que la distribución 
asintótica nula estandarizada con media $\mu = 
\frac{2n-1}{3}$ y varianza $\sigma^2=\frac{16n-29}{90}$ es la 
normal estándar.
	
\subsection{Test de bondad del ajuste}

	Una cuestión relevante en la estadística es la obtención 
de la forma de la población de la que se obtiene una muestra. 
En los test paramétricos, como se ha mencionado previamente, 
es habitual que la información relativa a la forma de la 
población se incluya entre las condiciones, por ejemplo en el 
test basado en la distribución $t$ de Student es necesaria la 
normalidad de la población. Por consiguiente, nos interesa 
disponer de test que nos indiquen cómo de confiable es la 
hipótesis de la normalidad para nuestra muestra. Los test de 
bondad del ajuste se ocupan de la forma de la población y no 
de la distribución concreta incluyendo parámetros de escala o 
localización.
	
\subsubsection{Chi cuadrado}

	Sea una muestra aleatoria de tamaño $n$ obtenida de una 
población con función de distribución desconocida $F_X$. El 
test tendrá como hipótesis nula
		\[ H_0: F_X(x) = F_0(x) \ \forall x \]
	con $F_0$ conocida contra
		\[ H_1: F_X(x) \neq F_0(x) \text{ para algún }  x \]
	Para realizar este test, los datos deben disponerse en
categorías, bien mediante los valores que toma la variable 
para distribuciones discretas o mediante rangos especificados 
al realizar el experimento para distribuciones continuas. Una 
vez realizadas estas categorías podemos obtener las 
frecuencia esperada si la hipótesis nula es cierta de 
$F_0(x)$.\\
	
	Supongamos que disponemos de $n$ muestras clasificadas en 
$k$ categorías mutuamente excluyentes. Sea $f_i$ la 
frecuencia observada y $e_i$ la frecuencia esperada para cada 
muestra. El estadístico que definimos para la realización de 
este test es $Q = \sum\limits_{i=1}^k 
\frac{(f_i-e_i)^2}{e_i}$, para el cual estudiaremos su 
distribución asintótica.\\
	
	Sean $\theta_1, \dots, \theta_k$ las probabilidades de 
pertenencia a cada clase y $f_1, \dots, f_k$ los valores 
observados. La función de verosimilitud será:
	
	\[ L(\theta_1, \dots, \theta_k) = 
			\prod\limits_{i=1}^k \theta_i^{f_i},\			
	   \text{ con } f_i = 0, 1, \dots, n; \
	   \sum\limits_{i=1}^k \theta_i = 1, \
	   \sum\limits_{i=1}^k f_i = n
	 \]
	 
	Podemos por tanto escribir la hipótesis nula de la 
siguiente forma:
	 
	\[ H_0 = \theta_i = \theta_i^0,\ i = 1, \dots, k \]
	 
	habiendo obtenido cada $\theta_i^0$ de $F_0$. El 
estimador de máxima verosimilitud es $\hat{\theta}_i = 
\frac{f_i}{n}$. Entonces el ratio de verosimilitud es
	 
	 \[ 
	 T = \frac{L(\hat{\omega})}{L(\hat{\Omega})}
	   = \frac{L(\theta_1^0, \dots, \theta_k^0)}
	   		{L(\hat{\theta}_1^0, \dots, \hat{\theta}_k^0)}
	   = \prod\limits_{i=1}^k
	   		\left( 
	 			\frac{\theta_i^0}{\hat{\theta_i}} 
	 		\right)^{f_i}
	 \]
	 
	 y la distribución de la v.a. $-2 \log T$ puede ser 
aproximada por la distribución chi cuadrado. Debido a que 
estimamos $k-1$ parámetros (el parámetro restante se deduce 
de la restricción $\sum\limits_{i=1}^k \theta_i = 1$). 
Tenemos entonces
	 \begin{equation}
	 2 \log T = 
	 		-2 \sum\limits_{i=1}^k
	 			f_i \left(
	 					\log \theta_i^0 - \log \frac{f_i}{n}
	 				\right)
	 \label{2logT}
	 \end{equation}
	y mostramos a continuación que esta expresión es 
equivalente asintóticamente a la expresión de $Q$.\\
	
	La serie de Taylor de $\log \theta_i$ centrada en 
$\hat{\theta}_i = f_i/n$ es
	\[ \log \theta_i = 
			\log \hat{\theta}_i +
			(\theta_i - \hat{\theta}_i)
				\frac{1}{\hat{\theta}_i} +
			\frac{(\theta_i - \hat{\theta}_i)^2}{2!}
				\left(-\frac{1}{\hat{\theta}_i^2}\right) +
			\dots
	\]
	
	con lo que
	
	\begin{align*}	
	 \log \theta_i^0 - \log \frac{f_i}{n} & = 
			\left(
				\theta_i^0 - \frac{f_i}{n}
			\right) \frac{n}{f_i} -
			\left(
				\theta_i^0 - \frac{f_i}{n}
			\right)^2 \frac{n^2}{2f_i^2} + \epsilon \\
		&= \frac{n\theta_i^0 - f_i}{f_i} -
			\frac{(n\theta_i^0 - f_i)^2}{2f_i^2} +\epsilon
	\end{align*}
	
	con $\epsilon = \sum\limits_{j=3}^\infty
			(-1)^{j+1} 
			\left( \theta_i^0 - \frac{f_i}{n}\right)^j
			\frac{n^j}{j!f_i^j}$. Sustituyendo en \ref{2logT} 
nos queda
			
	\begin{align*}
	-2 \log T &= 
		-2 \sum\limits_{i=1}^k n\theta_i^0 - f_i -
		\sum\limits_{i=1}^k 
			\frac{(n\theta_i^0 - f_i)^2}{f_i} + 
		\sum\limits_{i=1}^k \epsilon' = \\
	&= 0 + 
	   \sum\limits_{i=1}^k \frac{(f_i-e_i)^2}{f_i} +
	   \epsilon''	
	\end{align*}	 
	
	Por la ley de los grandes números, $F_i/n$ es un 
estimador consistente de $\theta_i$, es decir
	
	\[ \lim_{n \rightarrow \infty} \left[
			P \left(
				\abs{ \frac{F_i}{n} - \theta_i } 
					> \varepsilon
			\right) \right] = 0 \; \forall \varepsilon > 0 \]
	
	\subsubsection{Kolmogorov-Smirnov}
	
	En el test anterior sólo se realizaban $k$ comparaciones 
a pesar de disponer de $n$ ($n \geq k$) observaciones. Si las 
$n$ muestras provienen de una distribución continua, 
podríamos realizar la comparación entre la función de 
distribución que constituye la hipótesis nula y la 
\textbf{función de distribución empírica} (edf) $S_n$ 
definida de la siguiente forma:
	\[ S_n(x) = \frac{\text{número de muestras} \leq x}{n} \]
	Para una definición formal introducimos notación sobre 
estadísticos ordinales. Sea $X_1, \dots, X_n$ una muestra 
aleatoria de una población con función de distribución 
continua $F_X$. Sea $X_{(1)}$ el menor valor de $X_1, \dots, 
X_n; X_{(2)}$ el segundo menor;$ \dots; X_{(n)}$ el mayor. 
Entonces se puede definir $S_n(x)$ como:
	\[ S_n(x) = 
		\left\lbrace\begin{array}{ll}
			0 & \text{si } x < X_{(1)} \\
			i/n & \text{si } X_{(i)} < x <X_{(i+1)},
				i = 1, \dots, n-1 \\
			1 & \text{si } x > X_{(n)} \\
	\end{array}\right.
	\]
	
	$S_n(x)$ es un estimador consistente para $F_X(x)$ y 
conforme $n$ crece, se aproxima a $F_X(x)$ para todo $x$. 
Entonces cabe esperar que el error vaya disminuyendo. Se 
define el estadístico
	\[ D_n = \underset{x}{\sup} 
				\vert S_n(x) - F_0(x) \vert, \]
	que si la hipótesis nula es cierta es un buen indicador 
de la precisión de la estimación. El estadístico $D_n$ es 
especialmente útil en la inferencia no paramétrica debido a 
que la distribución de $D_n$ no depende de $F_0(x)$ mientras 
sea continua. Se definen las desviaciones direccionales
	\[ D_n^+ = \underset{x}{\sup} [S_n(x) - F_0(x)]
		D_n^- = \underset{x}{\sup} [F_0(x) - S_n(x)]\]
	
\begin{teorema}
	Los estadísticos $D_n, D_n^+$ y $D_n^-$ son libres de 
distribución para cualquier función de distribución continua
$F_0$.
\end{teorema}
	
\begin{teorema}
	Si $F_X$ es una función de distribución continua, 
entonces para cada $d>0$
	\[ \underset{n \rightarrow \infty}{lim}
			P(D_n \leq d/\sqrt{n}) = L(d) \]
	con
	\[ L(d) = 1 - 2 \sum\limits_{i=1}^\infty 
			(-1)^{i-1} e^{-2i^2d^2}	\]
\end{teorema}

\begin{teorema}
	Si $F_0$ es una función de distribución continua, 
entonces bajo $H_0$ para cada $d>0$
	\[ \underset{n \rightarrow \infty}{lim}
			P(D_n^+ < d/\sqrt{n}) = 1-e^{-2d^2} \]
\end{teorema}	
	Como consecuencia de este teorema podemos usar las tablas
de la distribución chi cuadrado:
	
\begin{corolario}
	Si $F_0$ es una función de distribución continua, 
entonces para cada $d \geq 0$, la distribución límite de 
$V = 4n {D_n^+}^2$ para $n \rightarrow \infty$ es la 
distribución chi cuadrado con dos grados de libertad.
\end{corolario}	
	
\subsection{Análisis del conteo de datos}
	
	A la hora de comparar el rendimiento de algoritmos, una 
primer enfoque puede ser contar el número de casos en los que 
un algoritmo acierta y otro no. Para representar los datos 
necesarios para este tipo de test, se utiliza una matriz de 
contingencia $r \times k$, donde cada posición se corresponde 
con el número de muestras observadas que cumple las 
características de la fila y la columna.
	
\subsubsection{Test de McNemar}
	
	En este test suponemos una tabla $2 \times 2$ que recoge 
la respuesta de $n$ elementos ante una cierta prueba antes y 
después de un tratamiento o, en el caso en el que estamos, si 
los $n$ individuos de la muestra están bien o mal 
clasificados por dos algoritmos de clasificación.
	
\begin{table}[]
\centering
\caption{Tabla de contingencia de McNemar}
\label{Tb:McNemar}
\begin{tabular}{|lc|cc|}
\hline
                                                          &       & \multicolumn{2}{c|}{Clasificador $f_2$} \\ \cline{3-4} 
                                                          &         & Fallo              & Acierto            \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{Clasificador $f_1$}} & Fallo   & $c_{00}$           & $c_{01}$           \\
\multicolumn{1}{|c|}{}                                    & Acierto & $c_{10}$           & $c_{11}$           \\ \hline
\end{tabular}
\end{table}

	En este test la hipótesis nula es que la probabilidad de 
que un individuo sea bien clasificado es la misma para ambos 
algoritmos. Notamos por $\theta_{ij},\ i=0,1,\ j=0,1$ la 
probabilidad de pertenecer a cada grupo. Notamos 
$\theta_{1 \cdot} = \theta_{10} + \theta_{11}$, 
$\theta_{\cdot 1} = \theta_{01} + \theta_{11}$, la 
probabilidad de estar bien clasificado por el primer y el 
segundo clasificador respectivamente. La hipótesis nula se 
escribe entonces como $H_0: \theta_{1 \cdot} = 
\theta_{\cdot 1}$, para la cual se considera el estadístico 
basado en $T = \frac{c_{1 \cdot} - c_{\cdot 1}}{N}$ como 
estimador insesgado. Podemos escribir $T = \frac{c_{01} - 
c_{10}}{N}$. El test de McNemar está basado en
	\[ \frac{(c_{01} - c_{10})^2}{(c_{01} + c_{10})} \]
	que sigue aproximadamente una distribución $\chi^2$ con 
un grado de libertad. Obtengamos ahora la esperanza y 
varianza de $T$. Puesto que $c_{01}$ y $c_{10}$ siguen una 
distribución binomial con parámetros $n$, $\theta_{01}$ y 
$\theta_{10}$ respectivamente, obtenemos

\begin{align*}
	E[c_{01}] 	&= n \theta_{01} \\
	var(c_{01}) &= n \theta_{01} (1 - \theta_{01}) \\
	E[c_{10}] 	&= n \theta_{10} \\
	var(c_{10}) &= n \theta_{10} (1 - \theta_{10}).
\end{align*}

	La varianza de $T$ se puede ver obtener de 
	
\begin{equation}
	N^2 var(T) = var(c_{01}) + var(c_{10}) - 2 cov(X_{01}, c_{10}).
	\label{eq:McNemarVar}
\end{equation}

	Para el término de la covarianza podemos usar que la 
distribución de $(c_{00}, c_{01}, c_{10}, c_{11})$ es una 
distribución multinomial con probabilidades $(\theta_{00}, 
\theta_{01}, \theta_{10}, \theta_{11})$. Entonces, haciendo 
uso de la función generadora de momentos de $c_{01}$ y 
$c_{10}$,
	\[ 
		mgf(t_1, t_2) = 
		\left(
			\theta_{01} e^{t_1} + 
			\theta_{10} e^{t_2} + 
			[ 1 - (\theta_{01} + \theta_{10})] \right)^n,
	\]
	
	obtenemos $E[c_{01}c_{10}] = \frac{\partial^2 }
{\partial t_1 \partial t_2} mgf(0,0) = n(n-1)\theta_{01} 
\theta_{10}$ y por tanto escribimos la covarianza como:
	\[
		cov( c_{01}, c_{10} ) =
			n (n-1) \theta_{01} \theta_{10} -
			(n \theta_{01}) (n \theta_{10}) = 
			- n \theta_{01} \theta_{10}.
	\]
	
	Sustituyendo en \ref{eq:McNemarVar}, tenemos que $T$ 
tiene media $\theta_{01}-\theta_{10}$ y $var(T) = 
\frac{(\theta_{01} + \theta_{10}) - (\theta_{01} - 
\theta_{10})^2 }{n}$. Bajo la hipótesis nula $\theta_{01} = 
\theta_{10}$, $E[T] = 0$ y $var(T) = \frac{\theta_{01}+
\theta_{10}}{n}$, que se puede estimar de manera consistente 
del estadístico $(c_{01} + c_{10})/n^2$.\\
	Otro enfoque es observar el número de parejas 
discordantes $S = c_{01} + c_{10}$. Entonces $c_{01}$ sigue 
una binomial con parámetros $S$ y $\frac{\theta_{01}}
{\theta_{01}+\theta_{10}}$. Es posible que estemos 
interesados en una alternativa unilateral, esto es $H_1: 
\theta_{\cdot 1} > \theta_{1 \cdot}$, en la que la hipótesis 
alternativa supone que un algoritmo de clasificación es mejor 
que otro. Para esta alternativa el $p$-valor exacto viene 
dado por $\sum\limits_{j=0}^S {S \choose j}(0.5)^S$. Para 
muestras de un gran tamaño, podemos obtener un $p$-valor 
aproximado basándonos en $Z = \frac{c_{01} - c_{10}}
{\sqrt{c_{01} + c_{01}}}$, que sigue aproximadamente una 
distribución normal estándar.
	
\subsection{Test basados en una muestra y en muestras emparejadas}
	
	En este apartado presentaremos los test no paramétricos 
análogos a test paramétricos como el test $t$ de Student para 
las hipótesis nulas $H_0: \mu = \mu_0$ para una única muestra 
y $H_0: \mu_X - \mu_Y = \mu_0$ para muestras emparejadas. En 
los test no paramétricos sólo serán necesarias condiciones 
sobre la continuidad de la población. 
	
\subsubsection{Test de signo}

	Supongamos una muestra de $n$ elementos de una población 
$F_X$ con mediana desconocida $M$, donde suponemos que $F_X$ 
es continua y estrictamente creciente al menos en el entorno 
de $M$. Esto significa que $F_X^{-1}(0.5) = M$. La hipótesis 
nula a comprobar se corresponde con el valor de la mediana:

	\[ H_0: M = M_0	\text{ o equivalentemente }
			\theta = P(X > M_0) = 0.5 \]
	con $M_0$ un valor dado. Como hemos supuesto que $F_X$ 
tiene una única mediana, la hipótesis significa que $M_0$ 
divide el área de la función de densidad en dos partes 
iguales. Denotamos por $K$ el número de observaciones mayores 
que $M_0$. Podemos considerar entonces que estamos obteniendo 
una muestra de una v.a. $K$ que sigue una distribución de 
Bernouilli con parámetros $n$ y $\theta=P(X>M_0)$, y 
$\theta=0.5$ si la hipótesis nula es cierta. Se llama test de 
signo debido a que $K$ es el número de signos positivos en 
$X_i - M_0, i = 1, \dots, n$. La hipótesis alternativa queda 
por tanto
	\[ H_1: M \neq M_0	\text{ ó }
			\theta = P(X > M_0) \neq 0.5 \]
	La región crítica, para $\alpha$ el nivel de 
significación, es $K \geq k_{\alpha/2}$ ó $K \leq 
k_{\alpha/2}'$, con $k_{\alpha/2}$ y $k_{\alpha/2}'$ el menor 
y el mayor entero respectivamente tales que
	\[ \sum\limits_{i=k_{alpha/2}}^n
			{n \choose i}(0.5)^n \leq \frac{\alpha}{2}
		\text{ y }
		\sum\limits_{i=0}^{k_{alpha/2}'}
			{n \choose i}(0.5)^n \leq \frac{\alpha}{2}
	\]

\subsubsection{\textit{Signed-Rank test} de Wilcoxon}

	El test anterior usa únicamente el signo de la diferencia 
de la muestra a la mediana, sin considerar la distancia. Para 
este test sí consideramos la distancia a la mediana aunque 
necesitamos suponer la simetría de la población. \\
	Sea $X_1, \dots, X_n$ una muestra de una función de 
distribución continua $F$ con mediana $M$. De ser cierta la 
hipótesis nula $H_0: M = M_0$ las diferencias $D_i = X_i - 
M_0$ estarían distribuidas de manera simétrica en torno 
a 0.\\
	Supongamos que ordenamos las diferencias absolutas 
$|D_1|, \dots, |D_n|$ del valor absoluto más pequeño al más 
grande y le asignamos los puestos $1, 2, \dots, n$. Sea $T^+$ 
el valor esperado de la suma de los puestos con diferencias 
positivas, $T^-$ la de aquellos con diferencias negativas. 
Supuesta cierta la hipótesis nula, al ser la población 
simétrica, $T^+ = T^-$. Para realizar el test, notaremos por
$r(\cdot)$ la función que asigna el puesto de la v.a.. 
Definimos
	\[ T^+ = \sum\limits_{i=1}^n Z_i r(|D_i|); \quad
	   T^- = \sum\limits_{i=1}^n (1-Z_i) r(|D_i|) \]
	   
	 con $ Z_i = \mathbb{I}[ D_i > 0 ]$. Entonces,
	 		
	\[ T^+  - T^- = 2 \sum\limits_{i=1}^n
					 Z_i r(|D_i|) - \frac{N(N+1)}{2} \]
	
	Bajo la hipótesis nula, $Z_i$ sigue una distribución de 
Bernouilli con $E(Z_i) = 1/2$ y $var(Z_i) = 1/4$. Usando que 
$T^+$ es una combinación lineal de las variables $Z_i$, 
tenemos
	\[ E[ T^+ | H_0 ] = \sum\limits_{i=1}^n 
						\frac{r(|D_i|)}{2} 
					= \frac{n(n+1)}{4}			\]
	y
	
	\[ var( T^+ | H_0 ) = \sum\limits_{i=1}^n 
						\frac{[r(|D_i|)]^2}{4} 
					= \frac{n(n+1)(2n+1)}{24}	\]
					
	Para la aplicación de este test se obtiene el estadístico 
$T = \min \{ T^+, T^- \}$. En la tabla de los valores 
críticos de $T$ para el test \textit{signed-rank} de Wilcoxon 
\cite[Tabla A5]{SHESKIN11} se encuentran aquellos valores 
para nivel de significación 0.05 y 0.01 para los cuales 
debemos rechazar la hipótesis nula si $T$ es menor que el 
valor correspondiente en la tabla.\\
	
\paragraph{Valores iguales a la mediana} En este test se han 
considerado los valores iguales a la mediana como negativos. 
Como las diferencias con la mediana están ordenadas de manera 
creciente, estos valores estarán necesariamente al principio 
y el impacto será menor. Sin embargo, podemos considerar la 
siguiente modificación,

	\[ Z_i = \left\lbrace \begin{array}{ll}
	 				1 & \text{si } D_i > 0 \\
	 				0 & \text{si } D_i < 0 \\
	 				1/2 & \text{si } D_i = 0 
	 		\end{array} \right. 					\]
	
	para repartir así entre $T^+$ y $T^-$ estas puntuaciones. 
	
\subsubsection{Tratamiento de empates}
	
	Al realizar la suposición de que la muestra se obtiene de 
una población continua, la probabilidad teórica de obtener 
dos valores idénticos es nula. Sin embargo en la práctica 
podemos obtener empates debido a que la población sea 
discreta o limitaciones en la precisión. Presentamos a 
continuación algunos métodos para solventar esta situación:
	
\paragraph{Aleatorización} Se selecciona un orden aleatorio 
para los elementos con igual valor.

\paragraph{\textit{Midranks}} Asigna a cada individuo de un 
grupo de valores empatados la media de los puestos de la 
clasificación que tendrían de ser distintos. Es decir, si hay 
tres valores con la tercera menor distancia a la mediana, 
ocuparían los puestos 3,4 y 5 y por tanto el valor asignado a 
cada uno de ellos sería $\frac{3+4+5}{3}=4$. Es el método más 
utilizado debido a su simplicidad. 

\paragraph{Estadístico medio} Se realiza el test estadístico 
para todas las posibles asignaciones para los términos 
empatados y se realiza la media de estos test.

\paragraph{Estadístico menos favorable} Habiendo encontrado 
todos los posibles valores del test, se escoge aquel con 
menor probabilidad de rechazar la hipótesis nula. Es la 
opción más conservadora al minimizar la probabilidad de 
cometer un error de tipo I.

\paragraph{Rango de probabilidad} Se devuelve el valor menos 
favorable a rechazar la hipótesis nula y el más favorable. No 
conduce a una única decisión a no ser que ambos valores 
caigan en la región crítica o fuera de ella.

\paragraph{Omisión de los valores empatados} Otra posibilidad 
es descartar los valores empatados. Conlleva una pérdida de 
información y generalmente introduce un sesgo hacia rechazar 
la hipótesis nula.

	
\subsection{Medidas de asociación en clasificaciones múltiples}	

	En este apartado presentamos la versión no paramétrica 
para el problema del análisis de la varianza. Enfocado al 
problema abordado en este trabajo, nos será muy útil para 
comparar el rendimiento de varios algoritmos en distintas 
conjuntos de datos. Los datos se presentan en una tabla $n \times 
k$ con entradas $X_{ij}$. En esta distribución influyen dos 
factores que llamaremos el efecto por filas y por columnas.\\
	Para nuestro problema, consideraremos que las filas se 
corresponden con conjuntos de datos y que las columnas 
constituyen los algoritmos utilizados. Un enfoque similar 
sería considerar cada fila una porción de tierra y cada 
columna un tratamiento distinto aplicado a un cultivo.
	
\subsubsection{Análisis bidimensional de la varianza mediante clasificaciones en una tabla $k \times n$ y comparaciones múltiples de Friedman}

	Partimos de una matriz $n \times k$. Consideraremos que 
las filas son independientes, pero no las columnas (en 
nuestro problema esto significa que las conjuntos de datos sí 
son independientes pero cada algoritmo los resultados guardan 
correlación). Friedman sugirió cambiar cada valor de la 
matriz por la clasificación de cada fila.
	
	\[ \left( \begin{matrix}
		R_{11} & R_{12} & \dots & R_{1k} \\
		\vdots & \vdots & \ddots & \vdots \\
		R_{n1} & R_{k2} & \dots & R_{nk}
		\end{matrix} \right)	\]

	Entonces, $R_{i1}, \dots, R_{ik}$ es una permutación de 
los $k$ primeros números (salvo en caso de empate). 
Escribimos como $R_j$ el total para la columna $j$. 
Consideraremos la distribución de la muestra de la v.a. 
	\begin{equation}
		 S = \sum\limits_{j=1}^k
				\left[
					R_j - \frac{n(k+1)}{2}
				\right]^2 =
			\sum\limits_{j=1}^k \left[
				\sum\limits_{i=1}^n \left(
					R_{ij} - \frac{k+1}{2}
				\right)
			\right]^2
	\label{S-Friedman}
	\end{equation}
	
	bajo la hipótesis nula $H_0: \theta_1 = \dots = 
\theta_k$. En el caso de que no hubiera empates por filas 
habría un total de $(k!)^n$ posibles entradas igualmente 
probables. Las posibilidades se pueden enumerar y calcular el 
valor de $S$ para cada una de ellas, con lo que la 
distribución de probabilidad de $S$ sería $f_S(s) = 
\frac{u_s}{(k!)^n}$, con $u_s$ el número de asignaciones que 
tienen como suma de los cuadrados de las desviaciones totales 
por columnas $s$. Existe un método para obtener $u_s$ de $k$ 
y $n$ a partir de $k$ y $n-1$, y tablas con valores. Para los 
valores que exceden estas tablas se usa una aproximación de 
la distribución.\\
	Notando $\mu = \frac{k+1}{2}$, escribimos 
	\ref{S-Friedman}:
	
	\begin{align}
		S 	&= 	\sum\limits_{j=1}^k
					\sum\limits_{i=1}^n (R_{ij}-\mu)^2
				+ 2 \sum\limits_{j=1}^k
					\sum\limits_{i=1}^{n-1}
						\sum\limits_{p=i+1}^n
							(R_{ij}-\mu)(R_{pj}-\mu) 
				\nonumber \\
			&=	k \sum\limits_{j=1}^n (j-\mu)^2 + 2U 
				\nonumber \\
			&=  \frac{nk(k^2-1)}{12} + 2U	
	\label{S-Friedman2}
	\end{align}
	
	Los momentos de $S$ vienen determinados por los momentos 
de $U$, que se derivan de:
	\[ 	E[ R_{ij} ]= \frac{k+1}{2};\ 
		\var(R_{ij})=\frac{k^2-1}{12};\
		\cov(R_{ij},R_{iq}) = -\frac{k^2-1}{12}
	\]
	
	Además, dado que las observaciones en las diferentes 
filas son independientes, para $i \neq p$, la esperanza del 
producto de funciones de $R_{ij}$ y $R_{pq}$ estará 
multiplicado por $\cov(R_{ij},R_{pq})=0$. Entonces
	\[ E(U) = k {n \choose 2} \cov(R_{ij},R_{pq})=0, \] 
	con lo que $var(U) = kE(U^2)$, con
	\begin{align*}
		U^2 =& \sum\limits_{j=1}^k
				\sum\limits_{1 \leq i < p \leq n}
					(R_{ij} - \mu)^2 (R_{pj} - \mu)^2 \\
			+& 2 
			    \sum\limits_{j=1}^{k-1}
			      \sum\limits_{q=j+1}^k
					\sum\limits_{i=1}^{n-1}
					  \sum\limits_{p=i+1}^n	
					  	\sum\limits_{r=1}^{n-1}
						  \sum\limits_{s=r+1}^n
				(R_{ij} - \mu)(R_{pj} - \mu)
				(R_{rq} - \mu)(R_{sq} - \mu)	
	\end{align*}
	
	Como $R_{ij}$ y $R_{pq}$ son independientes para $i \neq p$, tenemos
	\begin{align*}
		E[U^2] =& \sum\limits_{j=1}^k
					\sum\limits_{1 \leq i < p \leq n}
						var(R_{ij})var(R_{pj}) \\
			 &+ 2 
			    \sum\limits_{j=1}^{k-1}
			      \sum\limits_{q=j+1}^n
			    {n \choose 2}
				\cov(R_{ij}, R_{iq}) \cov(R_{pj}, R_{pq}) \\
			=& k {n \choose 2} \frac{(k^2-1)^2}{144} +
				2{k \choose 2}{n \choose 2} 
					\frac{(k^2+1)^2}{144} \\
			=& k^2 {n \choose 2} (k+1)^2 \frac{k-1}{144}
	\end{align*}	
	
	Sustituyendo en \ref{S-Friedman2} llegamos a 
	
	\[ E[S] = \frac{nk(k^2-1)}{12}; \ 
		\var(S)= \frac{k^2n(n-1)(k+1)^2}{72} .\]
	
	Podemos definir la transformación
	
	\[ \chi^2_F = \frac{12S}{nk(k+1)} = 
	\frac{12 \sum\limits_{j=1}^k R_j^2}{nk(k+1)} -3n(k+1) .
	\]
	
	que tiene $E[\chi^2_F] = k-1$, $\var(\chi^2_F)= 2(k-1)
\frac{n-1}{n} \approx 2(k-1)$, que son los dos primeros 
momentos de la distribución $\chi^2_{k-1}$. También los 
momentos de mayor orden de $\chi^2_F$ se aproximan a los 
momentos de mayor orden de $\chi^2_{k-1}$ para $n$ grande. A 
efectos prácticos, podemos tratar $\chi^2_F$ como una $
\chi^2_{k-1}$ para $n>7$ ó $n>10, k>5$. La región crítica 
para la hipótesis nula mencionada con nivel de significación 
$\alpha$ es
	\[ 
		\chi^2_F \in R \ \text{ para } 
			Q \geq \chi_{k-1,\alpha}^2 .
	\]
	
\paragraph{Propuesta de Iman-Davenport} Sin embargo, este
test es demasiado conservador, por lo que Iman y Davenport
propusieron el estadístico
	\[
		F_F = \frac{(n-1)Q}{n(k-1) - Q},
	\]
	que sigue una distribución $F$ de Snedecor con $k-1$ y
$(k-1)(n-1)$ grados de libertad.
	
	
\subsubsection{Test de Friedman AR}
	Este test basado en el test de Friedman se propone como
solución a la hora de comparar un número pequeño de 
algoritmos para tener en cuenta el rendimiento no sólo 
para cada conjunto de datos sino entre ellos.\\
	
\begin{algorithm}
	\caption{Cálculo del estadístico de Friedman-AR}
	\label{alg:Friedman-AR}
	\begin{algorithmic}[1]
	\REQUIRE $x_{ij}$, medida del rendimiento del
			algoritmo $j$ en el conjunto $i$.
	\STATE Se calcula la media del rendimiento de los 
		algoritmos para cada conjunto de datos, 
		$\bar{x}_{i \cdot}$
	\FOR {$ x_{ij}:\ i=1,\dots, n,\ j=1,\dots,k$}
		\STATE Observación alineada: $\leftarrow$
			Diferencia entre $x_{ij}$ y $\bar{x}_{i \cdot}$.	
	\ENDFOR
	\STATE Se ordenan de $1$ a $kn$ las observaciones 
		alineadas $R_{ij}$.
	\STATE Se calculan los totales de estos ránquines
		por algoritmo $\hat{R}_{\cdot j}$ y por
		conjunto de datos $\hat{R}_{i \cdot}$.
	\end{algorithmic}
\end{algorithm} 

	Entonces, se calcula el estadístico 

	\[
		T = \frac{(k-1)
				\left[
					\sum\limits_{j=1}^k
						\hat{R}_{\cdot j}^2 -
					kn^2(kn+1)^2/4
				\right]}
				{[kn(kn+1)(2kn+1)/6] 
				 - (1/k) \sum\limits_{i=1}^n 
				 			\hat{R}_{i \cdot}^2},
	\]
	
	que sigue una distribución $\chi^2_{k-1}$.
	
\subsubsection{Test de Quade}

	El test de Friedman considera todos los conjuntos de 
datos iguales en cuanto a importancia. Se propone la 
siguiente modificación modificando el peso en base a las
diferencias entre los rendimientos en cada base de datos.\\
	Para ello, se considera el rango de cada conjunto,
	\[ rango_i = \underset{j}{\max} \{x_{ij}\} - 
				 \underset{j}{\min} \{x_{ij}\},
	\]
	
	y se clasifican los rangos de menor a mayor, notando por 
$Q_i$ al puesto ocupado por el conjunto de datos $i$.
Entonces se multiplica $Q_i$ por la diferencia entre el 
ránquin dentro del conjunto $i$ ($R_{ij}$ y el puesto medio,
$\frac{k+1}{2}$:
	\[ 
		S_{ij} = Q_i 
				\left( R_{ij} - \frac{k+1}{2} \right).
	\]
	Denotamos por $S_j = \sum\limits_{i=1}^n S_{ij}$ y
calculamos los términos
\begin{align*}
		A_2 &= \frac{kn(n+1)(2n+1)(k+1)(k-1)}{72},\\
		B &= \frac{1}{n} \sum\limits_{j=1}^k S_j^2.
\end{align*}

	Finalmente, obtenemos el estadístico
	\[
		T_3 = \frac{(n-1)B}{A_2 - B}
	\]
	que sigue una distribución $F$ de Snedecor con $k-1$ y
$(k-1)(n-1)$.
	

\subsubsection{Procedimientos \textit{post-hoc}}

	Una vez se ha descartado la hipótesis nula de 
la equivalencia entre los clasificadores, se pretende
identificar dónde se producen las diferencias. Para ello,
no se considera una única hipótesis sino una familia 
de ellas consistentes en la igualdad del rendimiento entre 
algoritmos y pretendemos rechazarlas o no sin tener que ir 
una por una.\\
	Si consideramos la comparación de $k$ algoritmos con 
nivel de significación $\alpha$, la probabilidad de no 
cometer un error de tipo I es $1-\alpha$, y entonces la 
probabilidad de no cometerlo en las $k-1$ comparaciones es
$(1-\alpha)^{k-1}$. Así pues, la probabilidad de cometer un
error de tipo I es $1-(1-\alpha)^{k-1}$, lo que aumenta 
la probabilidad de cometer un error cuando crece el número 
de algoritmos a comparar. Para ello, la solución es 
ajustar los $p$-valores (\textit{Adjusted $p$-values}, APV), 
y realizar las comparaciones con $\alpha$. Se describen a continuación algunos procedimientos para ajustar los 
$p$-valores y los valores de $\alpha$:

\begin{itemize}
\item Procedimientos de un paso.
	\begin{description} 
	\item[Bonferroni-Dunn] Ajusta el valor de $\alpha$ 
		dividiéndolo por el número de comparaciones
		realizadas, $k-1$. $APV_i = \min \{\nu,1\}$,
		con $\nu = (k-1)p_i$.
	\end{description}
\item Procedimiento descendente.
	\begin{description} 
	\item[Holm] Consideramos los $p$-valores ordenados
		de manera ascendente $p_1 \leq \dots \leq p_{k-1}$
		y $H_1, \dots, H_{k-1}$ sus hipótesis asociadas.
		Se rechazan las hipótesis $H_1, \dots, H_{i-1}$
		para $i$ el menor entero tal que $p_i > 
		\alpha/(k-i)$. $APV_i = \min \{\nu,1\}$,
		con $\nu = \max \{(k-j)p_j: 1 \leq j \leq i\}$.
	\item[Holland] Partiendo de la misma situación que en
		el de Holm, se rechazan las hipótesis $H_1, \dots, 
		H_{i-1}$ para $i$ el menor entero tal que $p_i > 
		1- (1-\alpha)^(k-i)$. $APV_i = \min \{\nu,1\}$,
		con $\nu = \max \{1- (1-\alpha)^(k-j): 1 \leq j 
		\leq i\}$.
	\item[Finner] Partiendo de la misma situación que en
		los anteriores, se rechazan las hipótesis 
		$H_1, \dots, H_{i-1}$ para $i$ el menor entero tal 
		que $p_i >  1- (1-\alpha)^{(k-1)/i}$. 
		$APV_i = \min \{\nu,1\}$, con $\nu = \max \{1- 
		(1-\alpha)^{(k-1)/j}: 1 \leq j \leq i\}$.
	\end{description}
\item Procedimiento ascendente.
	\begin{description} 
	\item[Hochberg] Se ajusta el valor de $\alpha$ de manera
		ascendente. Se compara el mayor $p$-valor con 
		$\alpha$, el siguiente con $\alpha/2$, el siguiente
		con $\alpha/3, \dots$ hasta encontrar una hipótesis
		que se pueda rechazar, rechazando también aquellas
		con un $p$-valor menor. $APV_i = \max \{(k-j)p_j:
		(k-1) \geq j \geq i \}$.
	\item[Hommel] Este método es más complejo de calcular
		y comprender. Se busca el mayor $j$ tal que 
		$p_{n-j+k} < k\alpha/j$ para todo $k=1,\dots,j$.
		Si no existe $j$, se rechazan todas las hipótesis,
		si no, se rechazan todas para las que $p_i \leq 
		\alpha/j$.
	\item[Rom] Consiste en una modificación del de Hochberg,
		calculando $\alpha$ de la siguiente manera:
		\[ 
			\alpha_{k-i} = \frac{
								\sum\limits_{j=1}^{i-1}
									\alpha^j
								- \sum\limits_{j=1}^{i-2}
									{i \choose k}
									\alpha_{k-1-j}^{i-j}
						}{i},
		\]
		con $\alpha_{k-1} = \alpha, \alpha_{k-2}= \alpha/2$. 
		$APV_i = \max \{(r_{k-j})p_j: (k-1) \geq j \geq 
		i \}$, con $r_{k-j}=\alpha/\alpha_{k-j}$
	\end{description}	
\item Procedimiento en dos pasos.
	\begin{description}
	\item[Li] En primer lugar se rechazan todas las 
		hipótesis si $p_{k-1} \leq \alpha$. Si no, 
		no se rechazará $H_{k-1}$. En segundo lugar, se 
		rechazan las hipótesis $H_{i}$ tal que 
		$p_i \leq \frac{1-p_{k-1}}{(1-\alpha)\alpha}$.
		$APV_i = p_i/(p_i + 1 - p_{k-1})$.	
	\end{description}	 
\end{itemize}

\subsection{Test basados en permutaciones}
	
	En este apartado se incluye una descripción general sobre 
los test basados en permutaciones. La hipótesis general a la 
hora de realizar inferencia es considerar que una muestra 
aleatoria $\mathbf{x}$ proviene de una misma población 
$P \in \mathcal{P};\ H_0: \{ X \leadsto P \in 
\mathcal{P} \}$. Por tanto, supuesta esta hipótesis nula, 
obtenemos que si la muestra $\mathbf{x}$ viniese de 
poblaciones distintas, los valores pertenecientes a cada 
población podrían intercambiarse por los de otra sin ningún 
problema.\\
	Notemos además que $\mathbf{x}$ es un conjunto de 
estadísticos suficientes para cualquier distribución en 
$H_0$. Esto se debe a que, si $H_0$ es cierto, sea $f_P$ la 
densidad de $P$, $f_P^{(n)}(x)$ la densidad de la variable 
$X^(n)$. Como $f_P^{(n)}(\mathbf{x}) = f_P^{(n)}(\mathbf{x}) 
\cdot 1$ para todo $\mathbf{x} \in \Omega^n$, excepto para 
$f_P^{(n)}(\mathbf{x}) = 0$ debido al teorema de 
factorización cualquier conjunto $\mathbf{x}$ es un conjunto 
de estadísticos suficientes para cualquier $P \in 
\mathcal{P}$.\\
	En estos test se realizan inferencias condicionadas con
respecto a la muestra $x$, que es a su vez un conjunto de 
estadísticos suficientes en $H_0$. Este hecho unido a la 
intercambiabilidad de los datos observados con respecto a los 
grupos hace que los test sean independientes de las 
distribución $P$, por lo que no necesitamos conocerla. Esto 
queda más claramente explicado en el siguiente principio:

\begin{definicion}[Principio de los test basados en 
permutaciones]
	Si dos experimentos toman valores en el mismo espacio
muestral $\Omega$ respectivamente con las distribuciones 
$P_1, P_2 \in \mathcal{P}$, dan el mismo conjunto de datos 
$\mathcal{x}$, entonces las inferencias condicionales a 
$\mathcal{x}$ obtenidas usando el mismo test estadístico debe 
ser la misma, debido a la intercambiabilidad de los datos con 
respecto a los grupos se cumple en la hipótesis nula. Por 
consiguiente, si dos experimentos con distribuciones 
$P_1, P_2$ dan respectivamente como muestras $\mathbf{x_1}, 
\mathbf{x_2}$, con $\mathbf{x_1} \neq \mathbf{x_2}$, entonces 
las inferencias con respecto a $\mathbf{x_1}$ y 
$\mathbf{x_2}$ pueden ser distintas.
\end{definicion}


\subsubsection{Ejemplo con muestras emparejadas}

	Para explicar el funcionamiento de los test basados en 
permutaciones, expondremos situaciones ya conocidas en las 
que sabemos cómo utilizar test paramétricos o test no 
paramétricos expuestos anteriormente. El primer caso es el de 
muestras pareadas. Supondremos una muestra de 20 individuos 
que se somete a un tratamiento para reducir la ansiedad. Los 
datos se obtienen antes y después de realizar el experimento. 
Por tanto consideramos la v.a. $Y = (Y_1, Y_2)$ de $n=20$ 
elementos $\{(Y_{1i},Y_{2i}): i = 1, \dots, n\}$. La 
hipótesis nula es que las diferencias en que las 
distribuciones marginales de $Y_1$ e $Y_2$ son iguales:
$H_0 : \{ Y_1 = Y_2 \}$ frente a $H_1: \{ Y_1 > Y_2 \}$\\
	
	En primer lugar, nótese que la hipótesis nula $H_0$ 
implica que las dos variables $Y_1, Y_2$ son intercambiables. 
Esto es, supuesto $H_0$, para cada individuo los dos valores 
observados podrían corresponder con cualquiera de las 
observaciones, antes o después del tratamiento. Es decir, si 
consideramos la variable aleatoria $X = Y_2 - Y_1$, cada 
valor observado $X_i, i=1, \dots, n$ podría tener cualquier 
signo con probabilidad $1/2$. Una forma de realizar el test 
sería considerando el estadístico $T = \sum\limits_{i=1}^n 
X_i$, cuya distribución condicionada a $\mathbf{X} = \{X_i: i 
= 1, \dots, n\}$, $F_T(t|\mathbf{X})$ vendrá dada bajo $H_0$ 
considerando la atribución de todas las formas posibles del 
signo de cada diferencia con probabilidad $1/2$. Nos 
referimos por $T^* = \sum\limits_{i=1}^n X_i^*$, donde 
$X_i^*$ se obtiene asignando aleatoriamente el signo. 
Notaremos por $\Omega_{/\mathbf{X}}$ al espacio muestral de 
permutaciones. Este espacio consiste en las posibles 
permutaciones de la muestra obtenidas, aunque posteriormente 
daremos una definición más formal. En este caso, el espacio 
tiene $M^{(n)} = 2^v$ elementos, donde $n-v$ es el número de 
diferencias nulas. Notamos por $F(t|\mathbf{X}) = P[T^* \leq 
t | \mathbf{X}], t \in \mathbb{R}$ a la cdf condicional de la 
permutación inducida por $T$ dado $\mathbf{X}$.\\
	Si el tamaño de la muestra $n$ es grande, podrá aplicarse 
el Teorema Central del Límite Permutacional (\ref{th:PCTL}) 
para aproximar la distribución de la permutación 
$F[t|\mathbf{X}]$. Para resolver un problema de este tipo 
podemos guiarnos por lo siguiente:
	
\begin{enumerate}[a]
	\item Si $n \leq 25$ es posible calcular exactamente 
		$T^*$  para todas las posibles permutaciones y 
		calcular $F[t|\mathbf{X}]$.
	\item Si $n \geq 200$, $\sigma_X$ se supone finito y el 
		cociente $(\sum_i X_i^4)/(\sum_i X_i^2)^2$ es 
		pequeño, $F[t|\mathbf{X}]$ puede aproximarse por 
		el PCTL (\ref{th:PCTL}). 
	\item En otro caso, $F[t|\mathbf{X}]$ puede aproximarse 
		utilizando el algoritmo condicional de Monte 
		Carlo (CMC).
\end{enumerate}
	
\subsubsection{Teoría de los test basados en permutaciones}

\begin{definicion}[Espacio de referencia condicional]
	Conjunto de puntos del espacio muestral $\Omega^n$ que 
son equivalentes a $\mathbf{X}$ en términos de la información 
asociada a la verosimilitud subyacente. Lo notamos por 
$\Omega^n_{/\mathbf{X}}$.
\end{definicion}

	Esto es, $\Omega^n_{/\mathbf{X}}$ contiene todos los 
puntos $\mathbf{X}^*$ tales que $dP(X)/dP(X^*)$ es 
independiente de $P$. Dado que en $H_0$ la probabilidad de 
obtener $\mathbf{X}$ es la misma que de obtener una 
permutación $\mathbf{X}^*$,
	\[ 
		\Omega^n_{/\mathbf{X}} = 
			\left\lbrace
				\underset{\mathbf{u}^*}{\bigcup}
					[ X(u_i^*), i = 1, \dots, n ]
			\right\rbrace ,
	\]
	con $\mathbf{u}^*$ cualquier permutación de las etiquetas 
$(1, \dots, n)$.

\paragraph{Definicion de los test basados en permutaciones}
\begin{definicion}[Soporte de la permutación]
	Para realizar un test estadístico es necesaria una 
función no degenerada $T: \Omega^n \rightarrow \mathbb{R}$. 
Definimos el soporte de la permutación de $(T, \mathbf{X})$ 
como $\mathcal{T}_\mathbf{X} = \{ T^* = T(\mathbf{X}^*): 
\mathbf{X}^* \in \Omega_{/\mathbf{X}}\}$ 
\end{definicion}	

	Supongamos $H_0$ cierta. Entonces, $\mathbf{X}^*$ se 
distribuye uniformemente sobre $\Omega_{/\mathbf{X}}$. 
Pongamos los $M^{(n)}$ elementos de $\mathcal{T}_\mathbf{X}$ 
en orden creciente. De esta manera para $\alpha \in (0,1)$, 
se define $T_\alpha(\mathbf{X}) = T_\alpha = T^*_{(M^{(n)}_
\alpha)}$ como el valor crítico asociado a $(T, \mathbf{X})$, 
donde $M^{(n)}_\alpha$ es el número de valores $T^*$ 
estrictamente menor que $T_\alpha$. Nótese que $T_\alpha$ 
depende de $\Omega_{/\mathbf{X}}$ y no únicamente de $
\mathbf{X}$, pues $T_\alpha(\mathbf{X}) = T_
\alpha(\mathbf{X}')$ para $\mathbf{X}' \in \Omega_{/
\mathbf{X}}$. Esto implica que si $\alpha$ es fijo,$T_\alpha$ 
es fijo para $\mathcal{T}_\mathbf{X}$.
	
\paragraph{Test basados en permutaciones aleatorizados}

	Se define la versión aleatorizada del test basado en 
permutaciones para $(T, \mathbf{X})$ como 
	\[ 
		\phi_R = \left\lbrace \begin{array}{cc}
			1 		& \text{ si } T^0 > T_\alpha \\
			\gamma 	& \text{ si } T^0 = T_\alpha \\
			0		& \text{ si } T^0 < T_\alpha \\
		\end{array} \right. ,
	\]
	
	donde $T^0 = T(\mathbf{X})$, el valor de $T$ en los datos 
observados y $\gamma$ es:
	\[
		\gamma = \frac{\alpha - P[T^0 > T_\alpha | 
								\Omega_{/\mathbf{X}}]}
					  {P[T^0 = T_\alpha | 
								\Omega_{/\mathbf{X}}]} .
	\]
	
	Para aplicar $\phi_R$ es habitual usar un experimento 
aleatorio independiente de $\mathbf{X}$. Por ejemplo, 
rechazando $H_0$ si $U \geq \gamma$ para $T^0 = T_\alpha$, 
con $U$ un valor aleatorio de la variable uniforme 
$\mathcal{U}(0,1)$.\\
	Para $\mathbf{X} \in \Omega^n$ la esperanza en $H_0$ de 
$\phi_R$ para $\alpha$ es:
	\[ 
		E[ \phi_R(\mathbf{X}) | \Omega_{/\mathbf{X}}] =
			P[ T^0(\mathbf{X}) > T_\alpha(\mathbf{X}) | 
								\Omega_{/\mathbf{X}}] + 
			P[ T^0(\mathbf{X}) = T_\alpha(\mathbf{X}) | 
								\Omega_{/\mathbf{X}}] =
			\alpha .
	\]
	
	Por consiguiente, el tamaño del test basado en 
permutaciones aleatorizado es exactamente $\alpha$.
	
\begin{proposicion}
	Supuesta la condición de intercambiabilidad para 
$\mathcal{X}$. Entonces para todas las distribuciones $P$ y 
uniformemente para todos los conjuntos de datos $\mathbf{X} 
\in \Omega^n$ la probabilidad condicionada de rechazo de 
$\phi_R$ es invariante con respecto a $\mathbf{X}$ y $P$.
\end{proposicion}

\paragraph{Test basados en permutaciones no aleatorizados}

	En los contextos de aplicación se suele utilizar la 
versión no aleatorizada. Se define
	
	\[ 
		\phi = \left\lbrace \begin{array}{cc}
			1 		& \text{ si } T^0 \geq T_\alpha \\
			0		& \text{ si } T^0 < T_\alpha \\
		\end{array} \right. .
	\]
	
	Ahora, el error asociado de tipo I es 
	
	\[ 
		E[ \phi(\mathbf{X}) | \Omega_{/\mathbf{X}}] =
		P[ T^0 \geq T_\alpha | \Omega_{/\mathbf{X}}] =
		\sum\limits_{\Omega_{/\mathbf{X}}}
			\mathbb{I}[ T(\mathbf{X}^*) \geq T_\alpha ]/
				M^{(n)} =
		\alpha_a \geq
		\alpha,
	\] 
	
	donde $\alpha_a$ es el llamado $\alpha$-valor alcanzable 
asociado a $(T, \mathbf{X})$. Para $(T,\mathbf{X})$, el 
$\alpha$-valor alcanzable pertenece a $\Lambda_\mathbf{X}
^{(n)} = \{ L_\mathbf{X}(t): dL_\mathbf{X}(t) > 0 \}$, para 
la función $ L_\mathbf{X}(t) = P[ T^* \geq t | \Omega_{/
\mathbf{X}}] $. 
	
\paragraph{$p$-Valor} Determinar el valor crítico $T_\alpha$ 
para un test estadístico $T$ puede ser complicado en la 
práctica. Por tanto, normalmente se hace referencia a un $p$-
valor asociado a $(T, \mathbf{X})$, que se define como $p = 
\lambda_T(\mathbf{X}) = L_\mathbf{X}(T^0) = P[ T^* \geq T^0 | 
\Omega_{/\mathbf{X}}]$. Este valor se puede calcular 
enumerando completamente $\mathcal{T}_\mathbf{X}$ o 
estimándolo mediante el algoritmo condicional de Monte Carlo. 
El $p$-valor $p$ es una función creciente de $T^0$ y tiene 
una  correspondencia uno a uno con los $\alpha$-valores 
alcanzables de $\phi$, puesto que $\lambda_T(\mathbf{X}) > 
\alpha$ implica $T^0 < T_\alpha$ y viceversa.

\paragraph{Algoritmo CMC para estimar el $p$-valor}  
Describimos a continuación los pasos generales de un 
algoritmo condicional de Monte Carlo para la evaluación de un 
$p$-valor de un test estadístico $T$ en un conjunto de datos 
$\mathbf{X} = \{ X_i, \ i=1, \dots, n; n_1, n_2 \}$

\begin{algorithm}
	\caption{Algoritmo CMC para estimar el $p$-valor}
	\label{alg:CMC-pvalue}
	\begin{algorithmic}[1]
	\REQUIRE
		\begin{enumerate}[a]
		\item Muestra $\mathbf{X}$
		\item Test estadístico $T$
		\item Número de iteraciones $B$
		\end{enumerate}
		\STATE Calcular $T^0 = T(\mathbf{X})$
		\FOR { $b \in \{1, \dots, B\}$ }
			\STATE Realizar una permutación $\mathbf{X}^*$ de  
			$\mathbf{X}$.
			\STATE Calcular $T^* = T(\mathbf{X}^*)$
		\ENDFOR
		\STATE El conjunto $\{ \mathcal{X}^*_b, b = 1, \dots, 
		B \}$ es una muestra aleatoria de 
		$\Omega_{/\mathbf{X}}$ y los valores correspondientes 
		$\{ T^*_b, b = 1, \dots, B \}$ simulan la 
		distribución nula de las permutaciones de $T$ 
		(aquella que tendría $T$ de ser cierta $H_0$). 
		Entonces el $p$-valor se estima como $\hat{\lambda}
		(\mathbf{X}) = \sum\limits_{b=1}^B 
		\mathbb{I}[T_b^* \geq T^0]/B$, esto es, la proporción 
		de los valores de la permutación mayores que el 
		observado.
	\end{algorithmic}
\end{algorithm}

\paragraph{Teorema Central del Límite Permutacional}
	Por último en esta sección, se presenta la versión 
permutacional del TCL de Wald y Wolfowitz \cite{WALWOL44}.
Notaremos por $\mathbf{X} = \{X_1, \dots, X_n\}$ de $n$ v.a. 
independientes e idénticamente distribuidas. Supongamos que 
la hipótesis nula sobre la que se realiza el test, $H_0$, 
implica que las permutaciones en $\mathbf{X}$ son igualmente 
probables.\\
	Definimos el test estadístico permutacional
	\[
		T = T(\mathbf{X}) = 
			\sum\limits_{i=1}^n
				A_i X_i,
	\]
	para el vector $\mathbf{A} = \{A_1, \dots, A_n\}$. Para 
un vector genérico $\mathbf{D}$, notamos $\bar{D} = 
\frac{\sum\limits_{i=1}^n D_i}{n}$, $\mu_r(\mathbf{D}) = 
\frac{\sum\limits_{i=1}^n (D_i - \bar{D})^r}{n}$, 
$W_r(\mathbf{D}) = \frac{\sum\limits_{i=1}^n 
|D_i - \bar{D}|^r}{n}$, $R(\mathbb{D}) = 
\underset{1 \leq i \leq n}{\max} D_i - 
\underset{1 \leq i \leq n}{\min} D_i$.\\

	De la distribución de la permutación de $T$ se obtiene

\begin{align*}
	\mathbb{E}_{\Omega_{/\mathbf{X}}} \left[
		T(\mathbf{X}^*) | \Omega_{/\mathbf{X}}
		\right] &=
		n \bar{X} \bar{A}, \\
	\mathbb{E}_{\Omega_{/\mathbf{X}}} \left[
		(T(\mathbf{X}^*) - n\bar{X}\bar{A})^2 | 
			\Omega_{/\mathbf{X}}
		\right] &=
		\frac{[n^2 \mu_2{\mathbf{X}} \mu_2{\mathbf{A}}]^2}
			{n-1}.
\end{align*}

	Entonces, escribimos la v.a.
	\[
		Z = \frac{(T - n \bar{X} \bar{A})\sqrt{n-1}}
				{n^2 \mu_2(\mathbf{X}) \mu_2(\mathbf{A})},
	\]
	
	y sabemos que la cdf de $Z$, $F_Z(t|\Omega^n)$ puede 
determinarse enumerando todas las permutaciones de 
$\mathbf{X}$. Antes de enunciar el teorema, enunciaremos la 
condición sobre $\mathbf{X}$ y $\mathbf{A}$. 
$\{ \mathbf{D}_n; n \geq 2 \}$:

\begin{equation}
	 \label{eq:PCLTcond}
	 \tag{C.1}
	 \frac{\mu_r(\mathbf{D}_n)}
	 		{\mu_2(\mathbf{D})^{r/2}} = O(1),\quad
	 		\forall r \in \mathbb{N},\ r \geq 2
\end{equation}

\begin{teorema}[Teorema Central del Límite Permutacional]
	Sean $\{\mathbf{A}_n; n \geq 2\}$, $\{\mathbf{X}_n; 
n \geq 2\}$ cumpliendo la condición~\ref{eq:PCLTcond}. 
Entonces para $n \rightarrow \infty$,
	\[ F_Z(t | \Omega^n_{\mathbf{X}}) 
		\overset{P}{\rightarrow} \mathit{N}(t | 0,1)
	\]
	\label{th:PCTL}
\end{teorema}

\subsection{Revisión del estado del arte en la aplicación de test no paramétricos}
 
\paragraph{Validación de un modelo de degradación de 
documentos} \cite{KANUNGO00} En este artículo se presenta un 
modelo de la degradación en documentos producida por la 
digitalización de documentos impresos o la realización de 
fotocopias. El problema estadístico que se define es el 
siguiente. Dadas las muestras $x_1, \dots, x_N$ e $y_1, 
\dots, y_M$ de caracteres degradados de un mismo carácter de 
un documento y generados de manera artificial, 
respectivamente, realizar el test sobre la hipótesis nula de 
de ambos  provienen de la misma población para un valor de 
significación $\alpha$. Se aplica un algoritmo 
(\ref{alg:CMC-digitalizacion}) para realizar el test basado 
en permutaciones calculando el $p$-valor utilizando el 
algoritmo~\ref{alg:CMC-pvalue}.

\begin{algorithm}
	\caption{Test basado en permutaciones para validación en 
			modelo de degradación}
	\label{alg:CMC-digitalizacion}
	\begin{algorithmic}[1]
	\REQUIRE
		\begin{enumerate}[a]
		\item Datos reales $X = \{ x_1, \dots, x_N \}$
		\item Datos generados $Y = \{ y_1, \dots, y_M \}$
		\item Función distancia entre conjuntos $\rho(X,Y)$
		\item Función distancia entre caracteres $\delta(x,y)$
		\item Tamaño máximo del test $\alpha$
		\end{enumerate}
		\STATE Calcular $d_0 = \rho(X,Y)$
		\STATE Crear una muestra 
			$Z= \{x_1, \dots, x_N, y_1, \dots, y_M \}$.
		\FOR { $i \in \{1, \dots, K\}$ }
			\STATE Realizar una permutación de $Z$.
			\STATE Particionar $Z$ en $X'$ e $Y'$ tales que 
				$X' = \{ z_1, \dots, z_N \}$, $Y' = 
				\{ z_{N+1}, \dots, z_{N+M} \} $.
			\STATE Calcular $d_i = \rho(X,Y)$
		\ENDFOR
		\STATE Calcular la distribución empírica de las $d_i$
		\STATE Calcular el $p$-valor: 
			$\alpha_0 = P(d \geq d_0)$
		\STATE Rechazar la hipótesis nula si 
			$\alpha_0 \leq \alpha$
	\end{algorithmic}
\end{algorithm}

	Para la comparar un modelo $A$ con otro $B$ se comparan 
sus funciones de potencia. Suponemos $X \sim F(\theta_X)
$, $Y \sim F(\theta_Y)$. Consideraremos la hipótesis nula 
$H_0 = \theta_X = \theta_Y$. Si fijamos $\theta_X= \theta_0$, 
Denotamos a la función potencia $\gamma_{\theta_0}= 
P(H_1 | \theta_X = \theta_0 \text{ y } \theta_Y = \theta)$. 
$A$ será mejor que $B$ dado $\theta$ si $\gamma_{\theta_0}^A  
> \gamma_{\theta_0}^B$.
	
\paragraph{Comparación estadística de varios clasificadores} 
\cite{CHENGCHEN03} En este artículo se describe un método 
para realizar la comparación estadística de varios 
clasificadores sobre una misma base de datos a través del 
test de Cochran, una generalización del test de McNemar. La 
aplicación de un test no paramétrico en lugar de uno 
paramétrico como ANOVA se justifica en el artículo debido a 
que no se puede asegurar la independencia entre las 
instancias clasificadas por un mismo clasificador, con lo que 
queda en entredicho el desempeño del test ANOVA, por ejemplo. 
Si la hipótesis nula, $H_0: \theta_1 = \dots = \theta_n$ 
(todos los algoritmos tienen un rendimiento equivalente), es 
cierta, no es necesario ningún análisis posterior. Si es 
rechazada, se pretenden realizar múltiples comparaciones para 
encontrar los algoritmos con mejor rendimiento. Para ello se 
describen los métodos de Bonferroni y Scheffé. El primero 
parte de una familia de $g$ contrastes, mientras que el 
segundo considera la familia $L$ de todos los contrastes 
posibles. Por ello, para el primero se deben prefijar las 
comparaciones a realizar, mientras que para el segundo esto 
se puede realizar \textit{a posteriori} según los datos 
obtenidos. Para escoger entre un método u otro, se recomienda 
escoger el primero cuando $Z_{1-\alpha/2g}$ (percentil $(1-
\alpha/2g)100$ de una distribución normal estándar) es menor 
que $\sqrt{\chi^2_{m-1,1-\alpha}}$ (donde $m$ es el número de 
algoritmos en la comparación) debido a que en este caso el 
método de Bonferroni tiene una mayor potencia. Escogeremos el 
método de Scheffé en caso contrario.

\paragraph{Comparación estadística de clasificadores en 
varios conjuntos de datos} \cite{DEMSAR06} De la comparación 
utilizando un único conjunto de datos se pasa en este 
artículo a presentar un método para comparar el rendimento 
sobre varios conjuntos de datos utilizando test no 
paramétricos.\\
	Se incluyen en una primera sección las opciones para 
realizar las comparaciones entre dos clasificadores para 
varias conjuntos de datos, evaluando sus ventajas e 
inconvenientes:
	\begin{enumerate}
	\item Media entre los conjuntos de datos: Arroja poca 
		información poco valiosa al combinar puntuaciones 
		obtenidas en distintos dominios.
	\item $t$-test emparejados: El estadístico de este test 
		paramétrico es similar al usado al realizar la media 
		entre los conjuntos de datos. Además, se necesita que 
		la diferencia siga una distribución normal, además de 
		que los datos disponibles suelen ser reducidos. 
	\item Test de signo: Como se ha dicho en el desarrollo de 
		los test, no tiene en cuenta la magnitud de la 
		diferencia.
	\item \textit{Signed-Rank test} de Wilcoxon: Más seguro 
		que el $t$-test al no suponer la distribución normal. 
		Si no se dan las circunstancias adecuadas, este test 
		puede tener mayor potencia que el $t$-test.
	\end{enumerate}
	
	En cuanto a la comparación entre varios clasificadores, 
se incluye una breve descripción del método ANOVA y una 
descripción más extensa del test de Friedman, que podríamos 
considerar su versión no paramétrica. Se incluye el 
estadístico $F_F = \frac{(n-1) \chi^2_F}{n(k-1) - \chi^2_F}$ 
que sigue la distribución $F$ con $k-1$ y $(k-1)(n-1)$ grados 
de libertad. Aunque el test ANOVA tiene mayor potencia cuando 
las condiciones se cumplen, se incluye un experimento que 
muestra que apenas hay diferencias si éstas no se dan.\\

	Una vez se ha rechazado la hipótesis nula se describen 
los test \textit{post-hoc} de Nemenyi, Bonferroni-Dunn, Holm, 
Hochberg y Hommel.
	
	
\paragraph{Extensión sobre los procedimientos 
\textit{post-hoc}} \cite{GARCIAHERRERA08} Este artículo 
extiende al anterior prestando una mayor atención a la 
descripción de los procedimientos para la comparación entre 
algoritmos una vez rechazada la hipótesis nula. Se introducen
los procedimientos de Nemenyi y Holm. Debido a que las 
posibles hipótesis sobre la comparación  por parejas están 
relacionadas y no se pueden dar todas las posibles 
combinaciones, se presentan los procedimientos de 
Schaffer estático y dinámico. Bergmann y Hommel propusieron 
un procedimiento basado en la idea de encontrar todas las 
hipótesis que no pudieran ser rechazadas. En un estudio 
comparativo sobre el rendimiento de cinco clasificadores 
sobre treinta conjuntos de datos se observa como el 
procedimiento de Bergmann y Hommel tiene una mayor 
potencia.\\

	Se aborda también el problema de calcular $p$-valores 
ajustados (APV) que tengan en cuenta los demás test 
realizados para poder utilizar directamente este valor 
ajustado. Se indican el cálculo para cada procedimiento 
\textit{post-hoc}. Tras realizar un nuevo estudio 
introduciendo el uso de APV, se descarta el test de Nemenyi 
debido a que es demasiado conservador. Se recomienda el 
procedimiento estático de Schaffer frente al del Holm al 
tener mayor potencia al usar las relaciones entre las 
hipótesis y una dificultad no muy superior. Debido a su coste 
computacional y su complejidad, se recomienda el método de 
Bergmann-Hommel sólo para cuando las diferencias entre 
clasificadores sean muy pequeñas y otros métodos no detecten 
diferencias significantivas.

	\paragraph{Estudio del uso de test no paramétricos} 
	\cite{GARCIA09} En este artículo se realiza un estudio
sobre el uso de test no paramétricos para comparar el 
rendimiento de algoritmos evolutivos en la Sesión Especial de 
Optimización de parámetro real en el Congreso de Computación 
Evolutiva (CEC 2005). Los datos disponibles son los errores 
cometidos por los (11) algoritmos a la hora de minimizar 25 
funciones de 10, 30 y 50 variables reales. En primer lugar se 
estudian las condiciones para realizar un test paramétrico 
($t$-test) llevando a cabo test de normalidad (test de 
Kolmogoro-Smirnov, test de Shapiro-Wilk y el de D'Agostino-
Pearson) y el test de Levene de homocedasticidad. Se 
pretende realizar en primer lugar la comparación entre dos de 
los algoritmos para comprobar si hay diferencias entre ellos. 
Sin embargo los test de normalidad rechazan para los 
resultados en casi todas las funciones a minimizar la 
hipótesis de normalidad y el test de Levene rechaza la 
hipótesis de la equivalencia de las varianzas, con lo que no 
se cumplen las condiciones para realizar el $t$-test. Si se 
realizan el $t$-test y el test no paramétrico de Wilcoxon se 
observa que los resultados son muy similares.\\
	A la hora de afrontar la comparación en múltiples 
problemas en lugar de problema por problema en este artículo 
se toma la media de las distintas ejecuciones. Al realizar 
los test de normalidad sobre las dos muestras de 25 elementos 
para cada algoritmo se descarta la normalidad. El $t$-test y 
el test de Wilcoxon no rechazan la hipótesis nula de que 
ambos algoritmos sean igual de buenos, sin embargo el $p$-
valor del test de Wilcoxon es bastante menor, lo que nos 
lleva a pensar que, debido a la ausencia de normalidad y de 
pocos datos y difíciles de incrementar (pues en este caso 
deberíamos añadir funciones nuevas funciones y sus 
correspondientes evaluaciones para cada algoritmo), en estos 
casos es mejor utilizar test no paramétricos.\\
	Para realizar el análisis sobre todos los algoritmos se 
separan las funciones fáciles, aquellas en las que algún 
algoritmo alcanza el óptimo frente a las que ningún algoritmo 
llegó al óptimo. El test no paramétrico de Friedman y el de 
Iman-Davenport arrojan valores que nos llevan a rechazar la 
hipótesis nula tanto usando el grupo de funciones difíciles 
como usando el conjunto total de funciones.\\
	El estudio posterior se centra en comparar los algoritmos 
con aquel que consiguió un menor error medio, el 
\textit{G-CMA-ES}. Para ello se utilizan el test de 
Bonferroni-Dunn, el de Holm y el de Hochberg para los dos 
grupos de funciones. El test de Hochberg llega a encontrar 
diferencias entre el mejor algoritmo y todos los demás para 
$\alpha=0.1$. 
	
	\paragraph{Estudio estadístico sobre algoritmos 
genéticos: precisión e interpretabilidad} \cite{GARCIA08} En 
este artículo se realiza la comparación sobre algoritmos 
evolutivos utilizados en clasificación, comparando tanto la 
tasa de clasificación como el valor kappa de Cohen y la 
interpretabilidad de estos resultados. Al igual que en el 
artículo anterior, se realizan test de normalidad y 
homocedasticidad para comprobar si se dan las condiciones 
para aplicar un test paramétrico. Si las comparaciones por 
parejas de problemas se repiten crece el error asociado FWER 
(\textit{family-wise error rate}), esto es la probabilidad de 
al menos un error en la familia de hipótesis. Para realizar 
comparaciones entre varios algoritmos y fijar el FWER de 
antemano se utilizan el test de Friedman y el de Iman-
Davenport y los test de Bonferroni-Dunn y el de Holm para 
buscar diferencias entre los algoritmos una vez descartada la 
hipótesis de que todos tienen la misma media. Se realiza 
calculan también los $p$-valores ajustados.\\
	Para realizar el análisis de la interpretabilidad de los 
resultados se considera $\textit{Complejidad} = 
\textit{Tamaño} \cdot ANT$. Se realiza para este estudio 
únicamente un procedimiento para múltiples comparaciones, 
obteniendo diferencias significativas con el test de 
Bonferroni-Dunn y nivel de significación $\alpha=0.1$.
	
	\paragraph{Test avanzados para la comparación y análisis 
experimental de la potencia} \cite{GARCIA10} En este
artículo se introducen con respecto a otros artículos 
previos los test de múltiples signos y la estimación del 
contraste basado en medianas como test básicos para realizar
entre múltiples clasificadores y conjuntos de datos como 
test básicos, y los más avanzados del test de Friedman
de puestos alineados (\textit{Friedman Aligned Ranks}, 
Friedman-AR) y el test de Quade. Además, para realizar las 
comparaciones  posteriores  una vez descartada la hipótesis 
de un igual  rendimiento entre todos los algoritmos, se 
incluyen a los  procedimientos \textit{post-hoc} los de 
Holland y Finner  dentro de  los métodos descendentes, el de 
Rom como método  ascendente y el procedimiento de Li, para 
rechazar hipótesis en dos pasos.\\
	Se realiza un estudio sobre la potencia de los test
de Friedman, de Friedman-AR y de Quade, utilizando 8 y 4
algoritmos sobre 10 y 6 conjuntos de datos respectivamente. 
Se observa que el test de Friedman-AR es más conservador
cuando el número de algoritmos es elevado. En este estudio
se observa que el test de Quade se comporta mejor, sin
embargo depende de los conjuntos de datos utilizados. Para
el estudio sobre los test \textit{post-hoc}, se utilizan
8 algoritmos sobre 10 conjuntos de datos seleccionados
de forma pseudo-aleatoria (regulando mediante un parámetro la 
probabilidad de seleccionar una base de datos según la 
diferencia de los algoritmos a comparar en ella). Los 
resultados obtenidos hacen desaconsejar el test de 
Bonferroni-Dunn, en un siguiente grupo estarían Holm, 
Hochberg, Hommel, Holland y Rom con una potencia similar
y los que mejores resultados obtienen son el test de Finner
y el test de Li, el cual ofrece mejores resultados 
cuando las diferencias entre el algoritmo de control y los 
demás sean grandes.

	
	\paragraph{Análisis \textit{bootstrap} de múltiples 
repeticiones de experimentos} \cite{OTERO13} En este artículo 
se presenta la realización de test basados en permutaciones 
para la comparación del rendimiento de algoritmos de 
clasificación, realizando un estudio para el que el test 
presentado tiene mayor potencia que los test de ANOVA o 
Friedman. El contexto para el que se presenta este método es 
el de la comparación entre algoritmos estocásticos (de ahí 
que se realice la repetición de la ejecución de los 
algoritmos con diferentes semillas) utilizando validación 
cruzada. Se propone usar intervalos para recoger parte de la 
variabilidad de los datos atribuible a la repetición del 
experimento. Se plantea el problema del uso de la media entre 
los distintos experimentos para evaluar un algoritmo debido a 
que los valores extremos tienen una influencia excesiva y se 
aboga por otros estadísticos como la mediana, el rango 
intercuartílico o la media restringida a los valores 
centrales.\\
	El primer test es un test basado en permutaciones. Parte 
de la muestra compuesta por $e_{adfr}$, que es el error del 
algoritmo $a$-ésimo, el conjunto de datos $d$, para el 
\textit{fold} $f$ y la repetición $r$. Se utiliza en este 
test como estadístico para evaluar cada algoritmo la media de 
las ejecuciones en todos los \textit{folds}, repeticiones y 
conjuntos de datos como estimador, utilizando el algoritmo ~
\ref{alg:CMC-pvalue}. Se rechazará la hipótesis nula (la 
equivalencia de las medias) si para algún $a$ la media 
inicial $\hat{e}_a$ se encuentra en las colas de la 
distribución formada por los valores de las permutaciones $
\hat{e}_a^*$ consistente en la cdf muestral:
	\[ 
		\hat{F}_{a \cdot \cdot \cdot}(x) =
			\frac{1}{n_d n_r n_f}
			\sum\limits_{i=1}^{n_d}
				\sum\limits_{j=1}^{n_f}
					\sum\limits_{k=1}^{n_r}
						\mathbb{I}[ e_{aijk} \leq x ].
	\]
	El segundo test sí hace uso de los intervalos, notando 
por $[q_{-adf}, q_{+adf}]$ el intervalo de los errores para 
un algoritmo, base de datos y \textit{fold}. Se definen las 
cdf muestrales como
	
\begin{align*}
	\hat{F}_{-a \cdot \cdot}(x) &=
		\frac{1}{n_d n_f}
			\sum\limits_{i=1}^{n_d}
				\sum\limits_{j=1}^{n_f}
					\mathbb{I}[ q_{+aij} \leq x ], \\
	\hat{F}_{+a \cdot \cdot}(x) &=
		\frac{1}{n_d n_f}
			\sum\limits_{i=1}^{n_d}
				\sum\limits_{j=1}^{n_f}
					\mathbb{I}[ x \in [q_{-aij},q_{+aij}) ] +
			\hat{F}_{-a \cdot \cdot}(x) .			
\end{align*}

	En este test se aplica también el algoritmo 
~\ref{alg:CMC-pvalue}, rechazando la hipótesis nula si el 
intervalo $[\hat{q}_{-a}, \hat{q}_{+a}]$, con $\hat{q}_{-a}, 
\hat{q}_{+a}$ las medias de los extremos inferiores y 
superiores respectivamente para cada algoritmo con respecto a 
las conjuntos de datos y \textit{fold}, se encuentra en las colas 
de la distribución de los $[\hat{q}_{-a}^*, \hat{q}_{+a}^*]$.
\\
	Los resultados incluidos ofrecen una comparación entre la 
potencia de estos test presentados, el test de Friedman y el 
de ANOVA. Se realiza un experimento con datos sintéticos 
consistentes en los resultados de los errores de 5 algoritmos 
en 32 conjuntos de datos para una secuencia de diferencias en sus 
medias preestablecidas. Para calcular la potencia se estima 
para cada diferencia el porcentaje de experimentos para el 
que se encuentran diferencias significativas entre los 
algoritmos dos a dos. Los resultados indican una mayor 
potencia de los test presentados en este artículo.


\section{Test bayesianos}	

	En esta sección se hace una introducción a conceptos de 
la estadística bayesiana y test basados en esta estadística
para su aplicación en la comparación de algoritmos de
aprendizaje automático.\\
	Según A. Gelman (\cite{GELMAN14}), la inferencia 
bayesiana es el proceso de ajustar un modelo de probabilidad 
a un conjunto de datos y resumir el resultado  mediante una 
distribución de probabilidad sobre los  parámetros del modelo 
y sobre cantidades no observadas como predicciones para 
nuevas observaciones. Estamos por tanto frente a una 
forma de entender la estadística distinta, cuya principal
característica es el uso de la probabilidad para 
cuantificar la incertidumbre en las inferencias basadas en
el análisis de los datos. Este análisis puede dividirse en
tres pasos:

	\begin{enumerate}
	\item establecimiento de un modelo de probabilidad;
	\item condicionamiento sobre los datos observados,
		calculando e interpretando la distribución 
		\textit{a posteriori};
	\item evaluación del modelo y las implicaciones de la
		distribución \textit{a posteriori} resultante.
	\end{enumerate}

\subsection{Problemas de los test de hipótesis nula}	

	Los test de hipótesis nula (THN) son en ocasiones como un
método infalible para la realización de un experimento y la
forma de obtener conclusiones. Sin embargo, existen críticas
hacia el uso de este tipo de test, principalmente por parte 
de estadísticos bayesianos, causadas en su mayoría por el mal
uso que se hace de ellos. Las críticas realizadas son las
siguientes:

\begin{itemize}
\item Las decisiones dicotómicas. Al fijar el valor 
	$\alpha$ (normalmente $0.05$) se pueden realizar 
	decisiones opuestas con una mínima variación del $p$-
	valor. Se suele también confundir el significado del 
	test al considerar equivalentes dos métodos para los que
	no se encuentren diferencias estadísticamente 
	significativas.
\item Los THN no estiman la probabilidad
	de la hipótesis. La pregunta que habitualmente nos
	hacemos al comparar por ejemplo dos clasificadores es
	``\textit{¿cuál es la probabilidad de que el rendimiento
	de dos clasificadores sea el mismo?}'', en términos
	formales, $P(H_0 | \mathbb{X})$. La pregunta que
	responden es $P(T(\mathbb{X}) > \tau_\alpha | H_0)$.
\item Los test de hipótesis nula sobre puntos son
	prácticamente siempre falsos. La diferencia entre
	dos clasificadores puede ser muy pequeña, sin embargo
	no hay dos clasificadores cuyo rendimiento sea 
	equivalente. Esto tiene como consecuencia que añadiendo
	suficientes puntos es posible encontrar diferencias
	significantes. Además, no sólo en este contexto, los
	experimentos realizados y publicados suelen considerar
	hipótesis nulas difícilmente sostenibles donde el
	investigador busca rechazarla, con lo que el test está
	resulta sesgado.
\item El $p$-valor no distingue entre el efecto del tamaño
	y el tamaño de la muestra. Si el efecto del tamaño de
	$H_0$ es pequeño, se necesita más datos para demostrar 
	la diferencia. Sin embargo, como el tamaño de la muestra
	depende del investigador, y por el punto anterior $H_0$ 
	``es siempre falsa'', con suficientes datos se puede
	rechazar la hipótesis nula. En cambio, si se dispone 
	de pocos datos, se puede fallar al no rechazar una
	hipótesis nula ampliamente falsa.
\item Los THN no tienen en cuenta la magnitud y la 
	incertidumbre. No se proporciona información sobre la 
	magnitud del efecto o la incertidumbre de la estimación
	realizada, con lo que se dificulta un posterior análisis
	de las propias conclusiones realizadas.
\item No se obtiene información cuando no se rechaza la
	hipótesis nula. Es un error habitual al considerar 
	que al no encontrar diferencias significativas se
	considere cierta la hipótesis nula. 
\item No hay manera de decidir previamente el nivel 
	de significación $\alpha$. Aunque habitualmente se 
	fija un nivel de significación de $\alpha = 0.05$, y es
	este valor el que determina los límites para rechazar 
	$H_0$, este valor no tiene un significado concreto para
	el experimento. 
\item La inferencia depende del propósito del muestreo. 
	La distribución de la muestra cambia por ejemplo si
	se comparan dos algoritmos en todos los conjuntos de
	datos disponibles que si se trata de realizar un 
	número de observaciones en un único conjunto.
\end{itemize}
	
\subsection{Análisis de los resultados experimentales}

	Hay dos enfoques para el análisis de resultados 
experimentales. El primero, conocido como \textbf{factor de 
Bayes} o \textbf{comparación de modelo bayesiano}, está como 
los THN basado en lo que llamaríamos un valor nulo. Se 
comparan dos modelos y se escoge el más probable según los 
datos obtenidos. Éste modelo también recibe algunas críticas
similares a los THN pues en cierta forma se está cambiando el
valor $\alpha$ por el usado para elegir entre un modelo u 
otro, volviendo a una decisión dicotómica. El otro modelo, el 
cual se desarrollará con más detalle, se conoce como 
\textbf{estimación bayesiana de parámetros}. Al realizar
el análisis sólo hay que establecer un rango de valores 
candidatos para el parámetro (modelo \textit{a priori}) 
y usar la inferencia bayesiana para calcular la probabilidad
de todos los valores candidatos (distribución \textit{a 
posteriori}).\\

\subsection{t-test bayesiano correlado}
	\label{ssec:bayes-ttest}
	Este test se usa para el análisis de la validación
cruzada en un único conjunto de datos. Su aporte consiste en 
tener en cuenta la correlación debida al solapamiento de los 
conjuntos de entrenamiento. El modelo de los datos 
considerados es
	\[ \mathbf{X} = \mu \mathbf{1} + \mathbf{v}, \]
	con $\mathbf{X} = (x_1, \dots, x_n)$, $\mathbf{1}$ un 
vector de unos de $n$ elementos, $\mu$ el parámetro de
interés, esto es la media de las distancias entre el 
rendimiento de los clasificadores y $\mathbf{v} \backsim 
MVN(0, \Sigma_{n \times n})$, una normal multivariante con
media cero y matriz de covarianzas $\Sigma$. Se caracteriza
$\Sigma$ de la siguiente manera: $\Sigma_{ii} = \sigma^2$
y $\Sigma_{ij} = \sigma^2 \rho$ para $i \neq j$, con $\rho$
la correlación y $\sigma^2$ la varianza. Entonces,
la probabilidad del modelo es 
	\[ 
		P(\mathbf{X} | \mu, \Sigma) = 
		\frac{\exp\left(
				-\frac{1}{2}
				(\mathbf{X}-\mu\mathbf{X})^T
				\Sigma^{-1}
				(\mathbf{X}-\mu\mathbf{X})
			\right)}
		{(2\pi)^{n/2} \sqrt{|\Sigma|}}.
	\]

	Esta probabilidad no permite estimar $\rho$ de los datos, 
así que adoptamos la heurística $\rho = \frac{n_{test}}{n}$. 
Pretendemos estimar los parámetros $\mu$ y $\nu = 
\frac{1}{\sigma^2}$, para lo cual consideramos la 
distribución \textit{a priori} Normal-Gamma
	\[
		P(\mu, \nu | \mu_0, k_0, a, b) =
			N\left(\mu; \mu_0, \frac{k_0}{\nu} \right)
			G(\nu; a, b) = 
			NG(\mu, \nu ; \mu_0, k_0, a, b).
	\]
	Escogiendo los parámetros $\mu_0 = 0, k_0 \rightarrow 
\infty, a = -\frac{1}{2}, b=0$ la distribución \textit{a 
posteriori} de $\mu$ resulta ser la distribución de Student:
	
	\[
		P(\mu | \mathbf{X}, \mu_0, k_0, a, b) =
			St \left(
					\mu; n-1 , \bar{X},
					\left( \frac{1}{n} + 
							\frac{\rho}{1 - \rho} 
					\right) \hat{\sigma}^2
			   \right),
	\]

	con $\bar{X}$ y $\hat{\sigma}^2$ los estimadores 
habituales. Por tanto podemos hacer el análisis sobre $\mu$ 
basándonos en esta distribución.


\paragraph{Ejemplo} Supongamos que realizamos un experimento
con este test, realizando la comparación entre dos algoritmos
para una base de datos. La información obtenida es una 
distribución de Student, que describe como se ha mencionado
la ditribución de la media de las diferencias del rendimiento
entre dos clasificadores. Ahora, evaluamos la probabilidad 
de la hipótesis que queramos realizar, por ejemplo, que un 
algoritmo es mejor que otro directamente en la distribución
de $\mu$, calculando la probabilidad de que $\mu > 0$ ó $\mu 
< 0$ según corresponda. Para decir que los dos algoritmos son
prácticamente equivalentes, podemos suponer que esto 
significa que la diferencia de la precisión es menor que un
$1\%$. El intervalo $[-0.01, 0.01]$ se conoce entonces como
\textbf{región de práctica equivalencia} (rope). Una manera 
de mostrar la incertidumbre de la estimación es indicando el 
intervalo de los valores que son más confiables y cubren el 
$q\%$ de la distribución (HDI). 

\paragraph{Toma de decisiones} A la hora de realizar 
análisis queremos obtener conclusiones, para lo que nos 
apoyaremos en la rope. Si tenemos dos algoritmos $f_1, f_2$, 
notaremos por $P(f_1 \ll f_2)$ a la probabilidad de que el 
primero tenga un rendimiento inferior, por $P(f_1 \gg f_2)$ a 
que la de que tenga un rendimiento superior y por $P(f_1 =
f_2)$ a la probabilidad de que sean prácticamente 
equivalentes. Podemos tomar las decisiones con un nivel
de confianza (ahora con una interpretación directa) si
tenemos una de estas tres situaciones con un valor mayor
al nivel de confianza deseado.

\subsection{Test bayesiano de signo y \textit{signed-rank}}

	Al igual que el $t$-test, el test no paramétrico de 
signo también cuenta con la versión bayesiana. Partimos
del vector $z = \{z_1, \dots, z_q\}$ de muestras i.i.d.. 
Suponemos como distribución \textit{a priori} un proceso
de Dirichlet ($DP$). Un $DP$ es una distribución sobre 
distribuciones de probabilidad tales que sus distribuciones
marginales sobre particiones finitas siguen la distribución
de Dirichlet (que se puede considerar la generalización
multivariante de la distribución Gamma). El $DP$ está
definido por dos parámetros: la fuerza \textit{a priori},
$s>0$ y la media \textit{a priori} , $G_0$. Tengamos en 
cuenta que al ser $DP$ una distribución sobre distribuciones,
$G_0$ es una medida de probabilidad. Escogiendo $G_0 = 
delta_{z_0}$, una delta de Dirac centrada en el punto $z_0$,
la densidad de probabilidad posterior de $Z$ tiene la
expresión:
	\[ P(z) = 
		w_0 \delta_{z_0}(z) +
			\sum\limits_{j=1}^n
				w_j \delta_{z_j}(z); \quad
		(w_0, w_1, \dots, w_n) \sim Dir(s,1, \dots, 1).
	\] 
	
	Si observamos esta expresión, tenemos que es una 
combinación de deltas de Dirac centradas en las observaciones
y en la observación \textit{a priori} $z_0$ y cuyos pesos
siguen una distribución de Dirichlet. Para el análisis
experimental procedemos de la siguiente manera. Calculamos:

\begin{align*}
	\theta_l = P[ z < -r ] = 
				\sum\limits_{i = 0}^q 
					w_i \mathbb{I}[ z_i \in (-\infty,-r)],\\
	\theta_e = P[ |z| \leq -r ] = 
				\sum\limits_{i = 0}^q 
					w_i \mathbb{I}[ z_i \in [-r,r]], \\
	\theta_r = P[ z > r ] = 
				\sum\limits_{i = 0}^q 
					w_i \mathbb{I}[ z_i \in (r, \infty)].
\end{align*}

	Así, obtenemos una versión bayesiana del test de signo, 
que tiene en cuenta la rope $[-r,r]$. De hecho, $\theta_l,
\theta_e, \theta_r$ son las probabilidades de que la media
de las diferencias esté en el respectivo intervalo. 
Debido a que $(w_0, w_1, \dots, w_n) \sim Dir(s,1, \dots, 
1)$, se prueba que
	\[ 
		\theta_l,\theta_e, \theta_r \sim
		Dir(n_l + s \mathbb{I}[ z_0 \in (-\infty,-r) ],
			n_e + s \mathbb{I}[ z_0 \in [-r,r] ],
			n_r + s \mathbb{I}[ z_0 \in (r, \infty) ])
	\]
	
	donde $n_l, n_e, n_r$ son el número de observaciones 
que caen en cada intervalo. En definitiva, para 
completar el modelo, debemos escoger el valor \textit{a 
priori} de la fuerza $s$ y la observación $z_0$.\\

	Si ahora consideramos
	
\begin{align*}
	\theta_l &= P[ z < -r ] = 
				\sum\limits_{i = 0}^q 
				\sum\limits_{j = 0}^q 
					w_i w_j 
					\mathbb{I}[ z_i + z_j 
								\in (-\infty,-2r)],\\
	\theta_e &= P[ |z| \leq -r ] = 
				\sum\limits_{i = 0}^q 
				\sum\limits_{j = 0}^q 
					w_i w_j 
					\mathbb{I}[ z_i + z_j 
								\in [-2r,2r]], \\
	\theta_r &= P[ z > r ] = 
				\sum\limits_{i = 0}^q 
				\sum\limits_{j = 0}^q 
					w_i w_j 
					\mathbb{I}[ z_i + z_j 
								\in (2r, \infty)],
\end{align*}

	obtenemos una versión bayesiana del \textit{signed-rank}
test, con la rope $[-r,r]$. Ahora la distribución de 
$\theta_l, \theta_e, \theta_r$ no está claramente definida,
pero se puede calcular muestreando mediante el método
de Monte Carlo los pesos $(w_0, w_1, \dots, w_n) \sim 
Dir(s,1, \dots, 1)$.\\
	Para ambos métodos falta por fijar $s$ y $z_0$. 
En los experimentos realizados por Benavoli 
(\cite{BENAVOLI16}) se utiliza $s=0.5$ y $z_0=0$. Se realizan 
también experimentos con $z_0 = \infty$ y $z_0 = -\infty$, 
obteniendo resultados muy parecidos en la probabilidad
de escoger un algoritmo frente a otro.


\subsection{Revisión del estado del arte en la aplicación de test bayesianos}

	Se presenta en este apartado una revisión del estado del 
arte con diferentes métodos para la comparación de algoritmos
de aprendizaje automático mediante la realización de test 
estadísticos. 

\paragraph{Versión bayesiana del test de Wilcoxon} 
\cite{BENAVOLI14} Para la comparación de algoritmos mediante
muestras emparejadas, se presenta el test de Wilcoxon en 
versión bayesiana. Se realiza, al igual que en el test
de signo y el \textit{signed-rank}, utilizando el Proceso de
Dirichlet para la distribución \textit{a priori}. La versión 
bayesiana, a diferencia de la no paramétrica, no necesita 
suponer la simetría de las muestras. Una cuestión importante
es la elección de $G_0$ en caso de que no dispongamos
información. El enfoque realizado se basa en la obtención
del límite de $DP$ para $s \rightarrow 0$. Otro enfoque 
consiste en modelar la falta de información \textit{a priori} 
como un conjunto de distribuciones de probabilidad. 

\paragraph{Procedimiento no paramétrico bayesiano para la 
comparación de algoritmos} \cite{BENAVOLI15a} En este 
artículo se presenta la versión bayesiana del test de 
Friedman. Se presenta el test, que utiliza el $DP$ para 
realizar la comparación de dos algoritmos en un primer
momento y la versión para tres o más. Una vez se ha rechazado 
la hipótesis de que los algoritmos se comporten de igual
manera, se procede realizando la comparación dos a dos 
para encontrar dónde se producen las diferencias. Se realiza 
también en este artículo un experimento comparando el test
bayesiano de Friedman con el test $F$-\textit{race}, test que
compara varios algoritmos según aquel que consiga el mejor
resultado.

\paragraph{Test estadístico para el análisis conjunto de 
medidas de rendimiento} \cite{BENAVOLI15b}	Para la 
comparación de algoritmos con respecto a varias medidas
se suelen utilizar o bien la media ponderada de las medidas
para cada algoritmo o bien el frente de Pareto, donde se 
consideran las soluciones no dominadas (aquellas que no son
peor con respecto a otra solución para todos los criterios).
En este artículo se presenta en primer lugar la realización 
de un test basado en el ratio de verosimilitud, que presenta
las mismas desventajas que los THN. Para la realización del
test bayesiano, se opta por usar como distribución 
\textit{a priori} la distribución de Dirichlet, obteniéndose
también como distribución \textit{a posteriori} la 
distribución de Dirichlet de la que se calculan las 
probabilidades deseadas mediante muestras aleatorias.
Finalmente, se presenta una mejora de este método usando
redes bayesianas.

\paragraph{Comparación de algoritmos en múltiples bases de 
datos con CV} \cite{CORANI15} En este artículo se introduce
el $t$-test bayesiano (\ref{ssec:bayes-ttest}) y un test de 
Poisson que compara dos clasificadores en varias bases de 
datos teniendo en cuenta la correlación y la incertidumbre 
provocada por la validación cruzada en cada conjunto de 
datos.

\paragraph{Tutorial para la comparación de clasificadores 
mediante análisis bayesiano}. \cite{BENAVOLI16} Este artículo 
es un artículo divulgativo que presenta las ventajas de los 
test bayesianos y expone su uso en diferentes casos, 
aplicando el $t$-test bayesiano, el test de signos y el $t$-
test bayesiano jerárquico, una extensión que permite realizar 
inferencia en varios conjuntos de datos.










