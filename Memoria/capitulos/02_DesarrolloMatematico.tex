\part{Desarrollo matemático}
\label{part:matematicas}

\chapter{Notación e introducción a la evaluación de algoritmos de aprendizaje}
\label{chapter:Intro}

	En este capítulo se hace un breve repaso de los 
conceptos estadísticos necesarios para comprender el 
contenido de la memoria así como presentar la notación,
una introducción con las medidas de rendimiento y 
diferentes formas de utilizar los datos para 
obtener un valor más preciso del rendimiento.

\section*{Notación}
	
\begin{definicion}[Variable aleatoria]
	Función de conjuntos cuyo dominio es los elementos de un 
espacio muestral sobre el cual se ha definido una función de
probabilidad y cuyo rango es $\mathbb{R}$.\\
	$X$ es una variable aleatoria (v.a.) si para $x \in 
\mathbb{R}$ existe una probabilidad de que el valor tomado 
por la variable aleatoria sea menor o igual que $x$, es
decir, $P(X \leq x) = F_X (x)$, llamada función de
distribución de probabilidad (\textit{cumulative distribution
function}, cdf) de $X$.	
\end{definicion}

	Cualquier función de distribución, $F_X(x)$, de una v.a.
$X$ cumple las siguientes propiedades:
 
\begin{enumerate}
	\item $F_X$ es no decreciente: 
			$F_X(x_1) \leq F_X(x_2) \ \forall x_1 \leq x_2$.
	\item $\underset{x \rightarrow -\infty}{\lim} F_X(x) =
			 0$,
			$\underset{x \rightarrow \infty}{\lim} F_X(x) =
			 1$
	\item $F_X(x)$ es continua por la derecha: 
		$\underset{\varepsilon \rightarrow 0^+}{\lim} 
		F_X(x+\varepsilon) = F_X(x)$
\end{enumerate}
	
\begin{definicion}[Función de densidad]
	Se define la función de densidad como la derivada de 
$F_X(x)$, $f_X(x)$. Para $X$ continua:
	\[ 
		F_X(x) = \int_{-\infty}^x f_X(t) dt; \;
		f_X(x) = \frac{d}{dx}F_X(x) = F_X'(x) \geq 0; \;
		\int_{-\infty}^{\infty} f_X(x) dx = 1 
	\]
\end{definicion}
	
\begin{definicion}[Función de masa]
	Se define la función de masa de probabilidad  
(\textit{probability mass function}, pmf) de una v.a. 
\textbf{discreta}, es decir, que sólo toma un número contable 
de valores como
	\[ 
		f_X(x) = P(X=x) = 
		F_X(x) - 
			\lim_{\varepsilon \rightarrow 0^+} 
				F_X(X-\varepsilon).
	\]
\end{definicion}

\begin{definicion}[Muestra aleatoria]
	Llamamos muestra aleatoria de una v.a. $X$ a un conjunto 
de $n$ v.a., $\mathbf{X} = (X_1, \dots, X_n)$, si son independientes e 
idénticamente distribuidas (i.i.d.), con lo que su 
distribución de probabilidad conjunta es
	\[ 
		f_{\mathbf{X}}(x_1, \dots, x_n) =
		f_{X_1, \dots, X_n}(x_1, \dots, x_n) =
		\prod\limits_{i=1}^n f_X(x_i).
	\]
\end{definicion}
	
\begin{definicion}[Momento]
	Es un parámetro de la población. El momento $k$-ésimo de 
$X$ es $\mu_k' = \mathbb{E}[X^k]$. La media es el momento de 
primer orden, $\mu_1' = \mathbb{E}[X] = \mu$. El momento 
$k$-ésimo centrado es  $\mu_k = \mathbb{E}[(X - \mu)^k]$.
Notamos por $\var$ a la varianza, es decir, el momento 
centrado de segundo orden $\var(X) = \mathbb{E}[(X - \mu)^2]$. 
\end{definicion}

\begin{definicion}[Función generadora de momentos]
	Notamos por $M_{X}(t)$ a la función $\mathbb{E}[
\exp(tX)]$. 
\end{definicion}

	Sea $\hat{\theta}_n = u(X_1, \dots, X_n)$ un estimador de 
un parámetro $\theta$. Incluimos unas propiedades deseables 
de $\hat{\theta}_n$:
	
	\begin{enumerate}
	\item \textit{Insesgadez}: 
			$\mathbb{E}[\hat{\theta}_n] = \theta$ para todo $\theta$.
	\item \textit{Suficiencia}: Podemos escribir
			$f_{X_1, \dots, X_n}(x_1, \dots, x_n; \theta)$ 
			como producto de dos funciones $f_{X_1, \dots, 
			X_n}(x_1, \dots, x_n; \theta) = g(\hat{\theta}_n; 
			\theta) H((x_1, \dots, x_n)$ tal que $H(x_1, 
			\dots, x_n)$ no depende de $\theta$.
	\item \textit{Consistencia}
		\[ 
			\lim_{n \rightarrow \infty} 
				P(|\bar{\theta}_n - \theta| < \varepsilon) =
				 0 \quad 
				 \forall \varepsilon > 0 
		\]
	\begin{enumerate}
		\item Si $\hat{\theta}_n$ es un estimador insesgado 
			de $\theta$ y $\underset{n \rightarrow \infty}
			{\lim} \var(\hat{\theta}_n) = 0$, entonces $
			\hat{\theta}_n$ es un estimador consistente por l
			a desigualdad de Chebyshev.
		\item $\hat{\theta}_n$ es un estimador consistente de 
			$\theta$ si la distribución límite es la 
			distribución degenerada con probabilidad $1$ en 
			$\theta$.
	\end{enumerate}
			
	\item \textit{Mínimo error cuadrático:} 	
			$\mathbb{E}[(\hat{\theta}_n - \theta)^2] \leq
			 \mathbb{E}[(\hat{\theta}_n^* - \theta)^2]$ para cualquier 
			 estimador $\hat{\theta}_n^*$.
	\item \textit{Mínima varianza:} $\var(\hat{\theta}_n)
			\leq \var(\hat{\theta}^*_n)$ para cualquier 
			estimador $\hat{\theta}_n^*$, siendo ambos
			insesgados.
	\end{enumerate}
	
\begin{definicion}[Función de verosimilitud]
	La función de verosimilitud (\textit{likelihood 
function}) de una muestra aleatoria de tamaño $n$ de la 
población $f_X(x;\theta)$ es la probabilidad conjunta de las 
muestras tomadas como función de $\theta$. Esto es:
	\[ L(x_1, \dots, x_n; \theta) = 
		\prod\limits_{i=1}^n f_X(x_i;\theta)	\]
\end{definicion}

	Un \textbf{estimador máximo verosímil} (MLE) de $\theta$ 
es un valor $\bar{\theta}$ tal que 
	\[ 
		L(x_1, \dots, x_n; \bar{\theta}) \geq 
			L(x_1, \dots, x_n; \theta) \; \forall \theta 	
	\]
	
	La relevancia de este estimador consiste en que, para 
unas ciertas condiciones de regularidad, un estimador máximo 
verosímil es suficiente, consistente y asintóticamente 
insesgado, con varianza mínima y con distribución normal.
	
\begin{definicion}[Hipótesis estadística]
	Es una afirmación sobre la la función de probabilidad de 
una o más v.a. o una afirmación sobre las poblaciones de las 
cuales se han obtenido una o más muestras aleatorias. La 
\textbf{hipótesis nula}, $H_0$ es la hipótesis sobre la que 
se realizará un test. La \textbf{hipótesis alternativa}, 
$H_1$ es la que conclusión alcanzada si se rechaza la 
hipótesis nula.
\end{definicion}

\begin{definicion}[Región crítica]
	Llamamos región crítica o región de rechazo $R$ para un 
test al conjunto de valores tomados por el test que conducen 
a rechazar la hipótesis nula. Llamamos \textbf{valores 
críticos} a los extremos de $R$ y los notaremos por $\tau_
\alpha$
\end{definicion}

\begin{definicion}[Tipos de error]\textit{}
	\begin{description}
	\item[Error de tipo I] La hipótesis nula es rechazada 
		siendo cierta.
	\item[Error de tipo II] La hipótesis nula no es rechazada 
		siendo falsa.
	\end{description}
\end{definicion}

	Siendo $T$ un test estadístico con hipótesis $H_0: \theta 
\in \omega, \ H_1: \theta \in \Omega \setminus \omega$, los 
errores de tipo I y II tienen probabilidad
	\[ 
	\alpha(\theta) = P(T \in R | \theta \in \omega); \quad
	\beta(\theta) = 
		P(T \not\in R | 
				\theta \in \Omega \setminus \omega)
	\]
	respectivamente.

\begin{definicion}[Tamaño del test]
	Se define el tamaño del test como $\underset{\theta \in 
	\omega}{\sup}\ \alpha(\theta)$.
\end{definicion}

\begin{definicion}[Potencia del test]
	Se define la potencia del test como la probabilidad de 
que el test conduzca a un rechazo de $H_0$: $Pw(\theta) = P(T 
\in R)$. Esta medida nos interesa cuando debemos rechazar la 
hipótesis nula, con lo que calculamos $Pw(\theta) = P(T \in R 
| \theta \in \Omega \setminus \omega) = 1 - \beta(\theta)$. 
\end{definicion}
	
	Diremos que un test es \textbf{más potente} para una 
hipótesis alternativa concreta si ningún test del mismo 
tamaño tiene mayor potencia contra la misma hipótesis 
alternativa.\\
	A continuación definimos un enfoque distinto,
especialmente relevante en los test no paramétricos. 
	
\begin{definicion}[$p$-valor]
	Probabilidad de obtener, siendo cierta la hipótesis nula 
$H_0$, una muestra aleatoria tan extraña como la muestra
aleatoria observada.
\end{definicion}

\begin{definicion}[Consistencia]
	Diremos que un test es consistente para una hipótesis 
alternativa $H_1$ si la potencia del test se aproxima a 1 
conforme $n \rightarrow \infty$, siendo $n$ el tamaño de la 
muestra.
\end{definicion}

	Notaremos como $\mathbb{I}[\textit{condición}]$ a la 
función indicadora, que toma valor $1$ si \textit{condición} es
cierta y 0 si no.


\section*{Medidas del rendimiento}
	
	El rendimiento de un algoritmo sobre un problema puede 
depender del criterio que los investigadores deseen optimizar 
con lo que el concepto de la \textit{calidad} de un algoritmo 
depende según el problema al que se aplique. Por tanto, 
consideraremos el problema como un problema multiobjetivo. 
Una posible forma de abordarlo es condensar varias medidas en 
una única con la que posteriormente realizar las 
comparaciones necesarias a través de test estadísticos. Se 
presenta a continuación un resumen de las medidas comúnmente 
utilizadas en el campo del aprendizaje automático tanto para 
problemas de clasificación como de regresión, indicando 
ventajas e inconvenientes que nos ayuden a decidir aquella 
medida que mejor se ajuste a nuestro problema.
	
\subsection*{Medidas para problemas de clasificación}

	Las medidas utilizadas habitualmente para problemas de 
clasificación están basadas en la matriz de confusión 
(~\ref{tab:matrizconfusion}). Haremos un listado de aquellas 
más utilizadas sin entrar en las medidas diseñadas \textit{ad 
hoc} para problemas concretos. Suponemos que nos encontramos 
frente a un problema de clasificación binaria, aunque es 
posible extender la matriz de confusión y las medidas para 
problemas de clasificación con un mayor número de clases.
Notaremos por $x, \bar{x}$ la clase positiva y la negativa
respectivamente de nuestro problema, mientras que $y,\bar{y}$
se corresponden con las asignaciones a la clase positiva
y negativa respectivamente. Por tanto, notaremos por $TP$ a
los verdaderos positivos, por $TN$ a los verdaderos negativos,
$FP$ a los falsos positivos y $FN$ a los falsos negativos.

\begin{table}[H]
\centering
\begin{tabular}{cccc}
\cline{1-3}
\multicolumn{1}{|c|}{}           & \multicolumn{2}{c|}{Predicción del clasificador}      &                 \\ \cline{1-3}
\multicolumn{1}{|c|}{Clase real} & \multicolumn{1}{c|}{$y$}    & \multicolumn{1}{c|}{$\bar{y}$}    &                 \\ \cline{1-3}
\multicolumn{1}{|c|}{$x$}          & \multicolumn{1}{c|}{$TP$} & \multicolumn{1}{c|}{$FN$} & $N^+ = TP + FN$ \\ \cline{1-3}
\multicolumn{1}{|c|}{$\bar{x}$}          & \multicolumn{1}{c|}{$FP$} & \multicolumn{1}{c|}{$TN$} & $N^- = FP + TN$ \\ \cline{1-3}
                                & $\hat{N}^+ = TP + FP$     & $\hat{N}^+ = FN + TN$     &   $N = N^- + N^+$             
\end{tabular}
\caption{Matriz de confusión}
\label{tab:matrizconfusion}
\end{table} 

En función de esta matriz se definen las siguientes
medidas.
	
\begin{description}
	\item[Error de clasificación ($\varepsilon$),] 
		$\varepsilon = \frac{FP+FN}{N}$
	\item[Exactitud o \textit{Accuracy}(Acc),] 
		$Acc=\frac{TP+TN}{N}$
	\item[Exhaustividad o \textit{Recall}(r),] $r=\frac{TP}{N^+}$
	\item[Especificidad o \textit{Specificity}(sp),] 
		$sp=\frac{TN}{N^-}$
	\item[Precisión (pr),] 
		$pr=\frac{TP}{\hat{N}^+}$
	\item[Tasa falsos positivos(fpr)] $fpr=1-sp$
	\item[Tasa falsos negativos(fnr)] $fnr=1-r$
	\item[Valor negativo predicho(npv)] 
		$npv=\frac{TN}{\hat{N}^-}$
	\item[Estadístico kappa ($\kappa$)] El propósito de esta 
		medida es medir el grado de acuerdo entre dos 
		observadores, o, en nuestro contexto, compensar los 
		valores aleatorios además de minimizar el efecto de 
		un dispar número de ejemplos en cada clase. 
	\[ 
	\kappa = \frac{N(TP + TN) - N^+\hat{N}^+ - N^-\hat{N}^- }
				  {N^2 - N^+\hat{N}^+ - N^-\hat{N}^- }
	\]
\end{description}
	
	Las medidas de exactitud y el error de 
clasificación son comúnmente usadas debido a que representa 
un concepto claro y son fáciles de calcular.  Es necesario 
indicar que estas medidas son aconsejables cuando las dos 
clases se dan con una frecuencia similar y son igualmente 
relevantes para nuestro problema. Otras medidas como 
\textit{recall}, \textit{specificity} o \textit{precision} 
son más frecuentes en dominios como el de recuperación de 
información y aquellos donde o bien una clase es más 
relevante, o sólo existen unos pocos individuos de 
una clase.\\
	Para encontrar un equilibrio entre la detección de 
elementos de la muestra de ambas clases se han propuesto en 
la literatura (por ejemplo por Santafé, 
\cite{DBLP:journals/air/SantafeIL15}) algunas aproximaciones 
basadas en las anteriores medidas:
	
	\begin{description}
		\item[Compensación entre exhaustividad y 
especificidad.] El método más popular para encontrar 
este equilibrio es el análisis ROC, que consta de una 
representación de $r$ con respecto a $fpr$. Una curva ROC 
puede resumirse en el valor AUC (\textit{area under the ROC 
curve})
		\item[Compensación entre exhaustividad y 
precisión.] Depende del parámetro $\beta$ dado por el 
usuario :
		\[ F_\beta = \frac{(\beta^2+1) pr \cdot r}
						  {\beta^2 pr + r}	\]
	\end{description}

	Cuando en un problema de clasificación supervisada usamos 
un modelo probabilístico obtenemos la probabilidad de 
pertenencia a una de las clases, con lo que podemos realizar 
la asignación variando el umbral. Existen medidas que tratan 
de recoger el grado de proximidad entre esta asignación de 
probabilidad y la distribución real. La más conocida es la 
medida Brier ($BS$),
	\[ BS = \frac{1}{N} \sum\limits_{i=1}^N 
		\sum\limits_{j \in \{c^+,c^-\}}
			\left( P \left( C=j|\mathbf{x}^{(i)} \right) -
			\delta_{j,c^{(i)}} \right) ^2,\]
	donde $P\left(C=j|\mathbf{x}^{(i)}\right)$ es la 
probabilidad asignada por el clasificador a la instancia 
$i$-ésima para la clase $j$, $\delta$ es la delta de 
Kronecker y $c^{(i)}$ es la clase de la instancia 
$i$-ésima.\\
	Hasta ahora las medidas le han dado el mismo peso a los 
errores cometidos en ambos sentidos (asignar a la clase 
positiva una instancia negativa o viceversa), sin embargo se 
pueden incluir \textit{funciones de pérdida} ($\mathcal{L}$) 
según el coste relativo de cada tipo de fallo. Se 
puede considerar que en las medidas anteriores se ha usado 
la función de pérdida 
$\mathcal{L}(x,y) = 1 - \delta_{x,y} $, donde $x$ es la clase 
asignada e $y$ la clase real.
	
\subsubsection*{Medidas de interpretabilidad} 
	En algunos modelos y clasificadores se obtienen reglas 
para la clasificación de nuevos ejemplos. Por ello se valora 
positivamente que estas reglas sean entendibles para el 
usuario. 
	\begin{description}
	\item[Tamaño] Número de reglas que componen el modelo. 
		A menor tamaño, mayor interpretabilidad. 
		$\textit{Tamaño} = n_R$
	\item[Número de antecedentes (ANT)] Para $R_i$ una regla 
		de la forma $\textit{Condi-}$ ${ciones } \rightarrow 
		\textit{ Clase}$ donde las condiciones tienen la 
		forma $(Antecedente_1 \wedge \dots \wedge 
		Antecedente_k)$, definimos $Ant(R_i) = k$ y entonces 
		\[ANT = \frac{1}{n_R} 
				\sum\limits_{i=1}^{n_R} Ant(R_i).\]
	\end{description}


\subsubsection*{Medidas gráficas}

	Prati \textit{et al.} \cite{DBLP:journals/tkde/PratiBM11} afirman que en ocasiones es 
recomendable utilizar una representación gráfica del 
rendimiento ya que evitamos así pérdida de información al 
condensar toda la información en un escalar. En este artículo 
se presenta un conjunto de representaciones gráficas según el 
tipo de variable predicha: clases, ránquin o probabilidad de 
pertenencia a una clase.
	
\paragraph{Predicción de clases}
	\begin{description}
		\item[Gráficas ROC] Como se ha mencionado 
		anteriormente, es una representación del la medida 
		\textit{tpr} frente a \textit{fpr}. Un clasificador 
		será mejor considerado cuanto más arriba y a la 
		izquierda se sitúe en el gráfico. 
		\item[Líneas de coste] Se trata de una modificación 
		de las gráficas ROC para incluir el coste asociado a 
		cada tipo de fallo. Se define el coste esperado para 
		un clasificador como 
		\[ EC = \sum\limits_{X \in \{x, \bar{x}\}} 
		 		\sum\limits_{X \in \{x, \bar{x}\}} 
		 			P(X,Y) \mathcal{L}(X,Y),
		 \]
con $P(X,Y)$ la probabilidad de clasificar como $Y$ un
elemento de la clase $X$ y $\mathcal{L}(X,Y)$ la
función de coste asociado a considerar $Y$ un elemento
de la clase $X$.
Entonces, se definen $NormEC = \frac{EC}{maxEC}$, $PC = 
\frac{p(x) \mathcal{L}(\bar{x},y)}{maxEC}$, donde $maxEC 
= p(x)\mathcal{L}(\bar{x},y)+p(\bar{x})\mathcal{L}(x,
\bar{y})$.  La gráfica representa la $PC$ frente a 
$NormEC$. Ahora cada clasificador, representado por un 
punto en la gráfica ROC, es una línea. El clasificador 
representado por el punto $(0,0)$ en la gráfica ROC (asigna a 
todos los puntos la clase negativa) ahora se representa 
mediante la recta $NormEC=PC$ y el punto $(1,1)$ mediante la 
recta $NormEC= 1-PC$. Dependiendo del coste relativo de la 
clase positiva ($PC$), será el mejor clasificador aquel con 
menor $NormEC$.
	\end{description}

\paragraph{Predicción de \textit{ranking}} 	
	\begin{description}
		\item[Curvas ROC] Se traslada el problema a uno de 
		clasificación mediante la asignación a la clase 
		positiva del \textit{top} $n\%$. Se varía el 
		porcentaje del $0\%$ al $100\%$ para obtener la curva 
		ROC.
		\item[Curvas de coste] Se trata de la transformación 
		análoga a las curvas ROC para las líneas de coste.
		\item[Curvas \textit{precision-recall}] Usadas 
		habitualmente en el ámbito de la recuperación de 
		información. Representan $precision$ frente a 
		$recall$.
		\item[Gráfica \textit{lift}] Similar a la gráfica 
		ROC, representa $tpr$ frente a la probabilidad de 
		asignar a un individuo la clase positiva. 
		\item[Gráfica ROI] Similar a las gráficas 
		\textit{lift}, pero representando en el eje $Y$ el 
		beneficio esperado 
		\[	TEP = N \sum\limits_{X \in \{x,\bar{x}\}}
					\sum\limits_{Y \in \{y,\bar{y}\}}
						p(X,Y) \mathcal{L}(X,Y) p(X) \]
	\end{description}

\paragraph{Predicción de probabilidad de pertenencia a una clase} 	
	\begin{description}
		\item[\textit{Reliability diagram}] Contiene dos
		gráficas. Una es $p(x|j)$ según $j$, que mide el 
		grado en que concuerdan las predicciones con la
		frecuencia de los casos positivos. La segunda gráfica 
		se corresponde con $p(y_j)$ según $j$, identificada 
		con la confianza en la predicción.
		\item[Diagrama de atributos] Para evaluar las mejoras 
		relativas de un sistema de predicción con respecto a 
		uno de referencia se define la $BSS$ (\textit{Brier 
		skill score})
			\[BSS = 1 - \frac{BS}{BS_{ref}} \]
		El diagrama de atributos es un refinamiento del
		\textit{reliability diagram}, al que se le añaden 
		tres líneas: 
			\begin{description}
			\item[Línea de no resolución:] línea horizontal 
			donde $p(x|j)=p(x)$.
			\item[Línea de máxima resolución:] línea vertical 
			que intersecta a la diagonal en el mismo punto 
			que la línea de no resolución.
			\item[Clasificador de referencia:] Bisectriz 
			entre la diagonal principal y la línea de no 
			resolución. Representa los puntos cuya precisión 
			(\textit{accuracy}) es menor que en el modelo de 
			referencia.
			\end{description}
		\item[\textit{Discrimination diagram}] Gráfica de 
		$P(Y|X)$ según $y_j$. Contiene las curvas de 
		$p(y_j|x)$ y de $p(y_j|\bar{x})$. En el mejor de los 
		casos, estas dos curvas no se solaparían y podríamos 
		saber la clase según $y_j$.
	\end{description}
	
	
\subsection*{Medidas para problemas de regresión}

	Las medidas para un problema de regresión están basadas 
en la distancia entre el valor real de la instancia y el 
valor predicho. Consideraremos que calculamos el error de la 
predicción del algoritmo $f$ aplicado a los datos $x_1, 
\dots, x_N$ con valor $y_1, \dots, y_N$ respectivamente.
	
\begin{description}
	\item[\textit{Mean squared error} (MSE)]: Error 
	cuadrático medio
		\[ MSE(f) = \frac{1}{N} \sum\limits_{i=1}^N
								(y_i - f(x_i))^2	\]
	\item[\textit{Root mean squared error} (RMSE)]: Raíz del 
	error cuadrático medio
		\[ RMSE(f) = \sqrt{\frac{1}{N} 
		\sum\limits_{i=1}^N (y_i - f(x_i))^2}	\]
		
	\item[\textit{Mean absolute error} (MAE)]: Error 
	absoluto medio
		\[ MAE(f) = \frac{1}{N} \sum\limits_{i=1}^N
								|y_i - f(x_i)|	\]
\end{description}

	Las medidas $MSE$ y $RMSE$ son más utilizadas debido a la 
penalización de los errores mayores. 

\section{Validación cruzada y remuestreo}
\label{sec:CV}
	
	Para la repetición de los experimentos, necesitamos un 
número de conjuntos de entrenamiento y validación del 
conjunto de datos disponible. Si el conjunto es 
suficientemente grande, podemos dividir aleatoriamente el 
conjunto en $K$ partes, y de cada parte seleccionar la mitad 
para entrenamiento y la otra mitad para test. $K$ suele ser 
10 ó 30. Sin embargo, los conjuntos de datos no suelen ser 
tan grandes. Por tanto, lo que habitualmente se realiza es 
utilizar varias veces los mismos datos pero de formas 
distintas, lo que se conoce como \textbf{validación cruzada} 
(\textit{cross-validation}, CV). Otro concepto a tener en 
cuenta es el de \textbf{estratificación}. Consiste en 
mantener la proporción de las diferentes clases en cada una 
de las particiones realizadas en la base de datos. 
	
\paragraph{Validación cruzada con $K$-fold} Se divide el 
conjunto de datos $\mathcal{X}$ en $K$ partes aleatoriamente, 
$\mathcal{X} = \mathcal{X}_1 \cup \dots \cup \mathcal{X}_K$. 
Para formar cada par de datos de entrenamiento y validación, 
$(\mathcal{T}, \mathcal{V})$, se mantiene una de las $K$ 
partes y se unen las demás partes como conjunto de 
entrenamiento
\begin{align*}
	\mathcal{V}_i &= \mathcal{X}_i \\
	\mathcal{T}_i &= \underset{j=1,\dots,K; j\neq i}
							\bigcup \mathcal{X}_j
\end{align*} 
	El problema de este método es que el conjunto de 
validación es pequeño (lo que lleva a una mayor variabilidad 
en el error). Además, los conjuntos de entrenamiento se 
solapan considerablemente. $K$ es habitualmente 10 ó 30. 
Conforme $K$ crece, se incrementa la robustez al afectar 
menos cada dato concreto. El caso $K = n-1$, se conoce como 
\textit{leave-one-out}. 

\paragraph{$5 \times 2$ CV} Otra propuesta consiste en 
dividir $\mathcal{X}$ en dos partes, utilizar una de estas 
partes como datos de entrenamiento y la otra como test e 
invertir los roles. Para obtener el segundo \textit{fold}, se 
realiza otra partición aleatoria de $\mathcal{X}$ y se repite 
el proceso. Lo habitual es que se realice cinco veces, 
obteniendo así diez parejas $(\mathcal{T}, \mathcal{V})$. 
Aunque podría realizarse más veces, al realizarse más veces 
los conjuntos comparten muchas instancias y por lo tanto los 
errores son muy dependientes entre sí, con lo que no se 
aporta nueva información. Si se realiza menos de cinco veces, 
se obtienen pocas muestras y es más complejo comprobar las 
hipótesis.

\paragraph{\textit{Bootstrapping}} Para generar varias 
muestras a partir de una única se seleccionan instancias de 
la original con reemplazamiento. Puede solaparse más que con 
CV, con lo que las estimaciones resultan más dependientes. 
Por ello, se recomienda especialmente para conjuntos de datos 
muy pequeños en los que se necesiten mayores muestras. 

	Al realizar \textit{bootstrap}, se seleccionan $N$ 
instancias de un conjunto de tamaño $N$ con reemplazamiento. 
El conjunto original se usa como conjunto de validación. La 
probabilidad de no seleccionar una instancia es $1-1/N$, con 
lo que la probabilidad de no seleccionarla tras $N$ 
elecciones es $\left(1- \frac{1}{N}\right)^N \approx e^{-1} 
\approx 0.368$. Esto significa que el conjunto de 
entrenamiento contiene aproximadamente un $63.2\%$ de los 
datos. Para obtener una mejor estimación del error, se 
propone repetir el proceso y observar el comportamiento 
medio.
	
	
\chapter{Test paramétricos}
\label{chapter:test_parametricos}

	Los test paramétricos se basan en la suposición de que la
muestra pertenece a una distribución que sigue un modelo 
conocido (frecuentemente, un modelo gaussiano). La ventaja de 
este enfoque es que la definición del modelo atiende a un 
pequeño número de parámetros (son los estadísticos 
suficientes). Estimando estos parámetros a partir de la 
muestra, se conoce la distribución. 
	
\section{Test binomial para una muestra}

	Con este test se pretende comprobar si en una población
compuesta por dos categorías de la que se extrae la muestra, 
la proporción de observaciones de una de las categorías es 
igual a un valor concreto. En nuestro contexto, consideramos 
$\theta$ la probabilidad del clasificador de cometer un error 
y queremos realizar una hipótesis sobre el valor de $\theta$. 
Supongamos que tenemos una muestra de tamaño $N$, 
$\{(x_i, y_i): i = 1, \dots,N \}$ con $y_i$ la categoría y
consideraremos la variable aleatoria $X$ que denota el número
de errores cometidos por el clasificador $f$,
	\[ 
		X = \sum\limits_{i=1}^N 
				\mathbb{I}[f(x_i) \neq y_i].
	\]
	
	El test a realizar consiste en comprobar si la probabilidad de 
cometer un error $\theta$ es igual a un valor $\theta_0$
dado: $H_0: \theta = \theta_0;\ H_1: \theta \neq \theta_0$.
La probabilidad de cometer $j$ errores de $N$ supuesta $H_0$
será $P[X = j] = {N \choose j} \theta^j (1-p)^{N-j}$. Se 
rechazará la hipótesis nula si el $p$-valor observado 
es menor que el valor $\alpha/2$ (al considerar la hipótesis 
alternativa no direccional).\\
	Cuando el tamaño de la muestra es grande el test 
estadístico para la binomial puede ser aproximado con la 
distribución $\chi^2$ con un grado de libertad. Hay varias 
opiniones con respecto al tamaño mínimo para realizar
esta aproximación. Se pueden tomar referencia que 
$N \theta_0$ y $N (1 - \theta_0)$ sean mayores que 5. El 
estadístico para realizar el test usando esta 
aproximación será:
	\[
		z = \frac{X/N - \theta_0}
				{\sqrt{\frac{\theta_0(1 - \theta_0)}
							{N}}}
	\]
	
\section{$t$-Test para muestras apareadas}

	Nos ocupamos aquí de esta versión del $t$-test para 
muestras independientes apareadas con varianzas 
desconocidas por tener una mayor relevancia en la evaluación 
de algoritmos de aprendizaje automático. Suponiendo que 
disponemos de los datos del rendimiento de dos algoritmos, 
realizamos el test para comprobar si éstos se corresponden 
con los propios de dos poblaciones con diferentes medias. 
Para estimar el valor de las medias de las poblaciones, 
notaremos por $\bar{X}_1, \bar{X}_2$ a las medias de las dos 
muestras. Las condiciones para realizar este test son:
	
	\begin{itemize}
	\item Cada muestra ha sido seleccionada aleatoriamente 
		de la población a la que representa.
	\item La distribución de los datos de las poblaciones de 
		las que se extraen las muestras son normales.
	\item Homogeneidad de las varianzas: La varianza de las 
		dos poblaciones son iguales ($\sigma_1 = \sigma_2$).
	\end{itemize}
	
	Nótese que si la varianza es conocida, es más apropiado 
usar el $z$-test.\\
	La hipótesis nula será por tanto $H_0: \mu_1 = \mu_2$.
El test se realiza utilizando el estadístico $t$:
\begin{align*}
	t 	= \frac{\bar{d}}
			{\frac{\bar{\sigma}_d}{\sqrt{N}}}
		= \frac{\bar{X}_1 - \bar{X}_2}
			{\frac{\bar{\sigma}_d}{\sqrt{N}}},
\end{align*}
	
	donde $N$ es el número de datos de la muestra, 
$\bar{X}_i,\ i=1,2$  es la media $\frac{1}{N}
\sum\limits_{j=1}^{N} X_{ij}$ de los  valores obtenidos en 
cada muestra, $\bar{d}$ es la diferencia de las medias y 
$\bar{\sigma}_d$ es el estimador para la desviación típica
de las diferencias:
	\[
		\bar{\sigma}_d =
			\sqrt{
			\frac{\sum\limits_{i=1}^{N} (d_i - \bar{d})^2}
				{N - 1}
			}.
	\]
	
	El valor $t$ obtenido se comparará con el valor crítico
para la distribución $t$ de Student con $N - 1$ 
grados de libertad.\\
	Una versión más general de este test es el $t$-test de
Welch para muestras no apareadas de tamaños $N_1, N_2$
cuyo estadístico es
	\[
		t = \frac{\bar{X}_1 - \bar{X}_2}
				{\sqrt{ \frac{\sigma_1^2}{N_1} +
						\frac{\sigma_2^2}{N_2}}},
	\]
	con $\sigma_i^2,\ i=1,2$ la varianza de la muestra.
	
\paragraph{Tamaño del efecto} El $t$-test determina si las 
diferencias observadas son significativas, pero no si 
estas diferencias tienen importancia práctica, es decir, 
se observa un efecto, una diferencia entre los 
clasificadores, pero no se cuantifica esta diferencia
(crítica que se le hace desde la estadística bayesiana,
como veremos). El tamaño del efecto para este test se
suele realizar con el estadístico $d$ de Cohen:
	\[
		d_{Cohen} = \frac{\bar{X_1}-\bar{X_2}}
					{\sigma_p},
	\]
	con $\sigma_p = \sqrt{\frac{\sigma_1^2 + \sigma_2^2}{2}}$
la raíz de la media de las varianzas de las respectivas muestras.
La interpretación del estadístico propuesta por Cohen es:
	\begin{itemize}
	\item $d_{Cohen}$ en torno a $0.2, 0.3$ denota un 
		efecto pequeño, posiblemente significativo.
	\item $d_{Cohen}$ sobre $0.5$ significa un efecto medio,
		observable.
	\item $d_{Cohen}$ de $0.8$ significa un gran tamaño del 
		efecto.
	\end{itemize}
	
		
\section{Análisis de la varianza}

	Estos test resultan insuficientes a la hora de comparar 
múltiples clasificadores. Aunque puede usarse el $t$-test para 
realizar repetidas comparaciones entre distintos 
clasificadores, esto plantea el problema de que son 
necesarios numerosos test para realizar todas las 
combinaciones y por tanto la información que se obtiene es
más difícil de analizar. Otro problema asociado es el 
incremento de la probabilidad de cometer un error de tipo I. 
Presentamos en esta sección la versión paramétrica, ANOVA.\\
	En este test, al igual que en el $t$-test, la hipótesis 
hace referencia a las medias de las poblaciones de las que 
se extraen las muestras, sin embargo, la hipótesis nula es
	\[
		H_0 : \mu_1 = \mu_2 = \dots = \mu_k,
	\]
	frente a la hipótesis alternativa
	\[
		H_1 : \mu_r \neq \mu_s \text{ para algún par }
			(r, s), r \neq s 
	\]
	
	El test ANOVA puede tratar con tres tipos de varianzas
si los datos están clasificados en grupos (como es nuestro
caso, donde los datos se podrán agrupar bien por los errores
de todos los clasificadores en una base de datos, o bien por
los errores de un clasificador en todas las conjuntos de datos):
	\begin{enumerate}
	\item variación en un grupo,
	\item variación entre grupos, y
	\item variación total, como combinación de las 
		dos anteriores.
	\end{enumerate}

	Consideraremos para realizar este test que disponemos de 
$n$ conjuntos de datos y $k$ clasificadores. Notaremos por 
$X_{ij}$ el rendimiento del algoritmo $j$ para la base de 
datos $i$. Así, $\bar{\bar{X}}$ se refiere a la media entre 
todos los valores de los clasificadores para las bases de
datos; $\bar{X}_{i \cdot}$ la media para la base de datos $i$ 
y $\bar{X}_{\cdot j}$ la media del clasificador $f_j$.\\
	El modelo para el rendimiento de un clasificador en una 
base de datos es
	\[
		X_{ij} = \bar{\bar{X}} + \alpha_i + e_{ij},
	\]
	donde $\alpha_i$ es la variabilidad del rendimiento entre 
los distintos conjuntos de datos, que representa una v.a. con media 0 y
varianza $\sigma_A^2$ y $e_{ij}$ representa la variabilidad
dentro del propio conjunto de datos, v.a. con media 
0 y varianza $\sigma^2$. Tanto $\alpha_i$ como
$e_{ij}$ se suponen normales. Además, se supone $e_{ij}$ 
independiente de $\alpha_i$ y de los demás $e_{ij}$.\\
	Definiremos en primer lugar algunas medidas de la 
variación, como la existente debida a los clasificadores
	\[ 
		SS_C = \sum\limits_{j=1}^k
				 \sum\limits_{i=1}^m
					\left( \bar{X}_{\cdot j} - 
						   \bar{\bar{X}} \right)^2 =
				n \sum\limits_{j=1}^k
					\left( \bar{X}_{\cdot j} - 
					  	   \bar{\bar{X}} \right)^2,
	\]
	de igual manera, la variación relativa a los conjuntos de
datos:
	\[ 
		SS_B = k \sum\limits_{i=1}^n
					\left( \bar{X}_{i \cdot} - 
					  	   \bar{\bar{X}} \right)^2.
	\]
	
	La variación total entre clasificadores se obtiene con
	\[
		SS_{Total} =  
			\sum\limits_{j=1}^k
				\sum\limits_{i=1}^m
					\left( \bar{X}_{ij} - 
						   \bar{\bar{X}} \right)^2.
	\]
			
	La variación en el error se deriva de la diferencia entre 
la variación total y la combinación de $SS_B$ y $SS_C$:
	\[
		SS_{Error} = SS_{Total} - (SS_B + SS_C).
	\]
	
	Definimos ahora los estadísticos a partir de los cuales 
realizaremos el test. En primer lugar, la variabilidad entre
clasificadores:
	\[
		MS_C = \frac{SS_C}{k-1},
	\]
	con $k-1$ el grado de libertad de $SS_C$. El segundo 
estadístico hace referencia a la variabilidad dentro de los 
clasificadores:
	\[
		MS_{Error} = \frac{SS_{Error}}{(n-1)(k-1)},
	\]
	con $(n-1)(k-1)$ los grados de libertad de $SS_{Error}$.
Finalmente, el estadístico con el que se lleva a cabo el
test, el cociente $F$ se obtiene como
	\[
		F = \frac{MS_C}{MS_{Error}},
	\]
	que sigue una distribución $F$ de Snedecor con $k-1$ y
$(n-1)(k-1)$ grados de libertad.

\paragraph{ANOVA de una vía} Se trata de un modelo más 
simple que no distingue entre la variabilidad dentro de los
conjuntos de datos y entre conjuntos de datos, sino que ambas
variabilidades se analizan de forma conjunta. En términos del
caso anterior, $X_{ij} = \bar{\bar{X}} + \alpha_i + e_{ij}$, 
con $\alpha_i = \bar{X}_{\cdot j} - \bar{\bar{X}}$ y $e_{ij}$
hace referencia al error aleatorio, que sigue una 
distribución normal, con media $0$ y varianza $\sigma^2$. \\
	Al calcular los estadísticos necesarios, tenemos que los 
grados de libertad de $SS_{Error} = SS_{Total} - SS_{C}$ son 
$nk-k$ y por consiguiente $MS_{Error} = \frac{SS_{Error}}
{nk-k}$. Este test asume la independencia entre las muestras
a diferencia del test ANOVA previo, donde la correlación de 
las muestras, esto es, el rendimiento de cada algoritmo para
el mismo conjunto de datos se tenía en cuenta. Además, este
test tiene una menor potencia.
	

\chapter{Test no paramétricos}
\label{chapter:test_no_parametricos}

	Para poder comprender este concepto, definimos la familia 
no paramétrica de distribuciones en términos de Pesarin 
(\cite{pesarin2010permutation}), sobre 
la que se realizan los test no paramétricos. 
 
\begin{definicion}[Familia de distribuciones no paramétrica]
	Una familia de distribuciones $\mathcal{P}$ se dice que 
se comporta de manera no paramétrica cuando no es posible
encontrar un espacio de dimensión finita $\Theta$ tal que hay 
una relación uno a uno entre $\Theta$ y $\mathcal{P}$, en el 
sentido en que cada elemento $P \in \mathcal{P}$ no puede ser 
identificado por un único elemento $\theta \in \Theta$ y 
viceversa.
\end{definicion}

	Si existiese esta relación, $\mathcal{P}$ sería una 
familia paramétrica y $\theta$ sería el parámetro.\\
	En base a esta definición, consideraremos la inferencia 
estadística no paramétrica aquella que se realiza sobre una 
muestra suponiendo la pertenencia de ésta a una familia no 
paramétrica de distribuciones. Un concepto relacionado es la 
propiedad de ser libre de distribución, del que tomamos la definición de Hollander (\cite{Hollander99}):
	
\begin{definicion}[Libre de distribución]
	Decimos que un estadístico es libre de distribución si 
para $H_0$ cierta, la distribución del estadístico no depende 
de la distribución $F$ de la población.
\end{definicion}
	
\section{Comparación con test paramétricos}
	
	En la inferencia clásica se efectúan suposiciones sobre 
la población de la que se extraen muestras para realizar la 
inferencia. Aunque estas suposiciones están normalmente 
justificadas, en ocasiones no se dan las circunstancias 
necesarias para aplicar estas técnicas o su uso no está bien 
documentado. Por ello surgen las técnicas no paramétricas. 
Nótese que es distinta la suposición al aplicar estas 
técnicas no paramétricas, pues consideramos en este caso que 
no conocemos su distribución.\\
 	La principal ventaja de los test no paramétricos es que  
las hipótesis son más generales con lo que se pueden aplicar 
en un mayor número de problemas. Una de las condiciones 
habituales es la continuidad, aunque hay otras condiciones 
más estrictas como que la población sea simétrica para según 
qué test. Esto repercute en que se le pueden aplicar 
funciones a las muestras obtenidas para la realización de los 
test, a diferencia de en los test paramétricos dado que las 
muestras deben generalmente provenir de una población de 
forma conocida.\\
	Hay test de hipótesis que no están relacionados con 
valores de parámetros (a diferencia de los paramétricos). Son 
más simples de aplicar, las matemáticas, menos sofisticadas y 
basadas en la combinatoria, están relacionadas con las 
propiedades usadas en el proceso inductivo. 
Además, las distribuciones asintóticas son 
distribuciones conocidas como la normal o la chi cuadrado. Al 
relajar las condiciones sobre los datos de entrada, es menos 
sensible al \textit{dirty-data}, datos con errores usados en 
el entrenamiento del clasificador. Esto implica una mayor 
robustez en los test no paramétricos.\\
 	Correctamente aplicados, los test paramétricos, al 
disponer de mayor información tienen una mayor potencia, sin 
embargo, cuando se disponen de menos datos, y por tanto es 
más difícil que se den las condiciones de los test 
paramétricos, la potencia es similar. Además, en esta 
situación, la falta de eficiencia de los test no paramétricos 
se suple con la falta de precisión de los test paramétricos 
al aproximar la distribución de los datos por la distribución 
asintótica conocida.\\


 	Se incluye en esta sección el desarrollo de los test no
paramétricos más utilizados en aprendizaje automático 
utilizando como referencia las indicaciones de Gibbons y 
Chakraborti (\cite{DBLP:reference/stat/GibbonsC11}) y Sheskin 
(\cite{sheskin2003handbook}).
 	
 	
\section{Test de aleatoriedad}

	Una de las condiciones para la realización de los test 
estadísticos, tanto de los paramétricos como de los no 
paramétricos, es la aleatoriedad de la muestra de partida. La 
hipótesis nula para los test que serán presentados en esta 
sección será la aleatoriedad de la muestra, mientras que la 
hipótesis alternativa será la presencia de un patrón. 
En el problema que nos ocupa, podríamos usar estos test 
en el estudio del efecto de un parámetro, partiendo de la
hipótesis nula de que dicho parámetro no afecta (y por tanto
los resultados son aleatorios) mientras que la hipótesis
alternativa contempla la existencia de un patrón conforme
este parámetro crece o decrece.

\subsection{Test basado en el número de rachas}

	Supongamos una secuencia de $n$ elementos de dos tipos, 
$n_1$ del primer tipo y $n_2$ del segundo, $n = n_1 + n_2$. 
Sea $R_1$ el número de rachas del primer tipo, $R_2$ el 
número de rachas del segundo tipo, $R = R_1 + R_2$. Siendo 
cierta la hipótesis nula (la aleatoriedad de la muestra), 
procedemos a obtener la distribución de $R$.
	
\begin{lema} 
	El número de formas distintas de distribuir $n$ objetos 
en $r$ posiciones consecutivas es ${n-1 \choose r-1}, n \geq 
r, r \geq 1$.
\end{lema}

\begin{teorema}
	Sean $R_1$ y $R_2$ los números de rachas de los $n_1$ de 
tipo 1 y los $n_2$ elementos de tipo 2 respectivamente en una 
muestra de tamaño $n = n_1 + n_2$. La función de distribución 
de probabilidad conjunta de $R_1$ y $R_2$ es
	\[ f_{R_1,R_2} (r_1, r_2) = 
		\frac{c {n_1 - 1 \choose r_1 - 1} 
				{n_2 - 1 \choose r_2 - 1}}
			{{n_1 + n_2 \choose n_1}}\;
		\begin{array}{l}
			r_1 = 1,2, \dots, n_1 \\
			r_2 = 1,2, \dots, n_2 \\
			r_1 = r_2 \text{ ó } r_1 = r_2 \pm 1
		\end{array}
	\]
	donde $c=2$ si $r_1 = r_2$ (hay igual número de rachas de 
elementos del tipo 1 y del tipo 2) y $c=1$ si $r_1 = 
r_2 \pm 1$ (hay una racha más del tipo 1 ó 2).
\end{teorema}

	Para muestras de un mayor tamaño (aquellas en el que 
$n_1, n_2 \geq 10$) se suele utilizar una aproximación 
utilizando la distribución asintótica supuesto cierta 
$H_0$.\\
	Suponemos que el tamaño de la muestra $n \rightarrow 
\infty$, de forma en que $\frac{n_1}{n} \rightarrow \lambda$, 
$0<\lambda<1$. De aquí obtenemos
	\[ \underset{n \rightarrow \infty}{\lim} \mathbb{E}[R/n] = 
			2\lambda (1-\lambda) 
				\underset{n \rightarrow \infty}{\lim} 
					\var(R\sqrt{n}) =
			4\lambda^2(1-\lambda)^2
	\]
	
\begin{teorema}
	La distribución de probabilidad de $R$, es decir, el 
número total de rachas en una muestra aleatoria es:
	
	\begin{equation}
		f_R(r) = \left\lbrace\begin{array}{ll}
	2 {n_1-1 \choose r/2-1} {n_2-1 \choose r/2-1} 
		\big/ {n_1 + n_2 \choose n_1} &
			\textit{ si } r \text{ es par} \\
	\left[
		{n_1-1 \choose (r-1)/2} {n_2-1 \choose (r-3)/2} +  
		{n_1-1 \choose (r-3)/2} {n_2-1 \choose (r-1)/2} 
	\right]
		\big/ {n_1 + n_2 \choose n_1} &
			\textit{ si } r \text{ es impar} \\		
		\end{array}\right.
	\label{th-dist-R}
	\end{equation}
	para $r=2, 3, \dots, n_1 + n_2.$
\end{teorema}
	
	Si llamamos $Z = \frac{R - 2n\lambda (1-\lambda)}
{2 \sqrt{n}\lambda (1-\lambda)}$ y sustituimos en 
\ref{th-dist-R}, obtenemos la distribución estandarizada de 
$R$, $f_Z(z)$. Entonces aplicamos la fórmula de Stirling y el 
límite queda de la forma
	\[ \underset{n \rightarrow \infty}{\lim} \log f_Z(z)=
			-\log \sqrt{2\pi} - \frac{1}{2} z^2,	\]
	con lo que la distribución límite de $Z$ es la normal. 
	
	
\subsubsection{Test basado en rachas crecientes y decrecientes}	

	Para este test consideramos una serie de datos de tipo 
numérico ordenados temporalmente y queremos comprobar la 
hipótesis de la aleatoriedad de la muestra.\\
	Para una muestra de $n$ elementos, supongamos que podemos 
ordenarlos de la forma $a_1 < \dots < a_n$ (estamos 
suponiendo que no hay dos iguales). Si la hipótesis nula fuese 
cierta, nuestra muestra se corresponderá con una de las $n!$ 
permutaciones con igual probabilidad. Usaremos para este test 
las rachas crecientes y decrecientes. Construimos la 
secuencia $D_{n-1}$, cuyo elemento $i$-ésimo es el signo de 
$x_{i+1} - x_i,\ i=1, \dots, n-1$. Sean $R_1, \dots, R_{n-1}$ 
el número de rachas de longitud $1, \dots, n-1$ 
respectivamente. $f_n(r_{n-1}, \dots, r_1)$ indica la 
probabilidad de obtener $r_j$ rachas de longitud $j$ supuesta 
cierta la hipótesis nula. Escribiremos como $u_n$ la 
frecuencia absoluta $f_n = \frac{u_n}{n!}$. Para obtener la 
función de distribución, partiremos del caso $n=3$.\\
	Sean $a_1 < a_2 < a_3$. La distribución de probabilidad 
será 
	\[ 
	f_3(r_2, r_1) = 
		\left\lbrace\begin{array}{cc}
			\frac{2}{6} & \text{si } r_2 = 1, r_1 = 0 \\
			\frac{4}{6} & \text{si } r_2 = 0, r_1 = 2 
		\end{array}\right.
	\]
	dado que las únicas rachas de longitud 2 son 
$(a_1, a_2, a_3) \rightarrow (+,+)$ y $(a_3, a_2, a_1)$ 
$\rightarrow (-,-)$, siendo las demás posibles combinaciones 
dos rachas de longitud 1.\\
	Las posibilidades a la hora de insertar un elemento $a_n$ 
en las permutaciones de $S_n$ son:
\begin{enumerate}
	\item Se añade una racha de longitud 1.
	\item Una racha de longitud $i-1$ se convierte en una 
		de longitud $i$, $i=2,\dots n-1$.
	\item Una racha de longitud $h=2i$ se convierte en una de 
		longitud $i$, seguida por otra de longitud $1$, 
		seguida por otra de longitud $i$.
	\item Una racha de longitud $h=i+j$ se convierte en
	\begin{enumerate}
		\item Una racha de longitud $i$ seguida por otra de 	
			longitud $1$ seguida por otra de longitud $j$,
		\item Una racha de longitud $j$ seguida por otra de 	
			longitud $1$ seguida por otra de longitud $i$,
	\end{enumerate}
		con $h>i>j$, $3 \leq h \leq n-2$.
\end{enumerate}

	De forma general, la frecuencia $u_n$ conocido $u_{n-1}$ 
sigue la siguiente relación:
\begin{align*}
	& u_n (r_{n-1}, \dots, r_h, \dots, r_i, \dots, r_j, 
			\dots, r_1)= 
		2 u_{n-1}(r_{n-2}, \dots, r_1-1) \\
	&+ \sum\limits_{i=2}^{n-1} 
		(r_{i-1} + 1)
		u_{n-1}(r_{n-2},\dots, r_i-1, r_{i-1}+1,\dots, r_1)\\
	&+ \sum\limits_{i=1, h=2i}^{\lfloor (n-2)/2 \rfloor} 
		(r_{h} + 1)
		u_{n-1}(r_{n-2},\dots, r_h+1,\dots r_i-2,
				\dots, r_1-1)\\
	&+ 2 \underbrace{\sum\limits_{i=2}^{n-3} 
		\sum\limits_{j=1}^{i-1}}_{h=i+j, h \leq n-2}
		(r_{h} + 1)
		u_{n-1}(r_{n-2},\dots, r_h+1,\dots, r_i-1,
				\dots, r_1-1)			
\end{align*}
	
	Otro test que se podría realizar es el del número total 
de rachas, independientemente de su longitud. El número de 
rachas total sería $R = \sum\limits_{i=1}^{n-1} R_i$. Usando 
el procedimiento anterior, se llega a que la distribución 
del estadístico $\frac{R-\mu}{\sigma}$ con $\mu = 
\frac{2n-1}{3}$ y $\sigma^2=\frac{16n-29}{90}$ es la 
normal estándar.
	
\section{Test de bondad del ajuste}

	Una cuestión relevante en la estadística es la obtención 
de la forma de la población de la que se obtiene una muestra. 
En los test paramétricos, como se ha mencionado previamente, 
es habitual que la información relativa a la forma de la 
población se incluya entre las condiciones, por ejemplo en el 
test basado en la distribución $t$ de Student es necesaria la 
normalidad de la población. Por consiguiente, nos interesa 
disponer de test que nos indiquen cómo de confiable es la 
hipótesis de la normalidad para nuestra muestra. Los test de 
bondad del ajuste se ocupan de la forma de la población y no 
de la distribución concreta incluyendo parámetros de escala o 
localización. La utilización de estos test en nuestro problema
nos permiten, según los resultados, justificar el
uso de test paramétricos para realizar la comparación. Tras
la aplicación de estos test podríamos, si los datos
fuesen consistentes con la hipótesis de normalidad,
decidirnos por la aplicación del test ANOVA en lugar
de uno no paramétrico.
	
\subsection{Test chi cuadrado}

	Sea una muestra aleatoria de tamaño $n$ obtenida de una 
población con función de distribución desconocida $F_X$. El 
test tendrá como hipótesis nula
		\[ H_0: F_X(x) = F_0(x) \ \forall x \]
	con $F_0$ conocida contra
		\[ H_1: F_X(x) \neq F_0(x) \text{ para algún }  x \]
	Para realizar este test, los datos deben disponerse en
categorías, bien mediante los valores que toma la variable 
para distribuciones discretas o mediante rangos especificados 
al realizar el experimento para distribuciones continuas. Una 
vez realizadas estas categorías podemos obtener las 
frecuencia esperada si la hipótesis nula es cierta de 
$F_0(x)$.\\
	
	Supongamos que disponemos de $n$ muestras clasificadas en 
$k$ categorías mutuamente excluyentes. Sea $f_i$ la 
frecuencia observada y $e_i$ la frecuencia esperada para cada 
muestra. El estadístico que definimos para la realización de 
este test es $Q = \sum\limits_{i=1}^k 
\frac{(f_i-e_i)^2}{e_i}$, para el cual estudiaremos su 
distribución asintótica.\\
	
	Sean $\theta_1, \dots, \theta_k$ las probabilidades de 
pertenencia a cada clase y $f_1, \dots, f_k$ los valores 
observados. La función de verosimilitud será:
	
	\[ L(\theta_1, \dots, \theta_k) = 
			\prod\limits_{i=1}^k \theta_i^{f_i},\			
	   \text{ con } f_i = 0, 1, \dots, n; \
	   \sum\limits_{i=1}^k \theta_i = 1, \
	   \sum\limits_{i=1}^k f_i = n
	 \]
	 
	Podemos por tanto escribir la hipótesis nula de la 
siguiente forma:
	 
	\[ H_0 = \theta_i = \theta_i^0,\ i = 1, \dots, k \]
	 
	habiendo obtenido cada $\theta_i^0$ de $F_0$. El 
estimador de máxima verosimilitud es $\hat{\theta}_i = 
\frac{f_i}{n}$. Entonces la razón de verosimilitud es
	 
	 \[ 
	 T = \frac{L(\hat{\omega})}{L(\hat{\Omega})}
	   = \frac{L(\theta_1^0, \dots, \theta_k^0)}
	   		{L(\hat{\theta}_1^0, \dots, \hat{\theta}_k^0)}
	   = \prod\limits_{i=1}^k
	   		\left( 
	 			\frac{\theta_i^0}{\hat{\theta_i}} 
	 		\right)^{f_i}
	 \]
	 y la distribución de la v.a. $-2 \log T$ puede ser 
aproximada por la distribución chi cuadrado. Debido a que 
estimamos $k-1$ parámetros (el parámetro restante se deduce 
de la restricción $\sum\limits_{i=1}^k \theta_i = 1$). 
Tenemos entonces
	 \begin{equation}
	 2 \log T = 
	 		-2 \sum\limits_{i=1}^k
	 			f_i \left(
	 					\log \theta_i^0 - \log \frac{f_i}{n}
	 				\right)
	 \label{2logT}
	 \end{equation}
	y mostramos a continuación que esta expresión es 
equivalente asintóticamente a la expresión de $Q$.\\
	
	La serie de Taylor de $\log \theta_i$ centrada en 
$\hat{\theta}_i = f_i/n$ es
	\[ \log \theta_i = 
			\log \hat{\theta}_i +
			(\theta_i - \hat{\theta}_i)
				\frac{1}{\hat{\theta}_i} +
			\frac{(\theta_i - \hat{\theta}_i)^2}{2!}
				\left(-\frac{1}{\hat{\theta}_i^2}\right) +
			\dots
	\]
	
	con lo que
	
	\begin{align*}	
	 \log \theta_i^0 - \log \frac{f_i}{n} & = 
			\left(
				\theta_i^0 - \frac{f_i}{n}
			\right) \frac{n}{f_i} -
			\left(
				\theta_i^0 - \frac{f_i}{n}
			\right)^2 \frac{n^2}{2f_i^2} + \epsilon \\
		&= \frac{n\theta_i^0 - f_i}{f_i} -
			\frac{(n\theta_i^0 - f_i)^2}{2f_i^2} +\epsilon
	\end{align*}
	
	con $\epsilon = \sum\limits_{j=3}^\infty
			(-1)^{j+1} 
			\left( \theta_i^0 - \frac{f_i}{n}\right)^j
			\frac{n^j}{j!f_i^j}$. Sustituyendo en \ref{2logT} 
nos queda
			
	\begin{align*}
	-2 \log T &= 
		-2 \sum\limits_{i=1}^k n\theta_i^0 - f_i -
		\sum\limits_{i=1}^k 
			\frac{(n\theta_i^0 - f_i)^2}{f_i} + 
		\sum\limits_{i=1}^k \epsilon' = \\
	&= 0 + 
	   \sum\limits_{i=1}^k \frac{(f_i-e_i)^2}{f_i} +
	   \epsilon''	
	\end{align*}	 
	
	Por la ley de los grandes números, $F_i/n$ es un 
estimador consistente de $\theta_i$, es decir
	
	\[ \lim_{n \rightarrow \infty} \left[
			P \left(
				\abs{ \frac{F_i}{n} - \theta_i } 
					> \varepsilon
			\right) \right] = 0 \; \forall \varepsilon > 0 \]
	
	\subsubsection{Kolmogorov-Smirnov}
	
	En el test anterior sólo se realizaban $k$ comparaciones 
a pesar de disponer de $n$ ($n \geq k$) observaciones. Si las 
$n$ muestras provienen de una distribución continua, 
podríamos realizar la comparación entre la función de 
distribución que constituye la hipótesis nula y la 
\textbf{función de distribución empírica} (edf) $S_n$ 
definida de la siguiente forma:
	\[ S_n(x) = \frac{\text{número de muestras} \leq x}{n} \]
	Para una definición formal introducimos notación sobre 
estadísticos ordenados. Sea $X_1, \dots, X_n$ una muestra 
aleatoria de una población con función de distribución 
continua $F_X$. Sea $X_{(1)}$ el menor valor de $X_1, \dots, 
X_n; X_{(2)}$ el segundo menor;$ \dots; X_{(n)}$ el mayor. 
Entonces se puede definir $S_n(x)$ como:
	\[ S_n(x) = 
		\left\lbrace\begin{array}{ll}
			0 & \text{si } x < X_{(1)} \\
			i/n & \text{si } X_{(i)} < x <X_{(i+1)},
				i = 1, \dots, n-1 \\
			1 & \text{si } x > X_{(n)} \\
	\end{array}\right.
	\]
	
	$S_n(x)$ es un estimador consistente para $F_X(x)$ y 
conforme $n$ crece, se aproxima a $F_X(x)$ para todo $x$. 
Entonces cabe esperar que el error vaya disminuyendo. Se 
define el estadístico
	\[ D_n = \underset{x}{\sup} 
				\vert S_n(x) - F_0(x) \vert, \]
	que si la hipótesis nula es cierta es un buen indicador 
de la precisión de la estimación. El estadístico $D_n$ es 
especialmente útil en la inferencia no paramétrica debido a 
que la distribución de $D_n$ no depende de $F_0(x)$ mientras 
sea continua. Se definen las desviaciones direccionales
\begin{align*}
		D_n^+ &= \underset{x}{\sup} [S_n(x) - F_0(x)]  		\\
		D_n^- &= \underset{x}{\sup} [F_0(x) - S_n(x)]
\end{align*}	 
	
\begin{teorema}
	Los estadísticos $D_n, D_n^+$ y $D_n^-$ son libres de 
distribución para cualquier función de distribución continua
$F_0$.
\end{teorema}
	
\begin{teorema}
	Si $F_X$ es una función de distribución continua, 
entonces para cada $d>0$
	\[ \underset{n \rightarrow \infty}{lim}
			P(D_n \leq d/\sqrt{n}) = L(d) \]
	con
	\[ L(d) = 1 - 2 \sum\limits_{i=1}^\infty 
			(-1)^{i-1} e^{-2i^2d^2}	\]
\end{teorema}

\begin{teorema}
	Si $F_0$ es una función de distribución continua, 
entonces bajo $H_0$ para cada $d>0$
	\[ \underset{n \rightarrow \infty}{lim}
			P(D_n^+ < d/\sqrt{n}) = 1-e^{-2d^2} \]
\end{teorema}	
	Como consecuencia de este teorema podemos usar las tablas
de la distribución chi cuadrado:
	
\begin{corolario}
	Si $F_0$ es una función de distribución continua, 
entonces para cada $d \geq 0$, la distribución límite de 
$V = 4n {D_n^+}^2$ para $n \rightarrow \infty$ es la 
distribución chi cuadrado con dos grados de libertad.
\end{corolario}	
	
	Para aplicar el test, partimos de $\tau_\alpha$ el valor
crítico para el nivel de significación $\alpha$ de 
$\chi^2_2$, entonces del corolario anterior obtenemos el 
valor límite para $D^+_n$ despejando de $\tau_\alpha
= 4n {D_n^+}^2$. Si el $D^+_n$ de la muestra fuese mayor,
rechazaríamos la hipótesis nula.
	
\section{Análisis del conteo de datos}
	
	A la hora de comparar el rendimiento de algoritmos, una 
primer enfoque puede ser contar el número de casos en los que 
un algoritmo acierta y otro no. Para representar los datos 
necesarios para este tipo de test, se utiliza una matriz de 
contingencia $r \times k$, donde cada posición se corresponde 
con el número de muestras observadas que cumple las 
características de la fila y la columna.
	
\subsection{Test de McNemar}
	
	En este test suponemos una tabla $2 \times 2$ (\ref{Tb:McNemar}) que recoge 
la respuesta de $n$ elementos ante una cierta prueba antes y 
después de un tratamiento o, en el caso en el que estamos, si 
los $n$ individuos de la muestra están bien o mal 
clasificados por dos algoritmos de clasificación.
	
\begin{table}[H]
\centering
\caption{Tabla de contingencia de McNemar}
\label{Tb:McNemar}
\begin{tabular}{|lc|cc|}
\hline
                                                          &       & \multicolumn{2}{c|}{Clasificador $f_2$} \\ \cline{3-4} 
                                                          &         & Fallo              & Acierto            \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{Clasificador $f_1$}} & Fallo   & $c_{00}$           & $c_{01}$           \\
\multicolumn{1}{|c|}{}                                    & Acierto & $c_{10}$           & $c_{11}$           \\ \hline
\end{tabular}
\end{table}

	En este test la hipótesis nula es que la probabilidad de 
que un individuo sea bien clasificado es la misma para ambos 
algoritmos. Notamos por $\theta_{ij},\ i=0,1,\ j=0,1$ la 
probabilidad de pertenecer a cada grupo. Notamos 
$\theta_{1 \cdot} = \theta_{10} + \theta_{11}$, 
$\theta_{\cdot 1} = \theta_{01} + \theta_{11}$, la 
probabilidad de estar bien clasificado por el primer y el 
segundo clasificador respectivamente. La hipótesis nula se 
escribe entonces como $H_0: \theta_{1 \cdot} = 
\theta_{\cdot 1}$, para la cual se considera el estadístico 
basado en $T = \frac{c_{1 \cdot} - c_{\cdot 1}}{N}$ como 
estimador insesgado. Podemos escribir $T = \frac{c_{01} - 
c_{10}}{N}$. El test de McNemar está basado en
	\[ \frac{(c_{01} - c_{10})^2}{(c_{01} + c_{10})} \]
	que sigue aproximadamente una distribución $\chi^2$ con 
un grado de libertad. Obtengamos ahora la esperanza y 
varianza de $T$. Puesto que $c_{01}$ y $c_{10}$ siguen una 
distribución binomial con parámetros $n$, $\theta_{01}$ y 
$\theta_{10}$ respectivamente, obtenemos

\begin{align*}
	\mathbb{E}[c_{01}] 	&= n \theta_{01} \\
	\var(c_{01}) &= n \theta_{01} (1 - \theta_{01}) \\
	\mathbb{E}[c_{10}] 	&= n \theta_{10} \\
	\var(c_{10}) &= n \theta_{10} (1 - \theta_{10}).
\end{align*}

	La varianza de $T$ se puede ver obtener de 
	
\begin{equation}
	N^2 \var(T) = \var(c_{01}) + \var(c_{10}) - 2 cov(X_{01}, c_{10}).
	\label{eq:McNemarVar}
\end{equation}

	Para el término de la covarianza podemos usar que la 
distribución de $(c_{00}, c_{01}, c_{10}, c_{11})$ es una 
distribución multinomial con probabilidades $(\theta_{00}, 
\theta_{01}, \theta_{10}, \theta_{11})$. Entonces, haciendo 
uso de la función generatriz de momentos de $c_{01}$ y 
$c_{10}$,
	\[ 
		M_X(t_1, t_2) = 
		\left(
			\theta_{01} e^{t_1} + 
			\theta_{10} e^{t_2} + 
			[ 1 - (\theta_{01} + \theta_{10})] \right)^n,
	\]
obtenemos $\mathbb{E}[c_{01}c_{10}] = \frac{\partial^2 }
{\partial t_1 \partial t_2} M_X(0,0) = n(n-1)\theta_{01} 
\theta_{10}$ y por tanto escribimos la covarianza como:
	\[
		\cov( c_{01}, c_{10} ) =
			n (n-1) \theta_{01} \theta_{10} -
			(n \theta_{01}) (n \theta_{10}) = 
			- n \theta_{01} \theta_{10}.
	\]
	
	Sustituyendo en \ref{eq:McNemarVar}, tenemos que $T$ 
tiene media $\theta_{01}-\theta_{10}$ y $\var(T) = 
\frac{(\theta_{01} + \theta_{10}) - (\theta_{01} - 
\theta_{10})^2 }{n}$. Bajo la hipótesis nula $\theta_{01} = 
\theta_{10}$, $\mathbb{E}[T] = 0$ y $\var(T) = \frac{\theta_{01}+
\theta_{10}}{n}$, que se puede estimar de manera consistente 
a partir del estadístico $(c_{01} + c_{10})/n^2$.\\
	Otro enfoque es observar el número de parejas 
discordantes $S = c_{01} + c_{10}$. Entonces $c_{01}$ sigue 
una binomial con parámetros $S$ y $\frac{\theta_{01}}
{\theta_{01}+\theta_{10}}$. Es posible que estemos 
interesados en una alternativa unilateral, esto es $H_1: 
\theta_{\cdot 1} > \theta_{1 \cdot}$, en la que la hipótesis 
alternativa supone que un algoritmo de clasificación es mejor 
que otro. Para esta alternativa el $p$-valor exacto viene 
dado por $\sum\limits_{j=0}^S {S \choose j}(0.5)^S$. Para 
muestras de un gran tamaño, podemos obtener un $p$-valor 
aproximado basándonos en $Z = \frac{c_{01} - c_{10}}
{\sqrt{c_{01} + c_{01}}}$, que sigue aproximadamente una 
distribución normal estándar.
	
\section{Test basados en una muestra y en muestras apareadas}
	
	En este apartado presentaremos los test no paramétricos 
análogos a test paramétricos como el test $t$ de Student para 
las hipótesis nulas $H_0: \mu = \mu_0$ para una única muestra 
y $H_0: \mu_X - \mu_Y = \mu_0$ para muestras apareadas. En 
los test no paramétricos sólo serán necesarias condiciones 
sobre la continuidad de la población. 
	
\subsection{Test de signo}

	Supongamos una muestra de $n$ elementos de una población 
con mediana desconocida $M$, donde suponemos que $F_X$ 
es continua y estrictamente creciente al menos en el entorno 
de $M$. Esto significa que $F_X^{-1}(0.5) = M$. La hipótesis 
nula a comprobar se corresponde con el valor de la mediana:

	\[ H_0: M = M_0	\text{ o equivalentemente }
			P(X > M_0) = 0.5 \]
	con $M_0$ un valor dado. Como hemos supuesto que $F_X$ 
tiene una única mediana, la hipótesis significa que $M_0$ 
divide el área de la función de densidad en dos partes 
iguales. Denotamos por $K$ el número de observaciones mayores 
que $M_0$. Podemos considerar entonces que estamos obteniendo 
una muestra de una v.a. $K$ que sigue una distribución de 
Bernouilli con parámetros $n$ y $\theta=P(X>M_0)$, y 
$\theta=0.5$ si la hipótesis nula es cierta. Se llama test de 
signo debido a que $K$ es el número de signos positivos en 
$X_i - M_0, i = 1, \dots, n$. La hipótesis alternativa queda 
por tanto
	\[ H_1: M \neq M_0	\text{ ó }
			\theta = P(X > M_0) \neq 0.5 \]
	La región crítica, para $\alpha$ el nivel de 
significación, es $K \geq k_{\alpha/2}$ ó $K \leq 
k_{\alpha/2}'$, con $k_{\alpha/2}$ y $k_{\alpha/2}'$ el menor 
y el mayor entero respectivamente tales que
	\[ \sum\limits_{i=k_{alpha/2}}^n
			{n \choose i}(0.5)^n \leq \frac{\alpha}{2}
		\text{ y }
		\sum\limits_{i=0}^{k_{alpha/2}'}
			{n \choose i}(0.5)^n \leq \frac{\alpha}{2}
	\]

\subsubsection{Test de rangos con signos de Wilcoxon}

	El test anterior usa únicamente el signo de la diferencia 
de la muestra a la mediana, sin considerar la distancia. Para 
este test sí consideramos la distancia a la mediana aunque 
necesitamos suponer la simetría de la población. \\
	Sea $X_1, \dots, X_n$ una muestra de una función de 
distribución continua $F$ con mediana $M$. De ser cierta la 
hipótesis nula $H_0: M = M_0$ las diferencias $D_i = X_i - 
M_0$ estarían distribuidas de manera simétrica en torno 
a 0.\\
	Supongamos que ordenamos las diferencias absolutas 
$|D_1|, \dots, |D_n|$ del valor absoluto más pequeño al más 
grande y le asignamos los puestos $1, 2, \dots, n$. Sea $T^+$ 
el valor esperado de la suma de los puestos con diferencias 
positivas, $T^-$ la de aquellos con diferencias negativas. 
Supuesta cierta la hipótesis nula, al ser la población 
simétrica, $T^+ = T^-$. Para realizar el test, notaremos por
$r(\cdot)$ la función que asigna el puesto de la v.a.. 
Definimos
	\[ T^+ = \sum\limits_{i=1}^n Z_i r(|D_i|); \quad
	   T^- = \sum\limits_{i=1}^n (1-Z_i) r(|D_i|) \]
	   
	 con $ Z_i = \mathbb{I}[ D_i > 0 ]$. Entonces,
	 		
	\[ T^+  - T^- = 2 \sum\limits_{i=1}^n
					 Z_i r(|D_i|) - \frac{N(N+1)}{2} \]
	
	Bajo la hipótesis nula, $Z_i$ sigue una distribución de 
Bernouilli con $E(Z_i) = 1/2$ y $\var(Z_i) = 1/4$. Usando que 
$T^+$ es una combinación lineal de las variables $Z_i$, 
tenemos
	\[ \mathbb{E}[ T^+ | H_0 ] = \sum\limits_{i=1}^n 
						\frac{r(|D_i|)}{2} 
					= \frac{n(n+1)}{4}			\]
	y
	
	\[ \var( T^+ | H_0 ) = \sum\limits_{i=1}^n 
						\frac{[r(|D_i|)]^2}{4} 
					= \frac{n(n+1)(2n+1)}{24}	\]
					
	Para la aplicación de este test se obtiene el estadístico 
$T = \min \{ T^+, T^- \}$. En la tabla de los valores 
críticos de $T$ para el test de rangos con signos de Wilcoxon 
(por ejemplo en \cite[Tabla A5]{sheskin2003handbook}) se encuentran aquellos valores 
para nivel de significación 0.05 y 0.01 para los cuales 
debemos rechazar la hipótesis nula si $T$ es menor que el 
valor correspondiente en la tabla.\\
	
\paragraph{Valores iguales a la mediana} En este test se han 
considerado los valores iguales a la mediana como negativos. 
Como las diferencias con la mediana están ordenadas de manera 
creciente, estos valores estarán necesariamente al principio 
y el impacto será menor. Sin embargo, podemos considerar la 
siguiente modificación,

	\[ Z_i = \left\lbrace \begin{array}{ll}
	 				1 & \text{si } D_i > 0 \\
	 				0 & \text{si } D_i < 0 \\
	 				1/2 & \text{si } D_i = 0 
	 		\end{array} \right. 					\]
	
	para repartir así entre $T^+$ y $T^-$ estas puntuaciones. 
	
\subsubsection{Tratamiento de empates}
	
	Al realizar la suposición de que la muestra se obtiene de 
una población continua, la probabilidad teórica de obtener 
dos valores idénticos es nula. Sin embargo en la práctica 
podemos obtener empates debido a que la población sea 
discreta o limitaciones en la precisión. Presentamos a 
continuación algunos métodos para solventar esta situación:
	
\paragraph{Aleatorización} Se selecciona un orden aleatorio 
para los elementos con igual valor.

\paragraph{\textit{Midranks}} Asigna a cada individuo de un 
grupo de valores empatados la media de los puestos de la 
clasificación que tendrían de ser distintos. Es decir, si hay 
tres valores con la tercera menor distancia a la mediana, 
ocuparían los puestos 3,4 y 5 y por tanto el valor asignado a 
cada uno de ellos sería $\frac{3+4+5}{3}=4$. Es el método más 
utilizado debido a su simplicidad. 

\paragraph{Estadístico medio} Se realiza el test estadístico 
para todas las posibles asignaciones para los términos 
empatados y se realiza la media de estos test.

\paragraph{Estadístico menos favorable} Habiendo encontrado 
todos los posibles valores del test, se escoge aquel con 
menor probabilidad de rechazar la hipótesis nula. Es la 
opción más conservadora al minimizar la probabilidad de 
cometer un error de tipo I.

\paragraph{Rango de probabilidad} Se devuelve el valor menos 
favorable a rechazar la hipótesis nula y el más favorable. No 
conduce a una única decisión a no ser que ambos valores 
caigan en la región crítica o fuera de ella.

\paragraph{Omisión de los valores empatados} Otra posibilidad 
es descartar los valores empatados. Conlleva una pérdida de 
información y generalmente introduce un sesgo hacia rechazar 
la hipótesis nula.

	
\section{Medidas de asociación en clasificaciones múltiples}	

	En este apartado presentamos la versión no paramétrica 
para el problema del análisis de la varianza. Enfocado al 
problema abordado en este trabajo, nos será muy útil para 
comparar el rendimiento de varios algoritmos en distintas 
conjuntos de datos. Los datos se presentan en una tabla $n \times 
k$ con entradas $X_{ij}$. En esta distribución influyen dos 
factores que llamaremos el efecto por filas y por columnas.\\
	Para nuestro problema, consideraremos que las filas se 
corresponden con conjuntos de datos y que las columnas 
constituyen los algoritmos utilizados. 
	
\subsection{Análisis bidimensional de la varianza mediante clasificaciones en una tabla $k \times n$ y comparaciones múltiples de Friedman}

	Partimos de una matriz $n \times k$. Consideraremos que 
las filas son independientes, pero no las columnas (en 
nuestro problema esto significa que las conjuntos de datos sí 
son independientes pero en cada algoritmo los resultados guardan 
correlación). La hipótesis nula que consideraremos será la 
equivalencia del rendimiento de todos los algoritmos.
Friedman sugirió cambiar cada valor de la 
matriz por la clasificación de cada fila. Notaremos por $R_{ij}$
el orden del algoritmo $j$ para el problema $i$.

	\[ \left( \begin{matrix}
		R_{11} & R_{12} & \dots & R_{1k} \\
		\vdots & \vdots & \ddots & \vdots \\
		R_{n1} & R_{k2} & \dots & R_{nk}
		\end{matrix} \right)	\]

	Entonces, $R_{i1}, \dots, R_{ik}$ es una permutación de 
los $k$ primeros números (salvo en caso de empate). 
Escribimos como $R_j$ el total para la columna $j$. 
Consideraremos la distribución de la muestra de la v.a. 
	\begin{equation}
		 S = \sum\limits_{j=1}^k
				\left[
					R_j - \frac{n(k+1)}{2}
				\right]^2 =
			\sum\limits_{j=1}^k \left[
				\sum\limits_{i=1}^n \left(
					R_{ij} - \frac{k+1}{2}
				\right)
			\right]^2,
	\label{S-Friedman}
	\end{equation}
bajo la hipótesis nula $H_0: \theta_1 = \dots = 
\theta_k$. En el caso de que no hubiera empates por filas 
habría un total de $(k!)^n$ posibles entradas igualmente 
probables. Las posibilidades se pueden enumerar y calcular el 
valor de $S$ para cada una de ellas, con lo que la 
distribución de probabilidad de $S$ sería $f_S(s) = 
\frac{u_s}{(k!)^n}$, con $u_s$ el número de asignaciones que 
tienen como suma de los cuadrados de las desviaciones totales 
por columnas $s$. Existe un método para obtener $u_s$ de $k$ 
y $n$ a partir de $k$ y $n-1$, y tablas con valores. Para los 
valores que exceden estas tablas se usa una aproximación de 
la distribución.\\
	Notando $\mu = \frac{k+1}{2}$, escribimos 
	\ref{S-Friedman}:
	
	\begin{align}
		S 	&= 	\sum\limits_{j=1}^k
					\sum\limits_{i=1}^n (R_{ij}-\mu)^2
				+ 2 \sum\limits_{j=1}^k
					\sum\limits_{i=1}^{n-1}
						\sum\limits_{p=i+1}^n
							(R_{ij}-\mu)(R_{pj}-\mu) 
				\nonumber \\
			&=	k \sum\limits_{j=1}^n (j-\mu)^2 + 2U 
				\nonumber \\
			&=  \frac{nk(k^2-1)}{12} + 2U	.
	\label{S-Friedman2}
	\end{align}
	
	Los momentos de $S$ vienen determinados por los momentos 
de $U$, que se derivan de:
	\[ 	\mathbb{E}[ R_{ij} ]= \frac{k+1}{2};\ 
		\var(R_{ij})=\frac{k^2-1}{12};\
		\cov(R_{ij},R_{iq}) = -\frac{k^2-1}{12}
	\]
	
	Además, dado que las observaciones en las diferentes 
filas son independientes, para $i \neq p$, se tiene
$\cov(R_{ij},R_{pq})=0$. Entonces
	\[ E(U) = k {n \choose 2} \cov(R_{ij},R_{pq})=0, \] 
	con lo que $\var(U) = kE(U^2)$, con
	\begin{align*}
		U^2 =& \sum\limits_{j=1}^k
				\sum\limits_{1 \leq i < p \leq n}
					(R_{ij} - \mu)^2 (R_{pj} - \mu)^2 \\
			+& 2 
			    \sum\limits_{j=1}^{k-1}
			      \sum\limits_{q=j+1}^k
					\sum\limits_{i=1}^{n-1}
					  \sum\limits_{p=i+1}^n	
					  	\sum\limits_{r=1}^{n-1}
						  \sum\limits_{s=r+1}^n
				(R_{ij} - \mu)(R_{pj} - \mu)
				(R_{rq} - \mu)(R_{sq} - \mu).
	\end{align*}
	
	Como $R_{ij}$ y $R_{pq}$ son independientes para $i \neq p$, tenemos
	\begin{align*}
		\mathbb{E}[U^2] =& \sum\limits_{j=1}^k
					\sum\limits_{1 \leq i < p \leq n}
						\var(R_{ij})\var(R_{pj}) \\
			 &+ 2 
			    \sum\limits_{j=1}^{k-1}
			      \sum\limits_{q=j+1}^n
			    {n \choose 2}
				\cov(R_{ij}, R_{iq}) \cov(R_{pj}, R_{pq}) \\
			=& k {n \choose 2} \frac{(k^2-1)^2}{144} +
				2{k \choose 2}{n \choose 2} 
					\frac{(k^2+1)^2}{144} \\
			=& k^2 {n \choose 2} (k+1)^2 \frac{k-1}{144}.
	\end{align*}	
	
	Sustituyendo en \ref{S-Friedman2} llegamos a 
	
	\[ \mathbb{E}[S] = \frac{nk(k^2-1)}{12}; \ 
		\var(S)= \frac{k^2n(n-1)(k+1)^2}{72} .\]
	
	Podemos definir la transformación
	
	\[ \chi^2_F = \frac{12S}{nk(k+1)} = 
	\frac{12 \sum\limits_{j=1}^k R_j^2}{nk(k+1)} -3n(k+1) .
	\]
	que tiene $\mathbb{E}[\chi^2_F] = k-1$, $\var(\chi^2_F)= 2(k-1)
\frac{n-1}{n} \approx 2(k-1)$, que son los dos primeros 
momentos de la distribución $\chi^2_{k-1}$. También los 
momentos de mayor orden de $\chi^2_F$ se aproximan a los 
momentos de mayor orden de $\chi^2_{k-1}$ para $n$ grande. A 
efectos prácticos, podemos tratar $\chi^2_F$ como una $
\chi^2_{k-1}$ para $n>7$ ó $n>10, k>5$. La región crítica $R$
para la hipótesis nula mencionada con nivel de significación 
$\alpha$ es
	\[ 
		\chi^2_F \in R \ \text{ para } 
			\chi^2_F \geq \chi_{k-1,\alpha}^2 .
	\]
	
\paragraph{Propuesta de Iman-Davenport} Sin embargo, este
test es demasiado conservador, por lo que Iman y Davenport
propusieron el estadístico
	\[
		F_F = \frac{(n-1)\chi^2_F}{n(k-1) - \chi^2_F},
	\]
	que sigue una distribución $F$ de Snedecor con $k-1$ y
$(k-1)(n-1)$ grados de libertad.
	
	
\subsubsection{Test de Friedman AR}
	Este test basado en el test de Friedman se propone como
solución a la hora de comparar un número pequeño de 
algoritmos para tener en cuenta el rendimiento no sólo 
para cada conjunto de datos sino entre ellos. El
siguiente algoritmo indica el procedimiento de cálculo.\\
	
\begin{algorithm}
	\caption{Cálculo del estadístico de Friedman-AR}
	\label{alg:Friedman-AR}
	\begin{algorithmic}[1]
	\REQUIRE $x_{ij}$, medida del rendimiento del
			algoritmo $j$ en el conjunto $i$.
	\STATE Se calcula la media del rendimiento de los 
		algoritmos para cada conjunto de datos, 
		$\bar{x}_{i \cdot}$
	\FOR {$ x_{ij}:\ i=1,\dots, n,\ j=1,\dots,k$}
		\STATE Observación alineada: $\leftarrow$
			Diferencia entre $x_{ij}$ y $\bar{x}_{i \cdot}$.	
	\ENDFOR
	\STATE Se ordenan de $1$ a $kn$ las observaciones 
		alineadas $R_{ij}$.
	\STATE Se calculan los totales de estos ránquines
		por algoritmo $\hat{R}_{\cdot j}$ y por
		conjunto de datos $\hat{R}_{i \cdot}$.
	\end{algorithmic}
\end{algorithm} 

	Entonces, se calcula el estadístico 

	\[
		T = \frac{(k-1)
				\left[
					\sum\limits_{j=1}^k
						\hat{R}_{\cdot j}^2 -
					kn^2(kn+1)^2/4
				\right]}
				{[kn(kn+1)(2kn+1)/6] 
				 - (1/k) \sum\limits_{i=1}^n 
				 			\hat{R}_{i \cdot}^2},
	\]
	que sigue una distribución $\chi^2_{k-1}$.
	
\subsubsection{Test de Quade}

	El test de Friedman considera todos los conjuntos de 
datos iguales en cuanto a importancia. Se propone la 
siguiente modificación modificando el peso en base a las
diferencias entre los rendimientos en cada base de datos.\\
	Para ello, se considera el rango de cada conjunto,
	\[ rango_i = \underset{j}{\max} \{x_{ij}\} - 
				 \underset{j}{\min} \{x_{ij}\},
	\]
	y se clasifican los rangos de menor a mayor, notando por 
$Q_i$ al puesto ocupado por el conjunto de datos $i$.
Entonces se multiplica $Q_i$ por la diferencia entre el 
ránquin dentro del conjunto $i$ ($R_{ij}$ y el puesto medio,
$\frac{k+1}{2}$:
	\[ 
		S_{ij} = Q_i 
				\left( R_{ij} - \frac{k+1}{2} \right).
	\]
	Denotamos por $S_j = \sum\limits_{i=1}^n S_{ij}$ y
calculamos los términos
\begin{align*}
		A_2 &= \frac{kn(n+1)(2n+1)(k+1)(k-1)}{72},\\
		B &= \frac{1}{n} \sum\limits_{j=1}^k S_j^2.
\end{align*}

	Finalmente, obtenemos el estadístico
	\[
		T_3 = \frac{(n-1)B}{A_2 - B}
	\]
	que sigue una distribución $F$ de Snedecor con $k-1$ y
$(k-1)(n-1)$.
	

\subsubsection{Procedimientos \textit{post-hoc}}

	Una vez se ha descartado la hipótesis nula de 
la equivalencia entre los clasificadores, se pretende
identificar dónde se producen las diferencias. Para ello,
no se considera una única hipótesis sino una familia 
de ellas consistentes en la igualdad del rendimiento entre 
algoritmos y pretendemos rechazarlas o no sin tener que ir 
una por una.\\
	Si consideramos la comparación de $k$ algoritmos con 
nivel de significación $\alpha$, la probabilidad de no 
cometer un error de tipo I es $1-\alpha$, y entonces la 
probabilidad de no cometerlo en las $k-1$ comparaciones es
$(1-\alpha)^{k-1}$. Así pues, la probabilidad de cometer un
error de tipo I es $1-(1-\alpha)^{k-1}$, lo que aumenta 
la probabilidad de cometer un error cuando crece el número 
de algoritmos a comparar. Para ello, la solución es 
ajustar los $p$-valores (\textit{Adjusted $p$-values}, APV), 
y realizar las comparaciones con $\alpha$. Se describen a continuación algunos procedimientos para ajustar los 
$p$-valores y los valores de $\alpha$:

\begin{itemize}
\item Procedimientos de un paso.
	\begin{description} 
	\item[Bonferroni-Dunn] Ajusta el valor de $\alpha$ 
		dividiéndolo por el número de comparaciones
		realizadas, $k-1$. $APV_i = \min \{\nu,1\}$,
		con $\nu = (k-1)p_i$.
	\end{description}
\item Procedimiento descendente.
	\begin{description} 
	\item[Holm] Consideramos los $p$-valores ordenados
		de manera ascendente $p_1 \leq \dots \leq p_{k-1}$
		y $H_1, \dots, H_{k-1}$ sus hipótesis asociadas.
		Se rechazan las hipótesis $H_1, \dots, H_{i-1}$
		para $i$ el menor entero tal que $p_i > 
		\alpha/(k-i)$. $APV_i = \min \{\nu,1\}$,
		con $\nu = \max \{(k-j)p_j: 1 \leq j \leq i\}$.
	\item[Holland] Partiendo de la misma situación que en
		el de Holm, se rechazan las hipótesis $H_1, \dots, 
		H_{i-1}$ para $i$ el menor entero tal que $p_i > 
		1- (1-\alpha)^(k-i)$. $APV_i = \min \{\nu,1\}$,
		con $\nu = \max \{1- (1-\alpha)^(k-j): 1 \leq j 
		\leq i\}$.
	\item[Finner] Partiendo de la misma situación que en
		los anteriores, se rechazan las hipótesis 
		$H_1, \dots, H_{i-1}$ para $i$ el menor entero tal 
		que $p_i >  1- (1-\alpha)^{(k-1)/i}$. 
		$APV_i = \min \{\nu,1\}$, con $\nu = \max \{1- 
		(1-\alpha)^{(k-1)/j}: 1 \leq j \leq i\}$.
	\end{description}
\item Procedimiento ascendente.
	\begin{description} 
	\item[Hochberg] Se ajusta el valor de $\alpha$ de manera
		ascendente. Se compara el mayor $p$-valor con 
		$\alpha$, el siguiente con $\alpha/2$, el siguiente
		con $\alpha/3, \dots$ hasta encontrar una hipótesis
		que se pueda rechazar, rechazando también aquellas
		con un $p$-valor menor. $APV_i = \max \{(k-j)p_j:
		(k-1) \geq j \geq i \}$.
	\item[Hommel] Este método es más complejo de calcular
		y comprender. Se busca el mayor $j$ tal que 
		$p_{n-j+k} < k\alpha/j$ para todo $k=1,\dots,j$.
		Si no existe $j$, se rechazan todas las hipótesis,
		si no, se rechazan todas para las que $p_i \leq 
		\alpha/j$.
	\item[Rom] Consiste en una modificación del de Hochberg,
		calculando $\alpha$ de la siguiente manera:
		\[ 
			\alpha_{k-i} = \frac{
								\sum\limits_{j=1}^{i-1}
									\alpha^j
								- \sum\limits_{j=1}^{i-2}
									{i \choose k}
									\alpha_{k-1-j}^{i-j}
						}{i},
		\]
		con $\alpha_{k-1} = \alpha, \alpha_{k-2}= \alpha/2$. 
		$APV_i = \max \{(r_{k-j})p_j: (k-1) \geq j \geq 
		i \}$, con $r_{k-j}=\alpha/\alpha_{k-j}$
	\end{description}	
\item Procedimiento en dos pasos.
	\begin{description}
	\item[Li] En primer lugar se rechazan todas las 
		hipótesis si $p_{k-1} \leq \alpha$. Si no, 
		no se rechazará $H_{k-1}$. En segundo lugar, se 
		rechazan las hipótesis $H_{i}$ tal que 
		$p_i \leq \frac{1-p_{k-1}}{(1-\alpha)\alpha}$.
		$APV_i = p_i/(p_i + 1 - p_{k-1})$.	
	\end{description}	 
\end{itemize}

\section{Test basados en permutaciones}
	
	En este apartado se incluye una descripción general sobre 
los test basados en permutaciones. La hipótesis nula a la 
hora de realizar inferencia es considerar que una muestra 
aleatoria $\mathbf{x}$ proviene de una misma población 
$P \in \mathcal{P}$. Por tanto, supuesta esta hipótesis nula, 
obtenemos que si la muestra $\mathbf{x}$ viniese de 
poblaciones distintas, los valores pertenecientes a cada 
población podrían intercambiarse por los de otra sin ningún 
problema.\\
	Notemos además que $\mathbf{x}$ es un conjunto de 
estadísticos suficientes para cualquier distribución en 
$H_0$. Esto se debe a que, si $H_0$ es cierto, sea $f_P$ la 
densidad de $P$, $f_P^{(n)}(x)$ la densidad de la variable 
$X^{(n)}$. Como $f_P^{(n)}(\mathbf{x}) = f_P^{(n)}(\mathbf{x}) 
\cdot 1$ para todo $\mathbf{x} \in \Omega^n$, excepto para 
$f_P^{(n)}(\mathbf{x}) = 0$ debido al teorema de 
factorización (\cite[p. 167]{ibarrola1993principios}) cualquier conjunto $\mathbf{x}$ 
es un conjunto 
de estadísticos suficientes para cualquier $P \in 
\mathcal{P}$.\\
	En estos test se realizan inferencias condicionadas con
respecto a la muestra $\mathbf{x}$, que es a su vez un conjunto de 
estadísticos suficientes en $H_0$. Este hecho unido a la 
intercambiabilidad de los datos observados con respecto a los 
grupos hace que los test sean independientes de las 
distribución $P$, por lo que no necesitamos conocerla. Esto 
queda más claramente explicado en el siguiente principio:

\begin{definicion}[Principio de los test basados en 
permutaciones]
	Si dos experimentos toman valores en el mismo espacio
muestral $\Omega$ respectivamente con las distribuciones 
$P_1, P_2 \in \mathcal{P}$, dan el mismo conjunto de datos, 
entonces las inferencias condicionales a los datos obtenidas 
usando el mismo test estadístico debe 
ser la misma, debido a que la intercambiabilidad de los datos con 
respecto a los grupos se cumple en la hipótesis nula. Por 
consiguiente, si dos experimentos con distribuciones 
$P_1, P_2$ dan respectivamente como muestras $\mathbf{x_1}, 
\mathbf{x_2}$, con $\mathbf{x_1} \neq \mathbf{x_2}$, entonces 
las inferencias con respecto a $\mathbf{x_1}$ y 
$\mathbf{x_2}$ pueden ser distintas.
\end{definicion}


\subsection{Ejemplo con muestras apareadas}

	Para explicar el funcionamiento de los test basados en 
permutaciones, expondremos situaciones ya conocidas en las 
que sabemos cómo utilizar test paramétricos o test no 
paramétricos expuestos anteriormente. El primer caso es el de 
muestras pareadas. Supondremos una situación en la que 
tenemos 20 problemas y comparamos el rendimiento de dos
algoritmos en cada uno de ellos.
Por tanto consideramos la v.a. $Y = (Y_1, Y_2)$ de $n=20$ 
elementos $\{(Y_{1i},Y_{2i}): i = 1, \dots, n\}$. La 
hipótesis nula es que las diferencias en que las 
distribuciones marginales de $Y_1$ e $Y_2$ son iguales:
$H_0 : \{ Y_1 = Y_2 \}$ frente a $H_1: \{ Y_1 > Y_2 \}$\\
	
	En primer lugar, nótese que la hipótesis nula $H_0$ 
implica que las dos variables $Y_1, Y_2$ son intercambiables. 
Esto es, supuesto $H_0$, para cada individuo los dos valores 
observados podrían corresponder con cualquiera de las 
observaciones, para un algoritmo u otro. Es decir, si 
consideramos la variable aleatoria $X = Y_2 - Y_1$, cada 
valor observado $X_i, i=1, \dots, n$ podría tener cualquier 
signo con probabilidad $1/2$. Una forma de realizar el test 
sería considerando el estadístico $T = \sum\limits_{i=1}^n 
X_i$, cuya distribución condicionada a $\mathbf{X} = \{X_i: i 
= 1, \dots, n\}$, $F_T(t|\mathbf{X})$ vendrá dada bajo $H_0$ 
considerando la atribución de todas las formas posibles del 
signo de cada diferencia con probabilidad $1/2$. Denotamos
por $T^* = \sum\limits_{i=1}^n X_i^*$, donde 
$X_i^*$ se obtiene asignando aleatoriamente el signo. 
Notaremos por $\Omega_{/\mathbf{X}}$ al espacio muestral de 
permutaciones. Este espacio consiste en las posibles 
permutaciones de la muestra obtenidas. En este caso, el espacio 
tiene $M^{(n)} = 2^v$ elementos, donde $n-v$ es el número de 
diferencias nulas. Notamos por $F(t|\mathbf{X}) = P[T^* \leq 
t | \mathbf{X}], t \in \mathbb{R}$ a la cdf condicional de la 
permutación inducida por $T$ dado $\mathbf{X}$.\\
	Si el tamaño de la muestra $n$ es grande, podrá aplicarse 
el Teorema Central del Límite Permutacional (\ref{th:PCTL}) 
para aproximar la distribución de la permutación 
$F[t|\mathbf{X}]$. Para resolver un problema de este tipo 
podemos guiarnos por lo siguiente:
	
\begin{enumerate}[a]
	\item Si $n \leq 25$ es posible calcular exactamente 
		$T^*$  para todas las posibles permutaciones y 
		calcular $F[t|\mathbf{X}]$.
	\item Si $n \geq 200$, $\sigma_X$ se supone finito y el 
		cociente $(\sum_i X_i^4)/(\sum_i X_i^2)^2$ es 
		pequeño, $F[t|\mathbf{X}]$ puede aproximarse por 
		el PCTL (\ref{th:PCTL}). 
	\item En otro caso, $F[t|\mathbf{X}]$ puede aproximarse 
		utilizando el algoritmo condicional de Monte 
		Carlo (CMC) (\ref{alg:CMC-pvalue}).
\end{enumerate}
	
\subsubsection{Teoría de los test basados en permutaciones}

\begin{definicion}[Espacio de referencia condicional]
	Conjunto de puntos del espacio muestral $\Omega^n$ que 
son equivalentes a $\mathbf{X}$ en términos de la información 
asociada a la verosimilitud subyacente. Lo notamos por 
$\Omega^n_{/\mathbf{X}}$.
\end{definicion}

	Esto es, $\Omega^n_{/\mathbf{X}}$ contiene todos los 
puntos $\mathbf{X}^*$ tales que $dP(X)/dP(X^*)$ es 
independiente de $P$. Dado que en $H_0$ la probabilidad de 
obtener $\mathbf{X}$ es la misma que de obtener una 
permutación $\mathbf{X}^*$,
	\[ 
		\Omega^n_{/\mathbf{X}} = 
			\left\lbrace
				\underset{\mathbf{u}^*}{\bigcup}
					[ X(u_i^*), i = 1, \dots, n ]
			\right\rbrace ,
	\]
	con $\mathbf{u}^*$ cualquier permutación de las etiquetas 
$(1, \dots, n)$.

\paragraph{Definicion de los test basados en permutaciones}
\begin{definicion}[Soporte de la permutación]
	Para realizar un test estadístico es necesaria una 
función no degenerada $T: \Omega^n \rightarrow \mathbb{R}$. 
Definimos el soporte de la permutación de $(T, \mathbf{X})$ 
como $\mathcal{T}_\mathbf{X} = \{ T^* = T(\mathbf{X}^*): 
\mathbf{X}^* \in \Omega_{/\mathbf{X}}\}$ 
\end{definicion}	

	Supongamos $H_0$ cierta. Entonces, $\mathbf{X}^*$ se 
distribuye uniformemente sobre $\Omega_{/\mathbf{X}}$. 
Pongamos los $M^{(n)}$ elementos de $\mathcal{T}_\mathbf{X}$ 
en orden creciente. De esta manera para $\alpha \in (0,1)$, 
se define $T_\alpha(\mathbf{X}) = T_\alpha = T^*_{(M^{(n)}_
\alpha)}$ como el valor crítico asociado a $(T, \mathbf{X})$, 
donde $M^{(n)}_\alpha$ es el número de valores $T^*$ 
estrictamente menor que $T_\alpha$. Nótese que $T_\alpha$ 
depende de $\Omega_{/\mathbf{X}}$ y no únicamente de $
\mathbf{X}$, pues $T_\alpha(\mathbf{X}) = T_
\alpha(\mathbf{X}')$ para $\mathbf{X}' \in \Omega_{/
\mathbf{X}}$. Esto implica que si $\alpha$ es fijo,$T_\alpha$ 
es fijo para $\mathcal{T}_\mathbf{X}$.
	
\paragraph{Test aleatorizados basados en permutaciones }

	Se define la versión aleatorizada del test basado en 
permutaciones para $(T, \mathbf{X})$ como 
	\[ 
		\phi_R = \left\lbrace \begin{array}{cc}
			1 		& \text{ si } T^0 > T_\alpha \\
			\gamma 	& \text{ si } T^0 = T_\alpha \\
			0		& \text{ si } T^0 < T_\alpha \\
		\end{array} \right. ,
	\]
	donde $T^0 = T(\mathbf{X})$, el valor de $T$ en los datos 
observados y $\gamma$ es:
	\[
		\gamma = \frac{\alpha - P[T^0 > T_\alpha | 
								\Omega_{/\mathbf{X}}]}
					  {P[T^0 = T_\alpha | 
								\Omega_{/\mathbf{X}}]} .
	\]
	
	Para aplicar $\phi_R$ es habitual usar un experimento 
aleatorio independiente de $\mathbf{X}$. Por ejemplo, 
rechazando $H_0$ si $U \geq \gamma$ para $T^0 = T_\alpha$, 
con $U$ un valor aleatorio de la variable uniforme 
$\mathcal{U}(0,1)$.\\
	Para $\mathbf{X} \in \Omega^n$ la esperanza en $H_0$ de 
$\phi_R$ para $\alpha$ es:
	\[ 
		\mathbb{E}[ \phi_R(\mathbf{X}) | \Omega_{/\mathbf{X}}] =
			P[ T^0(\mathbf{X}) > T_\alpha(\mathbf{X}) | 
								\Omega_{/\mathbf{X}}] + 
			P[ T^0(\mathbf{X}) = T_\alpha(\mathbf{X}) | 
								\Omega_{/\mathbf{X}}] =
			\alpha .
	\]
	
	Por consiguiente, el tamaño del test aleatorizado basado en 
permutaciones es exactamente $\alpha$.
	
\begin{proposicion}
	Supuesta la condición de intercambiabilidad para 
$\mathcal{X}$. Entonces para todas las distribuciones $P$ y 
uniformemente para todos los conjuntos de datos $\mathbf{X} 
\in \Omega^n$ la probabilidad condicionada de rechazo de 
$\phi_R$ es invariante con respecto a $\mathbf{X}$ y $P$.
\end{proposicion}

\paragraph{Test basados en permutaciones no aleatorizados}

	En los contextos de aplicación se suele utilizar la 
versión no aleatorizada. Se define
	
	\[ 
		\phi = \left\lbrace \begin{array}{cc}
			1 		& \text{ si } T^0 \geq T_\alpha \\
			0		& \text{ si } T^0 < T_\alpha \\
		\end{array} \right. .
	\]
	
	Ahora, el error asociado de tipo I es 
	
	\[ 
		\mathbb{E}[ \phi(\mathbf{X}) | \Omega_{/\mathbf{X}}] =
		P[ T^0 \geq T_\alpha | \Omega_{/\mathbf{X}}] =
		\sum\limits_{\Omega_{/\mathbf{X}}}
			\mathbb{I}[ T(\mathbf{X}^*) \geq T_\alpha ]/
				M^{(n)} =
		\alpha_a \geq
		\alpha,
	\] 
	
	donde $\alpha_a$ es el llamado $\alpha$-valor alcanzable 
asociado a $(T, \mathbf{X})$. Para $(T,\mathbf{X})$, el 
$\alpha$-valor alcanzable pertenece a $\Lambda_\mathbf{X}
^{(n)} = \{ L_\mathbf{X}(t): dL_\mathbf{X}(t) > 0 \}$, para 
la función $ L_\mathbf{X}(t) = P[ T^* \geq t | \Omega_{/
\mathbf{X}}] $. 
	
\paragraph{$p$-Valor} Determinar el valor crítico $T_\alpha$ 
para un test estadístico $T$ puede ser complicado en la 
práctica. Por tanto, normalmente se hace referencia a un $p$-
valor asociado a $(T, \mathbf{X})$, que se define como $p = 
\lambda_T(\mathbf{X}) = L_\mathbf{X}(T^0) = P[ T^* \geq T^0 | 
\Omega_{/\mathbf{X}}]$. Este valor se puede calcular 
enumerando completamente $\mathcal{T}_\mathbf{X}$ o 
estimándolo mediante el algoritmo condicional de Monte Carlo. 
El $p$-valor $p$ es una función creciente de $T^0$ y tiene 
una  correspondencia uno a uno con los $\alpha$-valores 
alcanzables de $\phi$, puesto que $\lambda_T(\mathbf{X}) > 
\alpha$ implica $T^0 < T_\alpha$ y viceversa.

\paragraph{Algoritmo CMC para estimar el $p$-valor}  
Describimos a continuación los pasos generales de un 
algoritmo condicional de Monte Carlo para la evaluación de un 
$p$-valor de un test estadístico $T$ en un conjunto de datos 
$\mathbf{X} = \{ X_i, \ i=1, \dots, n; n_1, n_2 \}$

\begin{algorithm}
	\caption{Algoritmo CMC para estimar el $p$-valor}
	\label{alg:CMC-pvalue}
	\begin{algorithmic}[1]
	\REQUIRE
		\begin{enumerate}[a]
		\item Muestra $\mathbf{X}$
		\item Estadístico $T$
		\item Número de iteraciones $B$
		\end{enumerate}
		\STATE Calcular $T^0 = T(\mathbf{X})$
		\FOR { $b \in \{1, \dots, B\}$ }
			\STATE Realizar una permutación $\mathbf{X}^*$ de  
			$\mathbf{X}$.
			\STATE Calcular $T^* = T(\mathbf{X}^*)$
		\ENDFOR
		\STATE El conjunto $\{ \mathcal{X}^*_b, b = 1, \dots, 
		B \}$ es una muestra aleatoria de 
		$\Omega_{/\mathbf{X}}$ y los valores correspondientes 
		$\{ T^*_b, b = 1, \dots, B \}$ simulan la 
		distribución nula de las permutaciones de $T$ 
		(aquella que tendría $T$ de ser cierta $H_0$). 
		Entonces el $p$-valor se estima como $\hat{\lambda}
		(\mathbf{X}) = \sum\limits_{b=1}^B 
		\mathbb{I}[T_b^* \geq T^0]/B$, esto es, la proporción 
		de los valores de la permutación mayores que el 
		observado.
	\end{algorithmic}
\end{algorithm}

\paragraph{Teorema Central del Límite Permutacional}
	Por último en esta sección, se presenta la versión 
permutacional del TCL de Wald y Wolfowitz (\cite{wald1944}).
Notaremos por $\mathbf{X} = \{X_1, \dots, X_n\}$ de $n$ v.a. 
independientes e idénticamente distribuidas. Supongamos que 
la hipótesis nula sobre la que se realiza el test, $H_0$, 
implica que las permutaciones en $\mathbf{X}$ son igualmente 
probables.\\
	Definimos el test estadístico permutacional
	\[
		T = T(\mathbf{X}) = 
			\sum\limits_{i=1}^n
				A_i X_i,
	\]
	para el vector $\mathbf{A} = \{A_1, \dots, A_n\}$. Para 
un vector genérico $\mathbf{D}$, notamos $\bar{D} = 
\frac{\sum\limits_{i=1}^n D_i}{n}$, $\mu_r(\mathbf{D}) = 
\frac{\sum\limits_{i=1}^n (D_i - \bar{D})^r}{n}$, 
$W_r(\mathbf{D}) = \frac{\sum\limits_{i=1}^n 
|D_i - \bar{D}|^r}{n}$, $R(\mathbb{D}) = 
\underset{1 \leq i \leq n}{\max} D_i - 
\underset{1 \leq i \leq n}{\min} D_i$.\\

	De la distribución de la permutación de $T$ se obtiene

\begin{align*}
	\mathbb{E}_{\Omega_{/\mathbf{X}}} \left[
		T(\mathbf{X}^*) | \Omega_{/\mathbf{X}}
		\right] &=
		n \bar{X} \bar{A}, \\
	\mathbb{E}_{\Omega_{/\mathbf{X}}} \left[
		(T(\mathbf{X}^*) - n\bar{X}\bar{A})^2 | 
			\Omega_{/\mathbf{X}}
		\right] &=
		\frac{[n^2 \mu_2{\mathbf{X}} \mu_2{\mathbf{A}}]^2}
			{n-1}.
\end{align*}

	Entonces, escribimos la v.a.
	\[
		Z = \frac{(T - n \bar{X} \bar{A})\sqrt{n-1}}
				{n^2 \mu_2(\mathbf{X}) \mu_2(\mathbf{A})},
	\]
	y sabemos que la cdf de $Z$, $F_Z(t|\Omega^n)$ puede 
determinarse enumerando todas las permutaciones de 
$\mathbf{X}$. Antes de enunciar el teorema, enunciaremos la 
condición sobre $\mathbf{X}$ y $\mathbf{A}$. 
$\{ \mathbf{D}_n; n \geq 2 \}$:

\begin{equation}
	 \label{eq:PCLTcond}
	 \tag{C.1}
	 \frac{\mu_r(\mathbf{D}_n)}
	 		{\mu_2(\mathbf{D})^{r/2}} = O(1),\quad
	 		\forall r \in \mathbb{N},\ r \geq 2
\end{equation}

\begin{teorema}[Teorema Central del Límite Permutacional]
	Sean $\{\mathbf{A}_n; n \geq 2\}$, $\{\mathbf{X}_n; 
n \geq 2\}$ cumpliendo la condición~\ref{eq:PCLTcond}. 
Entonces para $n \rightarrow \infty$,
	\[ F_Z(t | \Omega^n_{\mathbf{X}}) 
		\overset{P}{\rightarrow} \mathit{N}(t | 0,1)
	\]
	\label{th:PCTL}
\end{teorema}


\chapter{Test bayesianos}	
\label{chapter:test_bayesianos}

	En esta sección se hace una introducción a conceptos de 
la estadística bayesiana y test basados en esta estadística
para su aplicación en la comparación de algoritmos de
aprendizaje automático.\\
	Según A. Gelman (\cite{Gelman03-105949}), la inferencia 
bayesiana es el proceso de ajustar un modelo de probabilidad 
a un conjunto de datos y resumir el resultado  mediante una 
distribución de probabilidad sobre los  parámetros del modelo 
y sobre cantidades no observadas como predicciones para 
nuevas observaciones. Estamos por tanto frente a una 
forma de entender la estadística distinta, cuya principal
característica es el uso de la probabilidad para 
cuantificar la incertidumbre en las inferencias basadas en
el análisis de los datos. Este análisis puede dividirse en
tres pasos:

	\begin{enumerate}
	\item establecimiento de un modelo de probabilidad;
	\item condicionamiento sobre los datos observados,
		calculando e interpretando la distribución 
		\textit{a posteriori};
	\item evaluación del modelo y las implicaciones de la
		distribución \textit{a posteriori} resultante.
	\end{enumerate}

\section{Problemas de los test de hipótesis nula}	

	Los test de hipótesis nula (THN) son en ocasiones como un
método infalible para la realización de un experimento y la
forma de obtener conclusiones. Sin embargo, existen críticas
hacia el uso de este tipo de test, principalmente por parte 
de estadísticos bayesianos, causadas en su mayoría por el mal
uso que se hace de ellos. Las críticas realizadas son las
siguientes:

\begin{itemize}
\item Las decisiones dicotómicas. Al fijar el valor 
	$\alpha$ (normalmente $0.05$) se pueden realizar 
	decisiones opuestas con una mínima variación del $p$-
	valor. Se suele también confundir el significado del 
	test al considerar equivalentes dos métodos para los que
	no se encuentren diferencias estadísticamente 
	significativas.
\item Los THN no estiman la probabilidad
	de la hipótesis. La pregunta que habitualmente nos
	hacemos al comparar por ejemplo dos clasificadores es
	``\textit{¿cuál es la probabilidad de que el rendimiento
	de dos clasificadores sea el mismo?}'', en términos
	formales, $P(H_0 | \mathbf{X})$. La pregunta que
	responden es $P(T(\mathbf{X}) > \tau_\alpha | H_0)$.
\item Los test de hipótesis nula sobre puntos son
	prácticamente siempre falsos. La diferencia entre
	dos clasificadores puede ser muy pequeña, sin embargo
	no hay dos clasificadores cuyo rendimiento sea 
	equivalente. Esto tiene como consecuencia que añadiendo
	suficientes puntos es posible encontrar diferencias
	significantes. Además, no sólo en este contexto, los
	experimentos realizados y publicados suelen considerar
	hipótesis nulas difícilmente sostenibles donde el
	investigador busca rechazarla, con lo que el test está
	resulta sesgado.
\item El $p$-valor no distingue entre el efecto del tamaño
	y el tamaño de la muestra. Si el efecto del tamaño de
	$H_0$ es pequeño, se necesita más datos para demostrar 
	la diferencia. Sin embargo, como el tamaño de la muestra
	depende del investigador, y por el punto anterior $H_0$ 
	``es siempre falsa'', con suficientes datos se puede
	rechazar la hipótesis nula. En cambio, si se dispone 
	de pocos datos, se puede fallar al no rechazar una
	hipótesis nula ampliamente falsa.
\item Los THN no tienen en cuenta la magnitud y la 
	incertidumbre. No se proporciona información sobre la 
	magnitud del efecto o la incertidumbre de la estimación
	realizada, con lo que se dificulta un posterior análisis
	de las propias conclusiones realizadas.
\item No se obtiene información cuando no se rechaza la
	hipótesis nula. Es un error habitual al considerar 
	que al no encontrar diferencias significativas se
	considere cierta la hipótesis nula. 
\item No hay manera de decidir previamente el nivel 
	de significación $\alpha$. Aunque habitualmente se 
	fija un nivel de significación de $\alpha = 0.05$, y es
	este valor el que determina los límites para rechazar 
	$H_0$, este valor no tiene un significado concreto para
	el experimento. 
\item La inferencia depende del propósito del estudio. 
	La distribución de la muestra cambia por ejemplo si
	se comparan dos algoritmos en todos los conjuntos de
	datos disponibles que si se trata de realizar un 
	número de observaciones en un único conjunto.
\end{itemize}
	
\section{Análisis de los resultados experimentales}

	Hay dos enfoques para el análisis de resultados 
experimentales. El primero, conocido como \textbf{factor de 
Bayes} o \textbf{comparación de modelo bayesiano}, está, como 
los THN, basado en lo que llamaríamos un valor nulo. Se 
comparan dos modelos y se escoge el más probable según los 
datos obtenidos. Éste modelo también recibe algunas críticas
similares a los THN pues en cierta forma se está cambiando el
valor $\alpha$ por el usado para elegir entre un modelo u 
otro, volviendo a una decisión dicotómica. El otro modelo, el 
cual se desarrollará con más detalle, se conoce como 
\textbf{estimación bayesiana de parámetros}. Al realizar
el análisis sólo hay que establecer un rango de valores 
candidatos para el parámetro (modelo \textit{a priori}) 
y usar la inferencia bayesiana para calcular la probabilidad
de todos los valores candidatos (distribución \textit{a 
posteriori}).\\

\section{t-test bayesiano correlado}
	\label{ssec:bayes-ttest}
	Este test se usa para el análisis de la validación
cruzada en un único conjunto de datos. Su aporte consiste en 
tener en cuenta la correlación debida al solapamiento de los 
conjuntos de entrenamiento. El modelo de los datos 
considerados es
	\[ \mathbf{X} = \mu \mathbf{1} + \mathbf{v}, \]
	con $\mathbf{X} = (X_1, \dots, X_n)$, $\mathbf{1}$ un 
vector de unos de $n$ elementos, $\mu$ el parámetro de
interés, esto es la media de las distancias entre el 
rendimiento de los clasificadores y $\mathbf{v} \backsim 
\Sigma_{n \times n}$, una normal multivariante con
media cero y matriz de covarianzas $\Sigma$. Se caracteriza
$\Sigma$ de la siguiente manera: $\Sigma_{ii} = \sigma^2$
y $\Sigma_{ij} = \sigma^2 \rho$ para $i \neq j$, con $\rho$
la correlación y $\sigma^2$ la varianza. Entonces,
la probabilidad del modelo es 
	\[ 
		P(\mathbf{X} | \mu, \Sigma) = 
		\frac{\exp\left(
				-\frac{1}{2}
				(\mathbf{X}-\mu\mathbf{X})^T
				\Sigma^{-1}
				(\mathbf{X}-\mu\mathbf{X})
			\right)}
		{(2\pi)^{n/2} \sqrt{|\Sigma|}}.
	\]

	Esta probabilidad no permite estimar $\rho$ de los datos, 
así que adoptamos la heurística $\rho = \frac{n_{test}}{n}$,
con $n_{test}$ el número de datos en el conjunto de test.
Pretendemos estimar los parámetros $\mu$ y $\nu = 
\frac{1}{\sigma^2}$, para lo cual consideramos la 
distribución \textit{a priori} Normal-Gamma
	\[
		P(\mu, \nu | \mu_0, k_0, a, b) =
			N\left(\mu; \mu_0, \frac{k_0}{\nu} \right)
			G(\nu; a, b) = 
			NG(\mu, \nu ; \mu_0, k_0, a, b).
	\]
	Escogiendo los parámetros $\mu_0 = 0, k_0 \rightarrow 
\infty, a = -\frac{1}{2}, b=0$ la distribución \textit{a 
posteriori} de $\mu$ resulta ser la distribución de Student:
	
	\[
		P(\mu | \mathbf{X}, \mu_0, k_0, a, b) =
			St \left(
					\mu; n-1 , \bar{X},
					\left( \frac{1}{n} + 
							\frac{\rho}{1 - \rho} 
					\right) \hat{\sigma}^2
			   \right),
	\]
	con $\bar{X}$ y $\hat{\sigma}^2$ los estimadores 
habituales. Por tanto podemos hacer el análisis sobre $\mu$ 
basándonos en esta distribución.


\paragraph{Ejemplo} Supongamos que realizamos un experimento
con este test, realizando la comparación entre dos algoritmos
para una base de datos. La información obtenida es una 
distribución $T$ de Student, que describe como se ha mencionado
la ditribución de la media de las diferencias del rendimiento
entre dos clasificadores. Ahora, evaluamos la probabilidad 
de la hipótesis que queramos realizar, por ejemplo, que un 
algoritmo es mejor que otro directamente en la distribución
de $\mu$, calculando la probabilidad de que $\mu > 0$ ó $\mu 
< 0$ según corresponda. Para decir que los dos algoritmos son
prácticamente equivalentes, podemos suponer que esto 
significa que la diferencia de la precisión es menor que un
$1\%$. El intervalo $[-0.01, 0.01]$ se conoce entonces como
\textbf{región de práctica equivalencia} (\textit{rope}). Una manera 
de mostrar la incertidumbre de la estimación es indicando el 
intervalo de los valores que son más confiables y cubren el 
$q\%$ de la distribución (HDI). 

\paragraph{Toma de decisiones} A la hora de realizar 
análisis queremos obtener conclusiones, para lo que nos 
apoyaremos en la \textit{rope}. Si tenemos dos algoritmos $f_1, f_2$, 
notaremos por $P(f_1 \ll f_2)$ a la probabilidad de que el 
primero tenga un rendimiento inferior, por $P(f_1 \gg f_2)$ a 
que la de que tenga un rendimiento superior y por $P(f_1 =
f_2)$ a la probabilidad de que sean prácticamente 
equivalentes. Podemos tomar las decisiones con un nivel
de confianza (ahora con una interpretación directa) si
tenemos una de estas tres situaciones con un valor mayor
al nivel de confianza deseado.

\section{Test bayesiano de signo y \textit{signed-rank}}

	Al igual que el $t$-test, el test no paramétrico de 
signo también cuenta con la versión bayesiana. Partimos
del vector $z = \{z_1, \dots, z_q\}$ de muestras i.i.d.. 
Suponemos como distribución \textit{a priori} un proceso
de Dirichlet ($DP$). Un $DP$ es una distribución sobre 
distribuciones de probabilidad tales que sus distribuciones
marginales sobre particiones finitas siguen la distribución
de Dirichlet (que se puede considerar la generalización
multivariante de la distribución Gamma). El $DP$ está
definido por dos parámetros: la fuerza \textit{a priori},
$s>0$ y la media \textit{a priori} , $G_0$. Tengamos en 
cuenta que al ser $DP$ una distribución sobre distribuciones,
$G_0$ es una medida de probabilidad. Escogiendo $G_0 = 
\delta_{z_0}$, una delta de Dirac centrada en el punto $z_0$,
la densidad de probabilidad \textit{a posteriori} de $Z$ tiene la
expresión:
	\[ P(z) = 
		w_0 \delta_{z_0}(z) +
			\sum\limits_{j=1}^n
				w_j \delta_{z_j}(z); \quad
		(w_0, w_1, \dots, w_n) \sim Dir(s,1, \dots, 1).
	\] 
	
	Si observamos esta expresión, tenemos que es una 
combinación de deltas de Dirac centradas en las observaciones
y en la observación \textit{a priori} $z_0$ y cuyos pesos
siguen una distribución de Dirichlet. Para el análisis
experimental procedemos de la siguiente manera. Calculamos:

\begin{align*}
	\theta_l = P[ z < -r ] = 
				\sum\limits_{i = 0}^q 
					w_i \mathbb{I}[ z_i \in (-\infty,-r)],\\
	\theta_e = P[ |z| \leq -r ] = 
				\sum\limits_{i = 0}^q 
					w_i \mathbb{I}[ z_i \in [-r,r]], \\
	\theta_r = P[ z > r ] = 
				\sum\limits_{i = 0}^q 
					w_i \mathbb{I}[ z_i \in (r, \infty)].
\end{align*}

	Así, obtenemos una versión bayesiana del test de signo, 
que tiene en cuenta la \textit{rope} $[-r,r]$. De hecho, $\theta_l,
\theta_e, \theta_r$ son las probabilidades de que la media
de las diferencias esté en el respectivo intervalo. 
Debido a que $(w_0, w_1, \dots, w_n) \sim Dir(s,1, \dots, 
1)$, se demuestra que
	\[ 
		\theta_l,\theta_e, \theta_r \sim
		Dir(n_l + s \mathbb{I}[ z_0 \in (-\infty,-r) ],
			n_e + s \mathbb{I}[ z_0 \in [-r,r] ],
			n_r + s \mathbb{I}[ z_0 \in (r, \infty) ])
	\]
	donde $n_l, n_e, n_r$ son el número de observaciones 
que caen en cada intervalo. En definitiva, para 
completar el modelo, debemos escoger el valor \textit{a 
priori} de la fuerza $s$ y la observación $z_0$.\\

	Si ahora consideramos
	
\begin{align*}
	\theta_l &= P[ z < -r ] = 
				\sum\limits_{i = 0}^q 
				\sum\limits_{j = 0}^q 
					w_i w_j 
					\mathbb{I}[ z_i + z_j 
								\in (-\infty,-2r)],\\
	\theta_e &= P[ |z| \leq -r ] = 
				\sum\limits_{i = 0}^q 
				\sum\limits_{j = 0}^q 
					w_i w_j 
					\mathbb{I}[ z_i + z_j 
								\in [-2r,2r]], \\
	\theta_r &= P[ z > r ] = 
				\sum\limits_{i = 0}^q 
				\sum\limits_{j = 0}^q 
					w_i w_j 
					\mathbb{I}[ z_i + z_j 
								\in (2r, \infty)],
\end{align*}
	obtenemos una versión bayesiana del 
test de rangos con signo, con la \textit{rope} $[-r,r]$. 
Ahora la distribución de 
$\theta_l, \theta_e, \theta_r$ no está claramente definida,
pero se puede calcular muestreando mediante el método
de Monte Carlo los pesos $(w_0, w_1, \dots, w_n) \sim 
Dir(s,1, \dots, 1)$.\\
	Para ambos métodos falta por fijar $s$ y $z_0$. 
En los experimentos realizados por Benavoli 
(\cite{DBLP:journals/corr/BenavoliCDZ16}) se utiliza $s=0.5$ y $z_0=0$. Se realizan 
también experimentos con $z_0 = \infty$ y $z_0 = -\infty$, 
obteniendo resultados muy parecidos en la probabilidad
de escoger un algoritmo frente a otro.



