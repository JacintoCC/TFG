\documentclass[leqno]{beamer}
\usepackage[spanish,activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{xtab,array,booktabs}

\usetheme{CambridgeUS}
\usecolortheme{spruce}
%\setbeameroption{show notes} %un-comment to see the notes

\title{Trabajo de Fin de Grado}
\subtitle{Evaluación del estado del arte en técnicas estadísticas para el análisis comparativo de algoritmos de aprendizaje automático}
\author{Jacinto Carrasco Castillo}

\newtheoremstyle{definition_wo_parentheses}
  {\topsep}% measure of space to leave above the theorem. E.g.: 3pt
  {\topsep}% measure of space to leave below the theorem. E.g.: 3pt
  {}% name of font to use in the body of the theorem
  {0pt}% measure of space to indent
  {\bfseries}% name of head font
  {.}% punctuation between head and body
  { }% space after theorem head; " " = normal interword space
  {\thmname{#1}\thmnumber{ #2.}\thmnote{ #3}}
  
  
\theoremstyle{definition_wo_parentheses}
\newtheorem{definicion}{Definición}


\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\section{Planteamiento}


\begin{frame}{Descripción del problema}
	La comparación de algoritmos debe realizarse de manera 
rigurosa para reducir la aleatoriedad asociada a los 
experimentos. Para realizar una correcta comparación es 
necesario:
	
\begin{itemize}
	\item Selección de medida del rendimiento.
	\item Validación cruzada y remuestreo. 
	\item Test estadísticos.
\end{itemize}
\end{frame}

\note{
\textbf{Selección de medida del rendimiento}. Diferentes medidas 
según el problema a resolver. Podemos interesarnos por maximizar 
la precisión o minimizar una función de coste o pérdida.\\
\textbf{Validación cruzada y remuestreo}. Para la validación de los 
resultados es necesario repetir los experimentos. Debido a que el
número de datos disponibles es limitado es necesario reutilizar los datos.\\
\textbf{Test estadísticos}. Responden a las preguntas sobre si se pueden justificar
los resultados estadísticamente o se han obtenido por azar. 
Los test se aplica a comparar dos algoritmos en un dominio, dos algoritmos
sobre varios problemas o comparar múltiples algoritmos en varios dominios.
}


\begin{frame}{Objetivos}
\begin{itemize}
	\item Estudio de los test estadísticos disponibles.
	\item Integración de herramientas informáticas existentes
	 para la aplicación de estos test.
	\item Comparación de las propiedades de los test.
\end{itemize}
\end{frame}

\section{Contenido matemático}

\subsection{Test paramétricos}
\begin{frame}{Test paramétricos}

	Suponen que la muestra pertenece a una distribución conocida. 

\begin{description}
\item[Test binomial para una muestra] Comprobación de que 
	el rendimiento para un problema sea igual a un valor 
	$\theta_0$.
\item[$t$-test para muestras apareadas]  Comparación de la 
	media de dos muestras. Comparación de dos algoritmos
	para un conjunto de datos.
\item[ANOVA] Comparación de la media de múltiples algoritmos
	en múltiples problemas. Trata la varianza
	en un grupo, entre grupos y la combinación de ellas.
\end{description}
\end{frame}

\note{
\textbf{$t$-test}: Para el $t$-test surgen modificaciones
que ofrecen mejores resultados usando validación cruzada $5 \times 2$,
esto es, se se divide en dos particiones, usando cada una de ellas como
entrenamiento y validación, y se repite cinco veces.
Para cada test se incluye en la memoria la obtención del
estadístico y la distribución que sigue para determinar
si se encuentra en la región crítica, 
esto es, la región donde rechazaríamos la hipótesis nula.
}


\subsection{Test no paramétricos}

\begin{frame}{Test no paramétricos}{Comparación con test paramétricos}
\begin{itemize}
\item Los test no paramétricos no suponen la pertenencia 
	de la distribución a ninguna familia de distribuciones.
\item Las hipótesis para aplicar estos test son más
	generales. 
\item Si se dan las hipótesis necesarias para los test
	paramétricos, tienen una menor potencia.
\item Si se disponen de pocos datos las hipótesis de los
	test paramétricos no suelen darse y los test no
	paramétricos suplen la falta de potencia con mayor
	precisión.
\end{itemize}		
\end{frame}

\note{
Las hipótesis de los test paramétricos son cuestiones 
más generales como la simetría de la población o la 
continuidad, mientras que en los test paramétricos
se suelen exigir la normalidad de la población o 
la igualdad de las varianzas.
}


\begin{frame}{Test no paramétricos}
	Tipos de test no paramétricos:
\begin{itemize}
\item Test de aleatoriedad: basados en el número de rachas.
\item Test de bondad del ajuste: Test chi cuadrado, 
	Kolmogorov-Smirnov.
\item Análisis del conteo de datos: Test de McNemar.
\item Test basado en una muestra y muestras apareadas: Test
	de signo, test de rangos con signos de Wilcoxon. 
\item Análisis bidimensional de la varianza: Test de 
	Friedman, modificación de Iman-Davenport, test de 
	rangos alineados de Friedman, test de Quade.
\end{itemize}
\end{frame}

\note{
Los test de bondad del ajuste podemos usarlos para aplicar
test paramétricos con mayor certeza sobre la normalidad de la población.\\
Usamos para la comparación de dos algoritmos en un problema el test de McNemar,
los test de signo y de rangos con signos para varios problemas.\\
Los restantes test para múltiples algoritmos en varios problemas. El test de 
Iman-Davenport tiene una mayor potencia. El test de Quade tiene en cuenta
la dificultad de los test.
}

\begin{frame}{Test no paramétricos}{Procedimientos \textit{post-hoc}}
	Los test que comparan múltiples algoritmos indican la
existencia de diferencias entre ellos. Necesitan un
test adicional para indicar dónde están estas diferencias.

\begin{itemize}
\item $p$-valores ajustados: Al realizar múltiples comparaciones aumenta la probabilidad de cometer un error de tipo I. Hay distintos métodos para ajustar los $p$-valores obtenidos.
\begin{itemize}
\item Procedimientos de un paso: Bonferroni-Dunn.
\item Procedimiento descendente: Holm, Holland, Finner.
\item Procedimiento ascendente:  Hochberg, Hommel, Rom.
\item Procedimiento en dos pasos: Li.
\end{itemize}
\end{itemize}
\end{frame}

\note{
El procedimiento de Hommel es más complejo. El procedimiento de Li ofrece
resultados más inestables cuando los $p$-valores originales son mayores
a 0.05. 
}

\begin{frame}{Test no paramétricos}{Test basados en permutaciones}
	Son test no paramétricos. La hipótesis nula es que una muestra $\mathbf{x}$ proviene de una misma población.\\
	Suponiendo $H_0$ cierta, los individuos de cada 
subconjunto de la muestra se puede intercambiar por los de 
otro subconjunto.
\begin{definicion}[Principio de los test basados en permutaciones] Si dos experimentos toman valores en el mismo
espacio muestral $\Omega$ con distribuciones $P_1, P_2$ dan
el mismo conjunto de datos, las inferencias condicionales
a los datos usando el mismo estadístico deben ser la misma.
\end{definicion}
\end{frame}


\subsection{Test bayesianos}

\begin{frame}{Test bayesianos}{Comparación con THN}
	La inferencia bayesiana ajusta un modelo de probabilidad
a los datos y obtiene una distribución sobre los parámetros
del modelo. Las diferencias con los test de hipótesis nula son:

\begin{itemize}
\item Se evitan decisiones dicotómicas marcadas por $\alpha$.
\item Los THN no estiman la probabilidad de la hipótesis.
\item Con suficientes datos se rechaza casi toda hip. nula.
\item No se tiene en cuenta magnitud de la diferencia ni incertidumbre.
\item No se obtiene información si no se rechaza la hipótesis nula.
\end{itemize}

\end{frame}

\note{
Con los test bayesianos sí se responde a la pregunta
más natural de ``¿cuál es la probabilidad de 
que el rendimiento de dos clasificadores sea el mismo?''.\\
Con los THN podríamos pensar que se obtienen datos hasta
que se consigue rechazar la hipótesis nula.\\
El enfoque realizado es la estimación bayesiana de parámetros, 
pues en el análisis mediante el factor de Bayes se 
dan problemas similares a los mencionados.
}

\begin{frame}{Test bayesianos}
\begin{description}
\item[$t$-test bayesiano correlado] Comparación de dos
dos algoritmos en un único conjunto de datos. Tiene en cuenta
la correlación de los conjuntos de entrenamientos en CV.
Se obtiene una distribución $T$ de Student sobre la
diferencia de las medias.
\item[Test bayesiano de signo] Versión bayesiana del test de 
signo. Se obtiene distribución sobre la probabilidad de que 
la diferencia entre algoritmos esté en la \textit{rope}, a la 
izquierda o a la derecha.
\item[Test bayesiano de rangos alineados] Versión bayesiana 
del test de rangos alineados. No se obtiene una distribución clara de los parámetros, 
pero se puede obtener una muestra. 
\end{description}
\end{frame}

\note{
Se considera la \textit{rope} la región de una equivalencia
entre los algoritmos.Si la distribución se encuentra dentro 
de esta región, consideraremos equivalentes el rendimiento 
de los algoritmos para ese conjunto de datos. Si la 
distribución se encuentra a la derecha o a la izquierda,
un algoritmo será mejor que otro.
}

\section{Contenido informático}

\begin{frame}[fragile]{rNPBST}{Características del paquete}

\begin{table}[]
\begin{tabularx}{\textwidth}{lX}
\toprule
Característica &    \\
\midrule
Lenguaje             & \texttt{R}\\
Test no paramétricos & Integrados a partir del paquete \texttt{JavaNPST} usando \texttt{rJava}.\\
Test bayesianos      & Implementados \texttt{R}. Mayor eficiencia y reusabilidad que los paquetes disponibles. 
						Incluye métodos para la representación gráfica de los resultados de estos test. \\
Datos de prueba      & Se incluyen los resultados de 5 algoritmos sobre 29 conjuntos de datos para ejemplificar el uso del paquete.\\
\bottomrule
\end{tabularx}
\end{table}
\end{frame}

\begin{frame}[fragile]{rNPBST}{Instalación}
Paquete de \texttt{R} disponible en 
\begin{center}
\url{https://github.com/JacintoCC/TFG/tree/master/rNPBST}
\end{center}
Para la instalación, ejecutar donde se encuentre la carpeta con el software:
	\begin{verbatim}
	> R CMD build rNPBST
	> R CMD INSTALL rNPBST
	\end{verbatim}
\end{frame}


\begin{frame}[fragile]{Aplicación de test}
\begin{verbatim}
 > data("results")
 > ft <- friedman.test(results)
 > ft$htest
      Friedman test
   data: results
   s = 2812.000, q = 39.056, p-value = 6.789e-08
\end{verbatim}
Con estos resultados rechazaríamos la hipótesis nula de la 
equivalencia de los algoritmos. El test nos devuelve en el 
parámetro \texttt{report} también la suma del orden
medio de cada algoritmo. 
\end{frame}


\begin{frame}[fragile]{Aplicación de test}{Test bayesianos - $t$-Test bayesiano correlado}
   \begin{verbatim}
   > dataset.index <- 13
   > correlatedBayesianT.test(results.lr[dataset.index, ],
                              results.rf[dataset.index, ])
   \end{verbatim}
   \begin{center}
   \includegraphics[width=0.4\textwidth]{imagenes/LR-RF-hayes-roth.pdf}
   \end{center}
\end{frame}

\note{Al situarse la mayor parte de la distribución a la izquierda 
de la \textit{rope}, tenemos que para este conjunto de datos el algoritmo
\textit{random forest} funciona mejor que la regresión logística.}

\begin{frame}[fragile]{Aplicación de test}{Test bayesianos - Test bayesiano de rangos con signo}
   \begin{verbatim}
   > bayesianSignedRank.test(results$KNN,
                            results$neural.network)
   \end{verbatim}
   \begin{center}
   \includegraphics[width=0.5\textwidth]{imagenes/BSR-KNN-NNET.pdf}
   \end{center}
\end{frame}

\note{Se observa una mayor concentración en la región
donde hay más probabilidad de que el parámetro caiga en la
\textit{rope}, con lo que no podríamos decir que hay 
diferencias entre los algoritmos comparados}


\begin{frame}[fragile]{Comparación de la potencia de test estadísticos}
   \begin{center}
   \includegraphics[width=0.6\textwidth]{imagenes/ComparacionesTest.pdf}
   \end{center}
\end{frame}

\note{Se han seleccionado aleatoriamente un subconjunto de conjuntos de datos
y se ha comprobado el número de hipótesis nulas rechazadas.
El parámetro $K$ influye en escoger aquellos conjuntos de datos 
con una mayor diferencia. Para estos datos el test
de Quade obtiene los peores resultados y los métodos
para ajustar los $p$-valores con mayor potencia son 
el de Finner y el de Bergmann y Hommel. Otro posible 
experimento podría consistir en ver el error de tipo I de cada test, es decir,
cuándo se rechaza la hipótesis nula siendo cierta.
}

\section{Conclusiones}

\begin{frame}{Conclusiones}
	Se presentan las conclusiones obtenidas tras la realización del trabajo:
\begin{itemize}
\item Necesidad de comprobar las condiciones necesarias para la aplicación de test.
\item Relevancia de los test basados en \textit{rankings} para la comparación de múltiples algoritmos.
\item Diferencias entre THN y test bayesianos.
\item Importancia de disponer una única herramienta para la realización de test.
\end{itemize}
\end{frame}

\begin{frame}{Trabajos futuros}
\begin{itemize}
\item Seguir profundizando en nuevos métodos para realizar la comparación propuestos
\item Complementar la biblioteca de \texttt{R} con estos nuevos métodos propuestos, test basados en permutaciones.
\item Realizar un estudio más detallado sobre las propiedades de los test y métodos, incluir comparación de test bayesianos.
\end{itemize}
\end{frame}

\end{document}
