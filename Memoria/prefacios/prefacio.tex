\chapter*{}
%\thispagestyle{empty}
%\cleardoublepage

%\thispagestyle{empty}

\input{portada/portada_2}



\cleardoublepage
\thispagestyle{empty}

\begin{center}
{\large\bfseries \myTitle }\\
\end{center}
\begin{center}	
	\myName \\
\end{center}

%\vspace{0.7cm}
\noindent{\textbf{Palabras clave}: aprendizaje automático,
	evaluación de algoritmos, test paramétricos, test no 
	paramétricos, test basados en permutaciones, test 
	bayesianos, R}\\

\vspace{0.7cm}
\noindent{\textbf{Resumen}}\\

	En este trabajo se pretende realizar un estudio sobre
	la aplicación de test estadísticos en la comparación
	del rendimiento de algoritmos de aprendizaje automático.
	Se incluye la descripción matemática de los test más
	utilizados tanto a la hora de detectar diferencias 
	entre los algoritmos como para evaluar el cumplimiento
	de ciertas características de los datos para la
	realización de los test. Se presentan test de 
	hipótesis nula basados en la estadística frecuentista,
	tanto paramétricos como no paramétricos, y test
	bayesianos. Para mostrar un ejemplo del problema, se 
	muestra la aplicación de test estadísticos sobre
	los resultados de varios algoritmos de clasificación
	sobre diversos conjuntos de datos y se buscan las 
	diferencias en el rendimiento de estos algoritmos.
	Este estudio nos permitirá observar las propiedades
	de cada test y realizar la comparación entre la
	potencia de cada uno de ellos.
\cleardoublepage


\thispagestyle{empty}


\begin{center}
{\large\bfseries Evaluation of state of the art stadistic techniques for machine learning algorithms' comparative analysis}\\
\end{center}
\begin{center}
	\myName	\\
\end{center}

%\vspace{0.7cm}
\noindent{\textbf{Keywords}: Machine learning, algorithms' evaluation, 
	parametric tests, non parametric tests, permutation tests, 
	bayesian tests, R}\\

\vspace{0.7cm}
\noindent{\textbf{Abstract}}\\

	In recent years the interest in machine learning has 
meant an increasing amount in the proposed machine learning 
algorithms. Nevertheless, these new algorithms need to be 
tested and the properties and results must be proved, so in 
order to achieve this objective statistical tests are the 
best approach.\\
	In this project, we present a set of tests commonly used 
in this problem, with a practical case of study analysing the 
power of each test. \\
	In the first part of this memory, we present the 
mathematical base of the statistical tests. This part 
contains an introduction about measuring the algorithms’ 
performance and the ways to obtein a reliable measure of this 
performance. The tests presented are classified in three 
categories: parametric, non-parametric and Bayesian tests. In 
each categorie we include tests with different goals: 
comparison between two algorithms in one data set, two 
algorithms in multiple data sets or between multimple 
algoritms in multiple data sets. The first set of statistical 
tests presented are the parametric ones, which are widely 
known and used, like t-test or ANOVA, but presents some 
faults related with the necessary conditions to apply the 
parametric tests, which are rarely given. \\
	We describe these faults and present the non parametric 
tests, which do not need these strict conditions about the 
population like normality or homocedasticity but relaxed 
conditions like the symmetry of the population. Non 
parametric test are usually less powerful than parametric one 
due to in non parametric test we have less information about 
the underlying population of the data, but this lack of power 
is compensated with the lack of precision in the parametric 
tests when the number of data is low or the conditions are 
not satisfied. The test presented in the non parametric 
chapter allows us to obtain some valuable information as the 
randomness of a sample or the goodness of fit of the data to 
a given population, which are conditions to use the previous 
parametric tests. Moreover, non parametric tests as Wilcoxon 
Signed-ranks for comparing two algorithms or Friedman test 
for multiple algorithms over multiple data sets are presented 
in this chapter with some improvements like Iman-Davenport 
test or Quade test, which takes account of the different 
difficulties of the data sets. Once the null hypothesis of an 
equal performance of all algorithms in the study is rejected, 
we need a post-hoc method to find where is the difference 
between algorithms, so we introduce some procedures, like 
Finner’s, Hommel’s or Li’s procedures. As a special case of 
non parametric tests, we include a general description of the 
base of permutation tests, which start with a sample of two 
populations and collect information against the null 
hypothesis making permutations of the sample.\\ 
	As a complete different approach of the comparison, we 
present Bayesian tests. Null hypothesis tests present some 
problems mainly related with the understanding of what 
information they give. More frequently that it should 
happens, researchers thinks that the p-value given by a null 
hypothesis test corresponds to the probability, given a 
sample, that the null hypothesis is true instead of the 
actual meaning, that is the probability, assuming the null 
hypothesis is true, of obtaining a sample as extreme or more 
than our sample. The wanted statement is not achieved with 
frequentist statistical methods but Bayesian ones, so we 
present a series of differences between null hypothesis tests 
and Bayesians tests. Moreover, we present a Bayesian version 
of frequentist tests as t-test, sign test and Wilcoxon 
signed-rank test.\\
	We dedicate the second part of the memory to the 
experimental study of the comparison between algorithms. The 
first chapter contains a revision of state of the art 
statistical techniques applied in recent years as well as 
most influential articles in the field. 



\chapter*{}
\thispagestyle{empty}

\noindent\rule[-1ex]{\textwidth}{2pt}\\[4.5ex]

Yo, \textbf{\myName}, alumno de la titulación \myDegree de la \textbf{\myFaculty de la \myUni}, con DNI 32056356, autorizo la
ubicación de la siguiente copia de mi Trabajo Fin de Grado en la biblioteca de ambos centros para que pueda ser
consultada por las personas que lo deseen.

\vspace{6cm}

\noindent Fdo: \myName

\vspace{2cm}

\begin{flushright}
Granada a 9 de septiembre de 2016.
\end{flushright}


\chapter*{}
\thispagestyle{empty}

\noindent\rule[-1ex]{\textwidth}{2pt}\\[4.5ex]

D. \textbf{ \myProf }, Profesor del Departamento de Ciencias de la Computación e Inteligencia Artificial de la Universidad de Granada.

\vspace{0.5cm}

D. \textbf{ \myOtherProf}, Profesora del Departamento de Estadística e Investigación Operativa de la Universidad de Granada.


\vspace{0.5cm}

\textbf{Informan:}

\vspace{0.5cm}

Que el presente trabajo, titulado \textit{\textbf{\myTitle}},
ha sido realizado bajo su supervisión por \textbf{\myName}, y autorizamos la defensa de dicho trabajo ante el tribunal
que corresponda.

\vspace{0.5cm}

Y para que conste, expiden y firman el presente informe en Granada a X de septiembre de 2016.

\vspace{1cm}

\textbf{Los directores:}

\vspace{5cm}

\noindent \textbf{\myProf \ \ \ \ \ \myOtherProf}

\chapter*{Agradecimientos}
\thispagestyle{empty}

       \vspace{1cm}


Poner aquí agradecimientos...

